<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>My First Post</title>
    <url>/2021/08/03/My-First-Post/</url>
    <content><![CDATA[<p>My first blog in zzhbrr.github.io.</p>
<p>yeah!!</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title>Study Diary</title>
    <url>/2021/10/09/Study-Diary/</url>
    <content><![CDATA[<center>
<p>学习笔记&lt;/&gt;</p>
<span id="more"></span>
]]></content>
      <categories>
        <category>Life</category>
        <category>Diary</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Life</title>
    <url>/2021/08/07/Life/</url>
    <content><![CDATA[
]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title>Pytorch数据载入学习</title>
    <url>/2022/01/30/Pytorch%E6%95%B0%E6%8D%AE%E8%BD%BD%E5%85%A5%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<center>
Dataset, Sampler, DataLoader, DataLoaderIter简单分析
</center>
<span id="more"></span>
<h3 id="一dataset">一、Dataset</h3>
<p>torch.utils.data.Dataset是一个抽象类，所有其他类的数据集类都是它的子类，所有子类都应该重载len和getitem。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dataset</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__add__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">        <span class="keyword">return</span> ConcatDataset([self, other])</span><br></pre></td></tr></table></figure>
<p>其子类中，torch.utils.data.TensorDataset，是将数据封装成tensor的数据集，每一个样本通过索引张量来获得。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TensorDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, *tensor</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">all</span>(tensors[<span class="number">0</span>].size(<span class="number">0</span>) == tensor.size(<span class="number">0</span>) <span class="keyword">for</span> tensor <span class="keyword">in</span> tensors) <span class="comment"># 要保证每一个张量的第一维大小相同（即数量）</span></span><br><span class="line">        self.tensors = tensors <span class="comment"># 把数据封装成一个张量</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">tuple</span>(tensor[index] <span class="keyword">for</span> tensor <span class="keyword">in</span> tensors) <span class="comment"># 返回张量在第index层的切片，即所有数据的第index个组合成的张量</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.tensors[<span class="number">0</span>].size(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="二sampler">二、Sampler</h3>
<p>torch.utils.data.Sampler 是负责生成Dataset的索引的类。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sampler</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source</span>):</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span> <span class="comment"># 返回一个迭代器，每个都是“一系列”数据的索引</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span> <span class="comment"># 表示返回的迭代器的长度</span></span><br><span class="line">        <span class="keyword">raise</span> NotImplementedError</span><br></pre></td></tr></table></figure>
<p>Sampler有子类SequentialSampler和RandomSampler，定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 顺序采样</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SequentialSampler</span>(<span class="params">Sampler</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source</span>):</span></span><br><span class="line">        self.data_source = data_source</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(self.data_source)))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_source)</span><br><span class="line"><span class="comment"># 随机采样</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomSampler</span>(<span class="params">Sampler</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_source</span>):</span></span><br><span class="line">        self.data_source = data_source</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">iter</span>(torch.randperm(<span class="built_in">len</span>(self.data_source)).long()) <span class="comment"># 随机生成一个排列</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_source)</span><br></pre></td></tr></table></figure>
<p>torch.utils.data.BatchSampler是基于Sampler来构造的，用来生成批量索引。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BatchSampler</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, sampler, batch_size, drop_last</span>):</span> <span class="comment"># 参数sampler, batch_size(每一批次大小), drop_last(如果最后一个批次没满，是否丢掉最后一批次)</span></span><br><span class="line">        self.sampler = sampler  </span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        batch = []</span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> self.sampler:</span><br><span class="line">            batch.append(idx) <span class="comment"># 根据sampler的索引，将数据装入一个batch中</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(batch) == self.batch_size:</span><br><span class="line">                <span class="keyword">yield</span> batch</span><br><span class="line">                batch = []</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(batch) &gt; <span class="number">0</span> <span class="keyword">and</span> <span class="keyword">not</span> self.drop_last:</span><br><span class="line">            <span class="keyword">yield</span> batch</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.drop_last:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">len</span>(self.sampler) // self.batch_size</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> (<span class="built_in">len</span>(self.sampler) + self.batch_size - <span class="number">1</span>) // self.batch_size</span><br></pre></td></tr></table></figure>
<p>drop_last的例子:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(<span class="built_in">range</span>(<span class="number">10</span>), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>))</span><br><span class="line">        [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>]]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">list</span>(BatchSampler(<span class="built_in">range</span>(<span class="number">10</span>), batch_size=<span class="number">3</span>, drop_last=<span class="literal">True</span>))</span><br><span class="line">        [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]]</span><br></pre></td></tr></table></figure>
<p>batchsampler的其他例子</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data.sampler <span class="keyword">import</span> BatchSampler</span><br><span class="line">[x <span class="keyword">for</span> x <span class="keyword">in</span> BatchSampler(<span class="built_in">range</span>(<span class="number">10</span>), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>)]</span><br><span class="line">Out[<span class="number">9</span>]: [[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>]]</span><br><span class="line">[x <span class="keyword">for</span> x <span class="keyword">in</span> BatchSampler(RandomSampler(<span class="built_in">range</span>(<span class="number">10</span>)), batch_size=<span class="number">3</span>, drop_last=<span class="literal">False</span>)]</span><br><span class="line">Out[<span class="number">15</span>]: [[<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>], [<span class="number">9</span>, <span class="number">2</span>, <span class="number">0</span>], [<span class="number">5</span>, <span class="number">4</span>, <span class="number">6</span>], [<span class="number">8</span>]]</span><br></pre></td></tr></table></figure>
<h3 id="三dataloader">三、DataLoader</h3>
<p>torch.utils.data.DataLoader 负责加载数据，支持多进程。</p>
<p>其接口定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>,</span><br><span class="line">           batch_sampler=<span class="literal">None</span>, num_workers=<span class="number">0</span>, collate_fn=<span class="literal">None</span>,</span><br><span class="line">           pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>, timeout=<span class="number">0</span>,</span><br><span class="line">           worker_init_fn=<span class="literal">None</span>, *, prefetch_factor=<span class="number">2</span>,</span><br><span class="line">           persistent_workers=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>dataset是加载的数据集。</p>
<p>batch_size是每个batch加载数据的多少。</p>
<p>shuffle设置为True的时候，调用RandomSampler进行随机索引。</p>
<p>sampler是从数据集中提取样本的策略，如果指定了sampler，则shuffle参数必须为False。</p>
<p>batch_sampler与sampler类似，每次返回一个批次的索引，如果指定了batch_sampler，则batch_size和shuffle必须与之相符合。</p>
<p>num_workers是数据加载的子进程数。</p>
<p>collate_fn是一个callable的函数，将Map-style
dataset取出的batch_size个数据（tuple类型，每个tuple长度为2，其中第一个是数据，第二个是标签）整合成一个list，这个list的长度为2，一个是batch_size个数据组成的FloatTensor，一个是batch_size个标签组成的longTensor。</p>
<p>pin_memory如果为True，则 DataLoader 在将张量返回之前将其复制到 CUDA
固定的内存中。</p>
<p>drop_last，如果最后一个batch没满，是否要丢掉。</p>
<p>timeout，如果为正，则为从 worker 收集 batch
的超时值，应始终为非负数，超过这个时间还没读取到数据的话就会报错</p>
<p>worker_init_fn 是callable的函数，如果不为 None，它将会被每个 worker
子进程调用，以 worker id ([0, num_workers - 1] 内的整形) 为输入。</p>
<p>prefetch_factor是每个 worker 提前加载 的 sample 数量，默认为2。</p>
<p>persistent_workers 如果为 True，dataloader 将不会终止 worker
进程，直到 dataset 迭代完成。</p>
<p><strong>collate_fn</strong></p>
<p>当collate_fn作用于数据样本列表，将输入样本整理为一个
batch时（不是只处理一个数据时），通常做以下3件事：</p>
<ol type="1">
<li>添加新的维度（第一维）</li>
<li>自动将numpy数组和python数值转换为tensor</li>
<li>保留数据结构</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoader</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">False</span>, sampler=<span class="literal">None</span>, batch_sampler=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 num_workers=<span class="number">0</span>, collate_fn=default_collate, pin_memory=<span class="literal">False</span>, drop_last=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                 timeout=<span class="number">0</span>, worker_init_fn=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.dataset = dataset</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        self.num_workers = num_workers</span><br><span class="line">        self.collate_fn = collate_fn</span><br><span class="line">        self.pin_memory = pin_memory</span><br><span class="line">        self.drop_last = drop_last</span><br><span class="line">        self.timeout = timeout</span><br><span class="line">        self.worker_init_fn = worker_init_fn</span><br><span class="line">        <span class="keyword">if</span> timeout &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;timeout option should be non-negative&#x27;</span>)</span><br><span class="line">        <span class="comment"># 检测是否存在参数冲突</span></span><br><span class="line">        <span class="keyword">if</span> batch_sampler <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">if</span> batch_size &gt; <span class="number">1</span> <span class="keyword">or</span> shuffle <span class="keyword">or</span> sampler <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">or</span> drop_last:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">&#x27;batch_sampler is mutually exclusive with &#x27;</span></span><br><span class="line">                                 <span class="string">&#x27;batch_size, shuffle, sampler, and drop_last&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> sampler <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> shuffle:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;sampler is mutually exclusive with shuffle&#x27;</span>)</span><br><span class="line">        <span class="keyword">if</span> self.num_workers &lt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&#x27;num_workers cannot be negative; &#x27;</span></span><br><span class="line">                             <span class="string">&#x27;use num_workers=0 to disable multiprocessing.&#x27;</span>)</span><br><span class="line">        <span class="comment"># 在此处会强行指定一个 BatchSampler</span></span><br><span class="line">        <span class="keyword">if</span> batch_sampler <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 在此处会强行指定一个 Sampler</span></span><br><span class="line">            <span class="keyword">if</span> sampler <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">if</span> shuffle:</span><br><span class="line">                    sampler = RandomSampler(dataset)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    sampler = SequentialSampler(dataset)</span><br><span class="line">            batch_sampler = BatchSampler(sampler, batch_size, drop_last)</span><br><span class="line">        <span class="comment"># 使用自定义的采样器和批采样器</span></span><br><span class="line">        self.sampler = sampler</span><br><span class="line">        self.batch_sampler = batch_sampler</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__iter__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="comment"># 调用Pytorch的多线程迭代器加载数据</span></span><br><span class="line">        <span class="keyword">return</span> DataLoaderIter(self)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.batch_sampler)</span><br></pre></td></tr></table></figure>
<h3 id="三dataloaderiter">三、DataLoaderIter</h3>
<p>在调用iter(DataLoader)的时候，返回了DataLoaderIter。</p>
<p>（只看了单线程，多线程还不会）</p>
<p>定义如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataLoaderIter</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;Iterates once over the DataLoader&#x27;s dataset, as specified by the sampler&quot;</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, loader</span>):</span></span><br><span class="line">        self.dataset = loader.dataset</span><br><span class="line">        self.collate_fn = loader.collate_fn</span><br><span class="line">        self.batch_sampler = loader.batch_sampler</span><br><span class="line">        self.num_workers = loader.num_workers</span><br><span class="line">        self.pin_memory = loader.pin_memory <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line">        self.timeout = loader.timeout</span><br><span class="line">        self.done_event = threading.Event()</span><br><span class="line"> </span><br><span class="line">        self.sample_iter = <span class="built_in">iter</span>(self.batch_sampler) <span class="comment"># DataLoaderIter比DataLoader多了sample_iter</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> self.num_workers &gt; <span class="number">0</span>: <span class="comment"># 后面就都是处理多线程的了</span></span><br><span class="line">            self.worker_init_fn = loader.worker_init_fn</span><br><span class="line">            self.index_queue = multiprocessing.SimpleQueue()</span><br><span class="line">            self.worker_result_queue = multiprocessing.SimpleQueue()</span><br><span class="line">            self.batches_outstanding = <span class="number">0</span></span><br><span class="line">            self.worker_pids_set = <span class="literal">False</span></span><br><span class="line">            self.shutdown = <span class="literal">False</span></span><br><span class="line">            self.send_idx = <span class="number">0</span></span><br><span class="line">            self.rcvd_idx = <span class="number">0</span></span><br><span class="line">            self.reorder_dict = &#123;&#125;</span><br><span class="line"> </span><br><span class="line">            base_seed = torch.LongTensor(<span class="number">1</span>).random_()[<span class="number">0</span>]</span><br><span class="line">            self.workers = [</span><br><span class="line">                multiprocessing.Process(</span><br><span class="line">                    target=_worker_loop,</span><br><span class="line">                    args=(self.dataset, self.index_queue, self.worker_result_queue, self.collate_fn,</span><br><span class="line">                          base_seed + i, self.worker_init_fn, i))</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.num_workers)]</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">if</span> self.pin_memory <span class="keyword">or</span> self.timeout &gt; <span class="number">0</span>:</span><br><span class="line">                self.data_queue = queue.Queue()</span><br><span class="line">                self.worker_manager_thread = threading.Thread(</span><br><span class="line">                    target=_worker_manager_loop,</span><br><span class="line">                    args=(self.worker_result_queue, self.data_queue, self.done_event, self.pin_memory,</span><br><span class="line">                          torch.cuda.current_device()))</span><br><span class="line">                self.worker_manager_thread.daemon = <span class="literal">True</span></span><br><span class="line">                self.worker_manager_thread.start()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.data_queue = self.worker_result_queue</span><br><span class="line"> </span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> self.workers:</span><br><span class="line">                w.daemon = <span class="literal">True</span>  <span class="comment"># ensure that the worker exits on process exit</span></span><br><span class="line">                w.start()</span><br><span class="line"> </span><br><span class="line">            _update_worker_pids(<span class="built_in">id</span>(self), <span class="built_in">tuple</span>(w.pid <span class="keyword">for</span> w <span class="keyword">in</span> self.workers))</span><br><span class="line">            _set_SIGCHLD_handler()</span><br><span class="line">            self.worker_pids_set = <span class="literal">True</span></span><br><span class="line"> </span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span> * self.num_workers):</span><br><span class="line">                self._put_indices()</span><br><span class="line">                </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__next__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.num_workers == <span class="number">0</span>:  <span class="comment"># 如果是单线程</span></span><br><span class="line">            indices = <span class="built_in">next</span>(self.sample_iter) <span class="comment"># 生成一个批次数据的索引</span></span><br><span class="line">            batch = self.collate_fn([self.dataset[i] <span class="keyword">for</span> i <span class="keyword">in</span> indices]) <span class="comment"># 用collate_fn将这些数据打包成一个长度为2的list</span></span><br><span class="line">            <span class="keyword">if</span> self.pin_memory:</span><br><span class="line">                batch = pin_memory_batch(batch)</span><br><span class="line">            <span class="keyword">return</span> batch <span class="comment"># 返回这个批次数据</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 后面都是多线程了</span></span><br><span class="line">        <span class="keyword">if</span> self.rcvd_idx <span class="keyword">in</span> self.reorder_dict:</span><br><span class="line">            batch = self.reorder_dict.pop(self.rcvd_idx)</span><br><span class="line">            <span class="keyword">return</span> self._process_next_batch(batch)</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> self.batches_outstanding == <span class="number">0</span>:</span><br><span class="line">            self._shutdown_workers()</span><br><span class="line">            <span class="keyword">raise</span> StopIteration</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">assert</span> (<span class="keyword">not</span> self.shutdown <span class="keyword">and</span> self.batches_outstanding &gt; <span class="number">0</span>)</span><br><span class="line">            idx, batch = self._get_batch()</span><br><span class="line">            self.batches_outstanding -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> idx != self.rcvd_idx:</span><br><span class="line">                self.reorder_dict[idx] = batch</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">return</span> self._process_next_batch(batch)     </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_get_batch</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self.timeout &gt; <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">return</span> self.data_queue.get(<span class="literal">True</span>, self.timeout)</span><br><span class="line">            <span class="keyword">except</span> queue.Empty:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(<span class="string">&#x27;DataLoader timed out after &#123;&#125; seconds&#x27;</span>.<span class="built_in">format</span>(self.timeout))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.data_queue.get()        </span><br><span class="line">        </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">_process_next_batch</span>(<span class="params">self, batch</span>):</span></span><br><span class="line">        self.rcvd_idx += <span class="number">1</span></span><br><span class="line">        self._put_indices()</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(batch, ExceptionWrapper):</span><br><span class="line">            <span class="keyword">raise</span> batch.exc_type(batch.exc_msg)</span><br><span class="line">        <span class="keyword">return</span> batch</span><br><span class="line">    </span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">_put_indices</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> self.batches_outstanding &lt; <span class="number">2</span> * self.num_workers</span><br><span class="line">        indices = <span class="built_in">next</span>(self.sample_iter, <span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> indices <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        self.index_queue.put((self.send_idx, indices))</span><br><span class="line">        self.batches_outstanding += <span class="number">1</span></span><br><span class="line">        self.send_idx += <span class="number">1</span>    </span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>HDU7047 Link With Balls</title>
    <url>/2021/08/10/HDU7047-Link-With-Balls/</url>
    <content><![CDATA[<center>
组合数学，思维
</center>
<span id="more"></span>
<h3 id="题目描述">题目描述</h3>
<p>There were a lot of balls in the factory of Ball Illusion
Technology(BIT). Link, a boy, went there to get some balls, but
suddenly, he found that there were too many ways to get balls.</p>
<p>There are <span class="math inline">\(2n\)</span>​​ buckets in the
factory. Link may get <span class="math inline">\(kx\)</span>​​ balls
from the <span class="math inline">\(2x-1^{th}\)</span>​ ​bucket, where
$k $ ​​is a non-negtive integer. He may also get at most <span
class="math inline">\(x\)</span>​ balls from the <span
class="math inline">\(2x^{th}\)</span>​ ​bucket.</p>
<p>Link wanted to get <span class="math inline">\(m\)</span>​ balls, and
he wondered how many ways there were to take out exactly <span
class="math inline">\(m\)</span> balls. While Link is calculating the
answer, he wants you to calculate it as well, and you should output the
answer modulo <span class="math inline">\(10^9+7\)</span>.</p>
<h3 id="输入">输入</h3>
<p>The input consists of multiple test cases.</p>
<p>The first line contains an integer <span class="math inline">\(T
(1≤T≤10^5)\)</span>​​ -- the number of test cases.</p>
<p>Each test case contains two integers <span
class="math inline">\(n\)</span>​ and <span
class="math inline">\(m\)</span><span
class="math inline">\((1≤n,m≤10^6)\)</span>​.</p>
<h3 id="输出">输出</h3>
<p>For each test case, print the answer modulo <span
class="math inline">\(10^9+7\)</span> in a single line.</p>
<h3 id="中文题意">中文题意</h3>
<p>有<span class="math inline">\(2n\)</span>个篮子，对于偶数篮子<span
class="math inline">\(2x\)</span>，可以任意从中取不超过<span
class="math inline">\(x\)</span>个球。对于奇数篮子<span
class="math inline">\(2x-1\)</span>，只能取<span
class="math inline">\(kx\)</span>个球，其中<span class="math inline">\(k
\geq 0\)</span>。问从中取出<span
class="math inline">\(m\)</span>个球的方案数。</p>
<h3 id="题解">题解</h3>
<p>比赛的时候将奇数偶数分开考虑了，导致不能在规定时间内求出答案。</p>
<p>将可以取<span class="math inline">\(0\sim
k-1\)</span>​​个球的篮子，与能取<span
class="math inline">\(k\)</span>的倍数个球的篮子合并，合并之后的篮子能取任意多的球，并且方案唯一。</p>
<p>这时得到了<span
class="math inline">\(n\)</span>个可以取任意个球的篮子，还有一个可以取<span
class="math inline">\(0\sim n\)</span>​​个球的篮子。​​</p>
<p>于是枚举<span class="math inline">\(0\sim
n\)</span>的篮子中取了多少球，剩下取的球可以用插板法。</p>
<p>答案就是<span
class="math inline">\(\sum_{i=0}^{n}C_{m-i+n-1}^{n-1}\)</span>​，即为<span
class="math inline">\(C_{m+n}^{n}-C_{m-1}^{n}\)</span>​。</p>
<h3 id="代码">代码</h3>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> int long long</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> mod = <span class="number">1e9</span> + <span class="number">7</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ksm</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> res = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span>(y) &#123;</span><br><span class="line">        <span class="keyword">if</span> (y &amp; <span class="number">1</span>) res = res * x % mod;</span><br><span class="line">        x = x * x % mod;</span><br><span class="line">        y &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> fac[<span class="number">2000006</span>], inv[<span class="number">2000005</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">C</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span> m)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; m) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> fac[n] * inv[m] % mod * inv[n-m] % mod;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">signed</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    fac[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">2000000</span>; i ++) fac[i] = fac[i - <span class="number">1</span>] * i  % mod;</span><br><span class="line">    inv[<span class="number">2000000</span>] = <span class="built_in">ksm</span>(fac[<span class="number">2000000</span>], mod - <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1999999</span>; i &gt;= <span class="number">0</span>; i --)</span><br><span class="line">        inv[i] = inv[i + <span class="number">1</span>] * (i + <span class="number">1</span>) % mod;</span><br><span class="line">    <span class="keyword">int</span> T;</span><br><span class="line">    cin &gt;&gt; T;</span><br><span class="line">    <span class="keyword">int</span> n, m;</span><br><span class="line">    <span class="keyword">while</span>(T--) &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%lld%lld&quot;</span>, &amp;n, &amp;m);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%lld\n&quot;</span>, ((<span class="built_in">C</span>(m+n, n) - <span class="built_in">C</span>(m<span class="number">-1</span>, n)) % mod + mod) % mod);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Algorithm</category>
        <category>Solutions</category>
      </categories>
      <tags>
        <tag>题解</tag>
        <tag>组合数学</tag>
      </tags>
  </entry>
  <entry>
    <title>Diary 2021.8</title>
    <url>/2021/08/04/Diary-2021-8/</url>
    <content><![CDATA[<h2 id="section">8.4</h2>
<p>今天休息，起床就下午了...然后搭了一天博客，初见成效。</p>
<p>明天再看看怎么装修吧。</p>
<p>昨天本来搭得差不多了，渲染的时候被自己给搞崩了，今天重新来的....</p>
<span id="more"></span>
<h3 id="section-1">8.7</h3>
<p>今天下午队伍自己找了套题做，演了一下午。</p>
<p>晚上继续配置博客。</p>
<p>弄好了分类里的子分类404问题，原来要在父分类里加一篇文章才行。</p>
<p>搞了文章隐藏功能，并没有用插件。</p>
<p>美化了文章分割线。</p>
<p>增加了Note功能。</p>
<p>修改了代码的tab_size。</p>
<p>添加了评论功能。</p>
<p>明天再加一个置顶功能，博客就快大功告成了。</p>
]]></content>
      <categories>
        <category>Life</category>
        <category>Diary</category>
      </categories>
      <tags>
        <tag>Diary</tag>
      </tags>
  </entry>
  <entry>
    <title>test</title>
    <url>/2021/08/06/test/</url>
    <content><![CDATA[<div class="hbe hbe-container" id="hexo-blog-encrypt" data-wpm="看起来不太对哦" data-whm="OOPS, these decrypted content may changed, but you can still have a look.">
  <script id="hbeData" type="hbeData" data-hmacdigest="f0cfef0a20b659adc697669f67c2734c34b659900fb9c3bca307dd12d7bd39f3">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</script>
  <div class="hbe hbe-content">
    <div class="hbe hbe-input hbe-input-default">
      <input class="hbe hbe-input-field hbe-input-field-default" type="password" id="hbePass">
      <label class="hbe hbe-input-label hbe-input-label-default" for="hbePass">
        <span class="hbe hbe-input-label-content hbe-input-label-content-default">输入密码哦(123)</span>
      </label>
    </div>
  </div>
</div>
<script data-pjax src="/lib/hbe.js"></script><link href="/css/hbe.style.css" rel="stylesheet" type="text/css">]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2021/08/03/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very
first post. Check <a href="https://hexo.io/docs/">documentation</a> for
more info. If you get any problems when using Hexo, you can find the
answer in <a
href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or
you can ask me on <a
href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<span id="more"></span>
<h2 id="quick-start">Quick Start</h2>
<h3 id="create-a-new-post">Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server">Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files">Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites">Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a
href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>交叉熵</title>
    <url>/2022/01/26/%E4%BA%A4%E5%8F%89%E7%86%B5/</url>
    <content><![CDATA[<p><strong>信息量</strong>定义<span
class="math inline">\(f(x)=-log_2x\)</span>，表明信息量的多少，x是概率，通俗来说概率越小信息量越大。</p>
<p><strong>熵</strong>的定义是信息量的期望，即<span
class="math inline">\(H(P)=\sum _{i=1}^{m}p_i*f(p_i)\)</span></p>
<p><strong>相对熵(KL散度)</strong>是两个系统“差距”，
比如以P为基准，与Q相差多少：<span
class="math inline">\(D_{KL}(P||Q)=\sum_{i=1}^{m}p_i*(f_Q(q_i)-f_p(p_i))=\sum_{i=1}^{m}p_i*(-log_2q_i)-\sum_{i=1}^{m}p_i(-log_2p_i)\)</span></p>
<p>后面一项是P的熵，前面一项是P与Q的交叉熵</p>
<p><strong>交叉熵</strong> <span class="math inline">\(H(P,
Q)=\sum_{i=1}^{m}p_i(-log_2q_i)=-\sum_{i=1}^{n}(y_ilog_2\hat{y_i}+(1-y_i)log_2(1-\hat{y_i}))\)</span></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>博客中Note的使用方法</title>
    <url>/2021/08/07/%E5%8D%9A%E5%AE%A2%E4%B8%ADNote%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<center>
Markdown里Note的使用方法
</center>
<span id="more"></span>
<h3 id="配置">配置</h3>
<p>打开主题的_config.yml</p>
<p>修改配置为</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"># Note tag (bs-callout)</span><br><span class="line">note:</span><br><span class="line">  # Note tag style values:</span><br><span class="line">  #  - simple    bs-callout old alert style. Default.</span><br><span class="line">  #  - modern    bs-callout new (v2-v3) alert style.</span><br><span class="line">  #  - flat      flat callout style with background, like on Mozilla or StackOverflow.</span><br><span class="line">  #  - disabled  disable all CSS styles import of note tag.</span><br><span class="line">  style: flat</span><br><span class="line">  icons: false</span><br><span class="line">  # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6).</span><br><span class="line">  # Offset also applied to label tag variables. This option can work with disabled note tag.</span><br><span class="line">  light_bg_offset: 0</span><br><span class="line">  border_radius: 3</span><br></pre></td></tr></table></figure>
<p>其中style是note的风格</p>
<h3 id="在markdown中使用方法">在markdown中使用方法</h3>
<figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">&#123;% note class<span class="emphasis">_name %&#125;内容&#123;% endnote %&#125;</span></span><br></pre></td></tr></table></figure>
<p>其中class_name可以是</p>
<ul>
<li>default</li>
<li>primary</li>
<li>success</li>
<li>info</li>
<li>warning</li>
<li>danger</li>
</ul>
<p>效果分别为</p>
<p><img
src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL0phbmtpbmdXb24vSmFua2luZ1dvbi5naXRodWIuaW8vbWFzdGVyLzIwMTkvaGV4b25vdGUvMTU0NzY2Mzk2MTcxMy5wbmc?x-oss-process=image/format,png" /></p>
]]></content>
      <categories>
        <category>Other</category>
      </categories>
  </entry>
  <entry>
    <title>没有代码的题解们</title>
    <url>/2021/11/03/%E6%B2%A1%E6%9C%89%E4%BB%A3%E7%A0%81%E7%9A%84%E9%A2%98%E8%A7%A3%E4%BB%AC/</url>
    <content><![CDATA[<center>
一些题目的思路
</center>
<span id="more"></span>
<h3 id="cf980d-perfect-groups">CF980D Perfect Groups</h3>
<p><strong>分类：</strong></p>
<p>[数学，思维]</p>
<p><strong>题意：</strong></p>
<p><img src="https://i.loli.net/2021/11/03/ipqUDS7CvhPxYVm.png" /></p>
<p><strong>思路：</strong></p>
<p>首先想到，往一个组内添加一个新元素会有什么性质。</p>
<p>假设组内原有数中有<span class="math inline">\(a\)</span>和<span
class="math inline">\(b\)</span>，并且有<span
class="math inline">\(a\times b=k_1^2\)</span>，对于新考虑的数<span
class="math inline">\(c\)</span>，<span
class="math inline">\(c\)</span>跟<span
class="math inline">\(b\)</span>的关系是<span
class="math inline">\(b\times c=k_2^2\)</span>，那么可以得到<span
class="math inline">\(a\times c=\frac{b^2}{k_1^2\times
k_2^2}\)</span>，即<span class="math inline">\(a\)</span>和<span
class="math inline">\(c\)</span>相乘也是平方数。</p>
<p>于是对于一个连续的序列，我们直接用一个并查集维护连通块即可。</p>
<p>中间会有一些细节，比如0.</p>
]]></content>
      <categories>
        <category>Algorithm</category>
        <category>Solutions</category>
      </categories>
      <tags>
        <tag>题解</tag>
      </tags>
  </entry>
  <entry>
    <title>代数系统笔记</title>
    <url>/2021/12/06/%E4%BB%A3%E6%95%B0%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>离散数学——代数系统</p>
<span id="more"></span>
<p>[TOC]</p>
<h3 id="代数系统">代数系统</h3>
<h4 id="二元运算及其性质">二元运算及其性质</h4>
<blockquote>
<p><strong>定义</strong> <strong>设<span
class="math inline">\(S\)</span>是一个非空集合，映射<span
class="math inline">\(f:S^n\rightarrow S\)</span>称为<span
class="math inline">\(S\)</span>上的一个n元运算。</strong></p>
</blockquote>
<p>n元运算可以看作n+1元关系。</p>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设"<span
class="math inline">\(\cdot\)</span>"是定义在集合<span
class="math inline">\(S\)</span>上的二元运算，如果</strong></p>
<ul>
<li><span class="math inline">\(\forall x, y \in S\)</span>, <span
class="math inline">\(x\cdot y \in S\)</span>,则称"<span
class="math inline">\(\cdot\)</span>"在S上是<strong>封闭的</strong></li>
<li><span class="math inline">\(\forall x, y\in S\)</span>, <span
class="math inline">\(x\cdot y=y\cdot x\)</span>,则称"<span
class="math inline">\(\cdot\)</span>"在S上是<strong>可交换的</strong></li>
<li><span class="math inline">\(\forall x, y, z\in S\)</span>, <span
class="math inline">\(x\cdot (y\cdot z)=(x\cdot y)\cdot
z\)</span>,则称"<span
class="math inline">\(\cdot\)</span>"在S上是<strong>可结合的</strong></li>
<li><span class="math inline">\(\forall x\in S\)</span>, <span
class="math inline">\(x\cdot x=x\)</span>,则称"<span
class="math inline">\(\cdot\)</span>"是<strong>幂等的</strong>。</li>
</ul>
</blockquote>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(\cdot\)</span>和<span
class="math inline">\(*\)</span>是同时定义在<span
class="math inline">\(S\)</span>上的两个二元运算。如果</strong></p>
<ul>
<li><span class="math inline">\(\forall x, y, z\in S, x*(y\cdot
z)=(x*y)\cdot(x*z)且(y\cdot
z)*x=(y*x)\cdot(z*x)\)</span>，则称运算*关于<strong>·</strong>是<strong>可分配的</strong>。</li>
<li>*和<span class="math inline">\(\cdot\)</span> 是可换运算，且<span
class="math inline">\(\forall x, y\in S, x*(x\cdot
y)=x及x\cdot(x*y)=x\)</span>，则称运算*和<strong>·</strong>满足<strong>吸收律</strong></li>
</ul>
</blockquote>
<h4 id="代数系统的定义与特异元">代数系统的定义与特异元</h4>
<blockquote>
<p><strong>定义</strong>
<strong>一个==非空集合==S连同若干个定义在S上的运算<span
class="math inline">\(f_1, f_2,
...,f_k\)</span>所组成的系统称为一个==代数系统==，记为<span
class="math inline">\(&lt;S,f_1,f_2,...,f_k&gt;\)</span></strong></p>
</blockquote>
<ul>
<li><p>判断集合S及其上的代数运算是否是代数系统的关键是</p>
<ol type="1">
<li><p>集合S<strong>非空</strong></p></li>
<li><p>这些运算是否满足<strong>封闭性</strong></p></li>
</ol></li>
</ul>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是一个代数系统，则</strong></p>
<ul>
<li><strong>如果<span class="math inline">\(\exist e\in
S\)</span>使<span class="math inline">\(\forall x\in S, e\cdot x=x\cdot
e=x\)</span>，则称e为代数系统的==幺元（单位元）==</strong></li>
<li><strong>如果存在<span class="math inline">\(\theta \in
S\)</span>，使<span class="math inline">\(\forall x\in S, \theta \cdot
x=x\cdot \theta=\theta\)</span>，则称<span
class="math inline">\(\theta\)</span>为代数系统的==零元==</strong></li>
<li><strong><span class="math inline">\(a\in S\)</span>，如果<span
class="math inline">\(a\cdot a=a\)</span>，则称<span
class="math inline">\(a\)</span>时系统的==幂等元==</strong></li>
</ul>
</blockquote>
<blockquote>
<p><strong>定义</strong> <strong>设在代数系统$&lt;S, $<span
class="math inline">\(~~\cdot~\)</span>&gt;中，<span
class="math inline">\(e\)</span>是幺元，<span
class="math inline">\(a\)</span>是S中的一个元素。如果存在<span
class="math inline">\(b\in S\)</span>使得<span
class="math inline">\(a\cdot b=b\cdot a=e\)</span>，则称<span
class="math inline">\(b\)</span>是<span
class="math inline">\(a\)</span>的==逆元==，记为<span
class="math inline">\(b=a^{-1}\)</span></strong></p>
</blockquote>
<p>在一个代数系统中，不是每个元都存在着逆元。</p>
<blockquote>
<p><strong>定理</strong> <strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是一个代数系统。如果存在幺元，则幺元是==唯一的==；如果存在零元，则零元是==唯一的==；如果元a有逆元，且"<span
class="math inline">\(~\cdot~\)</span>"==可结合==，则逆元是==唯一的==。</strong></p>
</blockquote>
<p>证明：反证法即可（设不唯一）。</p>
<p>根据运算满足的条件，可以把含单个二元运算的代数系统进行分层。</p>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是一个代数系统，则</strong></p>
<ul>
<li><strong>当"<span
class="math inline">\(\cdot\)</span>"是封闭的，称<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>为==广群==</strong></li>
<li><strong>如果<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是广群，且"<span
class="math inline">\(\cdot\)</span>"是==可结合运算==，则称<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>是==半群==</strong></li>
<li><strong>如果<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是半群，且存在幺元，则称<span
class="math inline">\(&lt;S,
\cdot&gt;\)</span>为==含幺半群==</strong></li>
<li><strong>如果<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是含幺半群，且每个元素都有逆元，则称<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>为==群==</strong></li>
</ul>
</blockquote>
<p>群的条件：闭，结，幺，逆</p>
<p>（没必要在代数系统是否要求有封闭性上花费太大心思，不同教材不同，在这里要求代数系统要有封闭性）</p>
<h3 id="半群与群">半群与群</h3>
<h4 id="半群">半群</h4>
<p>例：</p>
<ul>
<li><span class="math inline">\(&lt;S,
\cdot&gt;\)</span>满足封闭、可结合、有幺元0，所以是含幺半群。还满足可换性，每个元都有逆元，因此也是<strong>可换群</strong></li>
</ul>
<p>​ <span class="math inline">\(&lt;S,
\times&gt;\)</span>满足封闭、可结合、有幺元1，因此是含幺半群。但0无逆元，所以不是群。</p>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是半群，<span class="math inline">\(a\in
S\)</span>，n是正整数，约定符号<span
class="math inline">\(a^n\)</span>表示n个a在运算"<span
class="math inline">\(\cdot\)</span>"下的结果，可递归定义如下：</strong></p>
<ol type="1">
<li><strong><span class="math inline">\(a^1=a\)</span></strong></li>
<li><strong><span class="math inline">\(a^{n+1}=a^n\cdot
a\)</span></strong></li>
</ol>
<p><strong>当<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是含幺半群，e是幺元时，可以把归纳基础改为<span
class="math inline">\(a^0=e\)</span></strong></p>
</blockquote>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是半群，<span class="math inline">\(a\in
S\)</span>，m和m是正整数，则</strong></p>
<ol type="1">
<li><strong><span class="math inline">\(a^m\cdot
a^n=a^{n+m}\)</span></strong></li>
<li><strong><span
class="math inline">\((a^m)^n=a^{mn}\)</span></strong></li>
</ol>
<p><strong>当<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是含幺半群时，上述结论对任意非负整数m和n都成立</strong></p>
</blockquote>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是一个半群，如果S是==有限集==，则必有<span
class="math inline">\(a\in S\)</span>使得<span
class="math inline">\(a^2=a\)</span>。</strong></p>
</blockquote>
<p>证明:</p>
<p>任取<span class="math inline">\(b\in
S\)</span>，因为S是有限集，则元素<span class="math inline">\(b^1,
b^2,...\)</span>中必定有两个一样的，设为<span class="math inline">\(b^i,
b^j\)</span>，设<span class="math inline">\(i&lt;j\)</span>，所以<span
class="math inline">\(b^i=b^{j-i}\cdot b^i\)</span>，所以对于任意的<span
class="math inline">\(t \ge i\)</span>，都有<span
class="math inline">\(b^t=b^{j-i}\cdot
b^t\)</span>，反复迭代可以得到<span
class="math inline">\(b^t=b^{k(j-i)}\cdot b^t\)</span>，取<span
class="math inline">\(k\)</span>使得<span
class="math inline">\(k(j-i)\ge i\)</span>，同时令<span
class="math inline">\(t=k(j-i)\)</span>，则<span
class="math inline">\(b^t\)</span>是幂等元。</p>
<p>含幺半群至少有一个幂等元，即幺元。</p>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是一个半群，==非空集合==<span class="math inline">\(A
\subseteq S\)</span>，并且<span class="math inline">\(&lt;A,
\cdot&gt;\)</span>也是半群，则称<span class="math inline">\(&lt;A,
\cdot&gt;\)</span>是<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>的==子半群==</strong>。</p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>是一个含幺半群，==非空集合==<span
class="math inline">\(A \subseteq S\)</span>，并且<span
class="math inline">\(&lt;A, \cdot&gt;\)</span>也是含幺半群，则称<span
class="math inline">\(&lt;A, \cdot&gt;\)</span>是<span
class="math inline">\(&lt;S,
\cdot&gt;\)</span>的==含幺子半群==</strong>。</p>
</blockquote>
<p>要证明<span class="math inline">\(&lt;A,
\cdot&gt;\)</span>是半群<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>的子半群时，只需证明<span
class="math inline">\(A\)</span>非空，<span
class="math inline">\(A\subseteq S\)</span>并且运算"<span
class="math inline">\(\cdot\)</span>"在集合A内是封闭的。</p>
<h4 id="群和子群">群和子群</h4>
<p>例：</p>
<ul>
<li><span class="math inline">\(&lt;Z,+&gt;\)</span>整数加群，<span
class="math inline">\(&lt;R,+&gt;\)</span>实数加群，<span
class="math inline">\(&lt;Q,+&gt;\)</span>有理数加群。</li>
</ul>
<p>​ <span class="math inline">\(&lt;Z,\times&gt;\)</span>不是群，<span
class="math inline">\(&lt;R-\{0\},\times&gt;\)</span>是实数乘群。</p>
<ul>
<li><p>设<span
class="math inline">\(Z_k\)</span>表示整数集Z上的模k剩余类集合，即<span
class="math inline">\(Z_k=\{[0],[1],[2],..,[k-1]\}\)</span></p>
<p><span
class="math inline">\(&lt;Z_k,\bigoplus&gt;\)</span>是<strong>剩余类加群</strong>，[0]是幺元，
每元[i]的逆元是[k-i]</p>
<p><span
class="math inline">\(&lt;Z_k,\bigotimes&gt;\)</span>不是群，因为[0]无逆元。</p>
<p>而<span
class="math inline">\(&lt;Z_k-\{[0]\},\bigotimes&gt;\)</span>，也<strong>不一定</strong>是群。如<span
class="math inline">\(&lt;Z_4-\{[0]\}，\bigotimes&gt;\)</span>不是群（不封闭），但<span
class="math inline">\(&lt;Z_5-\{[0]\}，\bigotimes&gt;\)</span>是群。</p>
<p>当k是<strong>素数</strong>的时候，<span
class="math inline">\(&lt;Z_k-\{[0]\},\bigotimes&gt;\)</span>一定是群。</p></li>
<li><p>设n个元素的集合A上的全体置换构成集合<span
class="math inline">\(S_n\)</span>。则<span
class="math inline">\(&lt;S_n,\circ&gt;\)</span>构成群，称为<strong>n次对称群</strong></p></li>
</ul>
<p>==群中元素的个数称为群的阶==</p>
<p>群也可以用别的形式等价定义</p>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>如果<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>是==半群==，并且对于任意<span class="math inline">\(a,
b\in G\)</span>，都存在<span class="math inline">\(x, y\in
G\)</span>，使<span class="math inline">\(x\cdot a=b,a\cdot
y=b\)</span>，则<span
class="math inline">\(&lt;G,\cdot&gt;\)</span>是群。</strong></p>
</blockquote>
<p>证明：先证明有幺元，再证明每元都有逆。</p>
<ol type="1">
<li><p>设<span class="math inline">\(a\in G\)</span>，方程<span
class="math inline">\(x\cdot a=a\)</span>的解为<span
class="math inline">\(e_1\)</span>，那么对于任何<span
class="math inline">\(t\in G\)</span>，都有<span
class="math inline">\(e_1\cdot t=t\)</span></p>
<p>证明：设方程<span class="math inline">\(a\cdot
y=t\)</span>的解为<span class="math inline">\(y_0\)</span></p>
<p>​ 于是有<span class="math inline">\(e_1\cdot t=e_1\cdot (a\cdot
y_0)=(e_1\cdot a)\cdot y_0=a\cdot y_0=t\)</span></p>
<p>所以<span class="math inline">\(e_1\)</span>是<span
class="math inline">\(G\)</span>中的左幺元，同理<span
class="math inline">\(G\)</span>中的右幺元是<span
class="math inline">\(e_2\)</span></p>
<p>所以<span class="math inline">\(G\)</span>中有幺元<span
class="math inline">\(e\)</span>。（一个代数系统中幺元是唯一的）</p></li>
<li><p>同理，对任意<span class="math inline">\(b\in
G\)</span>，方程<span class="math inline">\(x\cdot b=e\)</span>有解<span
class="math inline">\(x_0\)</span>， 则<span
class="math inline">\(x_0\)</span>是b的左逆元。</p>
<p><span class="math inline">\(b\cdot y=t\)</span>有解<span
class="math inline">\(y_0\)</span>，是b的右逆元。从而b有逆元。（可结合的运算的代数系统每元的逆是唯一的）</p></li>
</ol>
<p>这个定理说明：在群的定义中，幺元的条件可以用存在左幺元（或右幺元）替代，逆元的条件可以用存在左逆元（右逆元）替代。</p>
<blockquote>
<p><strong>定理</strong> <strong>在群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>中==消去律成立==，即如果<span
class="math inline">\(a\cdot b=a\cdot c\)</span>，必有<span
class="math inline">\(b=c\)</span></strong></p>
</blockquote>
<p>证明：<span class="math inline">\(a^{-1}\cdot a\cdot b=a^{-1}\cdot
a\cdot c\\b=c\)</span></p>
<blockquote>
<p><strong>推论</strong>1 <strong>群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的运算表中每行和每列都没有重复元素</strong></p>
<p><strong>推论</strong>2 <strong>群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>除幺元外无其他幂等元</strong></p>
</blockquote>
<blockquote>
<p><strong>定理</strong> 设<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>是群，<span class="math inline">\(a\in
G\)</span>，构造映射<span class="math inline">\(\varphi_a:G\to
G\)</span>，使得对任意<span class="math inline">\(x\in G\)</span>，<span
class="math inline">\(\varphi _a(x)=a\cdot x\)</span>，令<span
class="math inline">\(H = \{\varphi _a|a \in
G\}\)</span>，则对于函数的复合运算"<span
class="math inline">\(\circ\)</span>"，<span
class="math inline">\(&lt;H,\circ&gt;\)</span>是群。</p>
</blockquote>
<p>按闭结幺逆证明即可。</p>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>是群，<span class="math inline">\(S\)</span>是<span
class="math inline">\(G\)</span>的==非空子集==。如果<span
class="math inline">\(&lt;G, \cdot&gt;\)</span>也是群，则称<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>是<span
class="math inline">\(&lt;G, \cdot&gt;\)</span>的子群。</strong></p>
</blockquote>
<p>任意群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>都有两个天然子群，即它本身和幺元子群<span
class="math inline">\(&lt;\{e\},\cdot&gt;\)</span>，被称为平凡子群，其他情况的子群称为真子群。</p>
<p>此外，由群中一个元素，也可生成一个子群，为此，需要把群中元素的幂扩充到负指数的情形，即定义<span
class="math inline">\(a^{-k}=(a^k)^{-1}\)</span></p>
<blockquote>
<p><strong>定理</strong></p>
<p>设<span class="math inline">\(&lt;G, \cdot&gt;\)</span>是群，<span
class="math inline">\(\forall x\in G\)</span>，记<span
class="math inline">\(S=\{a^n|n\in Z\}\)</span>，则<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>是<span
class="math inline">\(&lt;G, \cdot&gt;\)</span>的子群。</p>
</blockquote>
<p>把由群的一个元素<span
class="math inline">\(a\)</span>生成的子群记为<span
class="math inline">\((a)\)</span></p>
<blockquote>
<p><strong>定理</strong> <strong>子群的幺元与群的幺元相同；对任意<span
class="math inline">\(a\in S\)</span>，<span
class="math inline">\(a\)</span>在<span
class="math inline">\(S\)</span>中的逆元就是<span
class="math inline">\(a\)</span>在<span
class="math inline">\(G\)</span>中的逆元</strong></p>
</blockquote>
<p>判别子群的方法：</p>
<blockquote>
<p><strong>定理 设<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>是群，<span class="math inline">\(S\)</span>是<span
class="math inline">\(G\)</span>的==非空子集==。<span
class="math inline">\(&lt;S,\cdot&gt;\)</span>是<span
class="math inline">\(&lt;G,
\cdot&gt;\)</span>的子群，当且仅当对于任何<span class="math inline">\(a,
b\in S\)</span>，<span class="math inline">\(a\cdot b^{-1}\in
S\)</span></strong></p>
</blockquote>
<p>证明：</p>
<ol type="1">
<li><p>充分性：显然（闭，结，幺，逆）</p></li>
<li><p>必要性：</p>
<p>当<span class="math inline">\(a=b\)</span>时，由题意知<span
class="math inline">\(a\cdot a^{-1}=e\in
S\)</span>，所以S中存在幺元。</p>
<p>令<span class="math inline">\(a=e\)</span>，那么当<span
class="math inline">\(b\in S\)</span>时，必有<span
class="math inline">\(e\cdot b^{-1}=b^{-1}\in
S\)</span>，所以S中每元都有逆。</p>
<p>当<span class="math inline">\(a,b\in S\)</span>时，由于<span
class="math inline">\(b^{-1}\in S\)</span>，就有<span
class="math inline">\(a\cdot b = a\cdot (b^{-1})^{-1} \in
S\)</span>，所以满足封闭性。</p></li>
</ol>
<p>可以证明：当<span
class="math inline">\(G\)</span>是有限集的时候，判别<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>是否是<span
class="math inline">\(&lt;G, \cdot&gt;\)</span>的子群，只判别在<span
class="math inline">\(S\)</span>中是否封闭就行了。</p>
<h4 id="交换群和循环群">交换群和循环群</h4>
<blockquote>
<p><strong>定义</strong> <strong>如果群<span
class="math inline">\(&lt;G,
\cdot&gt;\)</span>的运算==满足交换率==，则称群<span
class="math inline">\(G\)</span>为==交换群（Abel群）==。</strong></p>
</blockquote>
<p>交换群又常被成为<strong>加群</strong></p>
<blockquote>
<p><strong>定理</strong> <strong>群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>为交换群的==充要条件==是：对任意<span
class="math inline">\(a,b\in G\)</span>，<span
class="math inline">\((a\cdot b)^2=a^2\cdot b^2\)</span></strong></p>
</blockquote>
<p>在交换群中，循环群有特殊地位</p>
<p>（循环群都是交换群）</p>
<blockquote>
<p><strong>定义</strong> <strong>如果群<span
class="math inline">\(&lt;G, \cdot&gt;\)</span>中存在一个元<span
class="math inline">\(a\)</span>，是的<span
class="math inline">\(G\)</span>能由<span
class="math inline">\(a\)</span>生成，即<span
class="math inline">\(G=(a)\)</span>，则称<span
class="math inline">\(G\)</span>为==循环群==，称<span
class="math inline">\(a\)</span>是<span
class="math inline">\(G\)</span>的一个==生成元==。</strong></p>
</blockquote>
<p><span class="math inline">\(G = \{a^k|k \in G\}\)</span></p>
<blockquote>
<p><strong>定义</strong> <strong>设<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>是群，<span class="math inline">\(a\in
G\)</span>，使得<span
class="math inline">\(a^n=e\)</span>的==最小正整数<span
class="math inline">\(n\)</span>==为元素<span
class="math inline">\(a\)</span>的周期。如果不存在这种最小正整数，则称<span
class="math inline">\(a\)</span>的周期为<span
class="math inline">\(\infty\)</span></strong></p>
</blockquote>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>设群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>中元素<span
class="math inline">\(a\)</span>的周期为正整数<span
class="math inline">\(n\)</span>，则：</strong></p>
<ul>
<li><strong><span class="math inline">\(a^m=e\)</span>，当且仅当<span
class="math inline">\(n|m\)</span></strong></li>
<li><strong><span class="math inline">\(a^i=a^j\)</span>，当且仅当<span
class="math inline">\(n|(i-j)\)</span></strong></li>
<li><strong>由<span
class="math inline">\(a\)</span>生成的子群恰好有n个元素。</strong></li>
</ul>
</blockquote>
<p><strong>有限群的每个元素周期都是有限数。</strong></p>
<p>循环群的任何子群都是循环群。</p>
<h4 id="陪集与拉格朗日定理">陪集与拉格朗日定理</h4>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;H,
\cdot&gt;\)</span>是群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的一个子群，<span class="math inline">\(a\in
G\)</span>，记<span class="math inline">\(aH=\{a\cdot h|h\in
H\}\)</span>，称<span class="math inline">\(aH\)</span>是<span
class="math inline">\(H\)</span>在<span
class="math inline">\(G\)</span>中关于元<span
class="math inline">\(a\)</span>的==左陪集==。称<span
class="math inline">\(Ha=\{h\cdot a|h\in H\}\)</span>是<span
class="math inline">\(H\)</span>在<span
class="math inline">\(G\)</span>中关于元<span
class="math inline">\(a\)</span>的==右陪集==。由左（右）陪集构成的集合的基数称为==子群的指数==。</strong></p>
</blockquote>
<p><span class="math inline">\(eH=He=H\)</span></p>
<p><span class="math inline">\(\forall x \in G,a\in Ha\)</span></p>
<ul>
<li><p><span
class="math inline">\(H\)</span>关于同一元素的左陪集和右陪集可能不相同</p></li>
<li><p>凡是同属某个左（右）陪集的元素，它们对应的左（右）陪集也相同</p>
<blockquote>
<p><strong>定理 设H是G的子群，<span class="math inline">\(a\in Hb
\Leftrightarrow a\cdot b^{-1}\in H \Leftrightarrow
Ha=Hb\)</span></strong></p>
</blockquote>
<p>证明：</p>
<ol type="1">
<li><p>先证明<span class="math inline">\(a\in Hb \Leftrightarrow a\cdot
b^{-1}\in H\)</span></p>
<ol type="1">
<li><p><span class="math inline">\(a\in Hb,~\therefore a=h\cdot b(h\in
H)\)</span></p>
<p><span class="math inline">\(\therefore a\cdot b^{-1}=h\in
H\)</span>（h有逆元）</p>
<p><span class="math inline">\(\therefore a\in Hb \Rightarrow a\cdot
b^{-1}\in H\)</span></p></li>
<li><p><span class="math inline">\(a\cdot b^{-1}\in H\)</span></p>
<p><span class="math inline">\(\therefore a\cdot b^{-1}=h\in
H\)</span></p>
<p><span class="math inline">\(\therefore a = h\cdot b\in
Hb\)</span></p>
<p><span class="math inline">\(\therefore a\cdot b^{-1}\in H \Rightarrow
a\in Hb\)</span></p></li>
</ol>
<p>所以<span class="math inline">\(a\in Hb \Leftrightarrow a\cdot
b^{-1}\in H\)</span></p></li>
<li><p>再证明<span class="math inline">\(a\cdot b^{-1}\in H
\Leftrightarrow Ha=Hb\)</span></p>
<ol type="1">
<li><p>证明<span class="math inline">\(a\cdot b^{-1}\in H \Rightarrow
Ha=Hb\)</span></p>
<ol type="1">
<li><p><span class="math inline">\(\forall x\in Ha,x=h_1\cdot a(h_1 \in
H)\)</span></p>
<p>又<span class="math inline">\(a\cdot b^{-1}=h_2\in H\)</span></p>
<p><span class="math inline">\(\therefore x=h_1\cdot h_2 \cdot
b=(h_1\cdot h_2)\cdot b \in Hb\)</span></p>
<p><span class="math inline">\(\therefore Ha \subseteq
Hb\)</span></p></li>
<li><p>类似可证明<span class="math inline">\(Hb\subseteq
Ha\)</span></p></li>
</ol>
<p><span class="math inline">\(\therefore Hb=Ha\)</span></p></li>
<li><p>证明：$ Ha=Hbab^{-1}H $</p>
<p>显然</p></li>
</ol></li>
</ol></li>
<li><p>任何两个左（右）陪集要么相同，要么无公共元素</p></li>
<li><p>所有左（右）陪集的元素数目相同</p></li>
</ul>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>设<span class="math inline">\(H\)</span>是群<span
class="math inline">\(G\)</span>的子群，<span class="math inline">\(a,
b\in G\)</span>。在<span
class="math inline">\(G\)</span>中建立二元关系<span
class="math inline">\(aRb\Leftrightarrow b\in aH\)</span>，则<span
class="math inline">\(R\)</span>是<span
class="math inline">\(G\)</span>上的一个等价关系。</strong></p>
</blockquote>
<p>证明：</p>
<ol type="1">
<li>自反的：<span class="math inline">\(a\in aH\)</span>，所以<span
class="math inline">\(aRb\)</span></li>
<li>对称的：如果<span class="math inline">\(aRb\)</span>，即<span
class="math inline">\(b\in aH\)</span>，则<span
class="math inline">\(bH=aH\)</span>，又因为<span
class="math inline">\(a\in aH\)</span>所以<span
class="math inline">\(a\in bH\)</span>，即<span
class="math inline">\(bRa\)</span>，对称性得证</li>
<li>可传递的：设<span
class="math inline">\(aRb,bRc\)</span>，根据定义存在<span
class="math inline">\(h_1,h_2\in H\)</span>，使<span
class="math inline">\(b=a\cdot h_1,c=b\cdot h_2\)</span>，于是<span
class="math inline">\(c=b\cdot h_2=a\cdot h_1\cdot h_2\in
aH\)</span>，所以<span class="math inline">\(aRc\)</span>成立</li>
</ol>
<blockquote>
<p><strong>定理</strong> R是上述等价关系，则<span
class="math inline">\([a]_R=aH\)</span></p>
</blockquote>
<p>等价关系R可以确定群G的一个分划，每个左陪集就是分划中的一个块。<span
class="math inline">\(G=H\cup a_1H\cup a_2H\cup
...\)</span>称为G的左陪集分解式。</p>
<p>同时可以确定G的右陪集分解式<span class="math inline">\(G=H\cup
Ha_1\cup Ha_2\cup ...\)</span></p>
<blockquote>
<p><strong>定理</strong>
<strong>群G中子群H的所有左（右）陪集都是等势的。</strong></p>
</blockquote>
<p>证明：只需证明任何<span class="math inline">\(aH\sim H\)</span>。</p>
<p>​ 构造映射<span class="math inline">\(f:H\to aH\)</span>，对任何<span
class="math inline">\(h\in H,f(h)=a\cdot h\)</span>。这是双射函数。</p>
<blockquote>
<p><strong>定理 拉格朗日定理</strong></p>
<p><strong><span class="math inline">\(n\)</span>阶群<span
class="math inline">\(&lt;G, \cdot&gt;\)</span>的任何子群<span
class="math inline">\(&lt;H, \cdot&gt;\)</span>的阶必定是<span
class="math inline">\(n\)</span>的因子。</strong></p>
</blockquote>
<p>由上述陪集分解式，显然。</p>
<blockquote>
<p><strong>推论</strong> <strong><span
class="math inline">\(n\)</span>元群<span
class="math inline">\(G\)</span>中任何元素的周期必是<span
class="math inline">\(n\)</span>的因子。</strong></p>
</blockquote>
<p>证明：</p>
<p>​ 设<span class="math inline">\(a\in G\)</span>，则<span
class="math inline">\((a)=\{e, a, a^2, ...,
a^{m-1}\}\)</span>是G的一个子群，故<span
class="math inline">\(m|n\)</span>,而<span
class="math inline">\(m\)</span>是元素<span
class="math inline">\(a\)</span>的周期，所以每个元素的周期必是<span
class="math inline">\(n\)</span>的因子。</p>
<h4 id="正规子群与商群">正规子群与商群</h4>
<blockquote>
<p><strong>定义</strong> <strong>设<span class="math inline">\(&lt;H,
\cdot&gt;\)</span>是群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的一个子群。如果对于任何<span
class="math inline">\(a\in G,aH=Ha\)</span>，则称<span
class="math inline">\(H\)</span>是<span
class="math inline">\(G\)</span>的==正规子群（不变子群）==。</strong></p>
</blockquote>
<ul>
<li>任意群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的平凡子群都是G的不变子群</li>
<li>交换群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的任意子群<span class="math inline">\(&lt;H,
\cdot&gt;\)</span>都是G的不变子群</li>
<li>循环群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的任意子群<span class="math inline">\(&lt;H,
\cdot&gt;\)</span>都是G的不变子群</li>
<li>素数阶群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>没有不平凡的不变子群</li>
</ul>
<blockquote>
<p><strong>定理</strong> <strong>群<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>的子群<span class="math inline">\(&lt;H,
\cdot&gt;\)</span>是不变子群，==当且仅当==对任何<span
class="math inline">\(a\in G,aHa^{-1}\subseteq H\)</span></strong></p>
</blockquote>
<p>证明：</p>
<ol type="1">
<li><span class="math inline">\(H\)</span>是<span
class="math inline">\(G\)</span>的正规子群，所以<span
class="math inline">\(aH=Ha\)</span>，即对任何<span
class="math inline">\(h_1\in H\)</span>，必有<span
class="math inline">\(h_2\in H\)</span>，使<span
class="math inline">\(a\cdot h_1=h_2\cdot a\)</span>，即<span
class="math inline">\(a\cdot h_1\cdot a^{-1}=h_2\in
H\)</span>，充分性得证</li>
<li>如果对于任何<span class="math inline">\(a\in G,aHa^{-1}\subseteq
H\)</span>，即对于任何<span class="math inline">\(h_1\in
H\)</span>，都有<span class="math inline">\(h_2\in H\)</span>，是<span
class="math inline">\(a\cdot h_1\cdot a^{-1}=h_2\)</span>，由此可得<span
class="math inline">\(a\cdot h_1=h_2\cdot a\)</span>，由<span
class="math inline">\(h_1,h_2\)</span>的任意性，可得<span
class="math inline">\(aH=Ha\)</span>，必要性得证。</li>
</ol>
<blockquote>
<p><strong>定义</strong> 设<span class="math inline">\(&lt;H,
*&gt;\)</span>是<span class="math inline">\(&lt;G,
*&gt;\)</span>的一个==正规子群==，<span
class="math inline">\(G/H\)</span>表示<span
class="math inline">\(G\)</span>的所有陪集的集合，则<span
class="math inline">\(&lt;G/H,
\cdot&gt;\)</span>是一个群，称为==商群==。其中"<span
class="math inline">\(\cdot\)</span>"定义为<span
class="math inline">\(\forall aH,bH\in G/H,aH\cdot
bH=(a*b)H\)</span></p>
</blockquote>
<h4 id="群的同态与同构">群的同态与同构</h4>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span class="math inline">\(&lt;S,
\cdot&gt;\)</span>和<span class="math inline">\(&lt;T,
\circ&gt;\)</span>是两个==代数系统==，其中“<span
class="math inline">\(\cdot\)</span>”和“<span
class="math inline">\(\circ\)</span>”分别是<span
class="math inline">\(S\)</span>和<span
class="math inline">\(T\)</span>的二元运算。如果存在映射<span
class="math inline">\(f:S\to T\)</span>使得对任意<span
class="math inline">\(a_1,a_2\in S,f(a_1\cdot a_2)=f(a_1)\circ
f(a_2)\)</span>，则称<span class="math inline">\(f\)</span>是<span
class="math inline">\(S\)</span>到<span
class="math inline">\(T\)</span>的==同态映射==，或者<span
class="math inline">\(S\)</span>和<span
class="math inline">\(T\)</span>==同态==，记为<span
class="math inline">\(S\sim T\)</span>；称<span
class="math inline">\(f(S)\subseteq T\)</span>为<span
class="math inline">\(S\)</span>的==同态像==。</strong></p>
<p><strong>当<span class="math inline">\(f\)</span>是满射时，称<span
class="math inline">\(f\)</span>为==满同态==；当<span
class="math inline">\(f\)</span>是双射时，称<span
class="math inline">\(f\)</span>为==同构映射==。代数系统<span
class="math inline">\(S\)</span>和<span
class="math inline">\(T\)</span>同构记为<span
class="math inline">\(S\cong T\)</span>.</strong></p>
</blockquote>
<p>同态映射不仅确定了不同集合元素间的对应关系，而且还保持了代数系统的运算性质。</p>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>设<span class="math inline">\(f\)</span>是从代数系统<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>到代数系统<span
class="math inline">\(&lt;T,
\circ&gt;\)</span>的==同态映射==，则</strong></p>
<ul>
<li><strong>如果运算”<span class="math inline">\(\cdot\)</span>"在<span
class="math inline">\(S\)</span>中是封闭的，那么运算“<span
class="math inline">\(\circ\)</span>”在<span
class="math inline">\(f(S)\)</span>中也是封闭的。</strong></li>
<li><strong><span class="math inline">\(&lt;S,
\cdot&gt;\)</span>满足结合律，则<span class="math inline">\(&lt;f(S),
\cdot&gt;\)</span>满足结合律</strong></li>
<li><strong><span class="math inline">\(&lt;S,
\cdot&gt;\)</span>满足交换律，则<span class="math inline">\(&lt;f(S),
\cdot&gt;\)</span>满足交换律</strong></li>
<li><strong><span class="math inline">\(&lt;S,
\cdot&gt;\)</span>存在幺元，则<span class="math inline">\(&lt;f(S),
\cdot&gt;\)</span>存在幺元</strong></li>
<li><strong><span class="math inline">\(S\)</span>中每元关于运算“<span
class="math inline">\(\cdot\)</span>”有逆元，那么<span
class="math inline">\(f(S)\)</span>中每元关于运算“<span
class="math inline">\(\circ\)</span>”也有逆元。<span
class="math inline">\(\forall x\in S,
f(x^{-1})=f^{-1}(x)\)</span></strong></li>
</ul>
</blockquote>
<blockquote>
<p><strong>定理</strong> <strong>如果<span
class="math inline">\(f\)</span>是代数系统<span
class="math inline">\(&lt;S, \cdot&gt;\)</span>到<span
class="math inline">\(&lt;T,
\cdot&gt;\)</span>的满同态，那么</strong></p>
<ul>
<li><strong>如果<span class="math inline">\(S\)</span>是半群，则<span
class="math inline">\(T\)</span>也是半群</strong></li>
<li><strong>如果<span class="math inline">\(S\)</span>是群，则<span
class="math inline">\(T\)</span>也是群</strong></li>
</ul>
</blockquote>
<p>在同态映射下，像源的代数性质都为像集所具有，但像集所具有的代数性质像源未必能有。</p>
<p>如$&lt;Z_2,&gt; <span class="math inline">\(是群，而\)</span>&lt;N,
+&gt;$不是群。</p>
<p><span
class="math inline">\(f\)</span>实际上是按一定模式把像源的元素进行归类。</p>
<blockquote>
<p><strong>定义</strong> <strong>设<span
class="math inline">\(f\)</span>是使<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>到<span class="math inline">\(&lt;H,
\circ&gt;\)</span>的同态映射，<span
class="math inline">\(e&#39;\)</span>是<span
class="math inline">\(H\)</span>的幺元，记<span
class="math inline">\(Ker(f)=\{x|x\in G \and
f(x)=e&#39;\}\)</span>，则称<span
class="math inline">\(Ker(f)\)</span>为<span
class="math inline">\(f\)</span>的==同态核==</strong></p>
</blockquote>
<blockquote>
<p><strong>定理</strong> <strong>设<span
class="math inline">\(f\)</span>是使<span class="math inline">\(&lt;G,
\cdot&gt;\)</span>到<span class="math inline">\(&lt;H,
\circ&gt;\)</span>的同态映射，则<span
class="math inline">\(f\)</span>的==同态核==<span
class="math inline">\(Ker(f)\)</span>是<span
class="math inline">\(G\)</span>的==正规子群==</strong></p>
</blockquote>
<p>证明：</p>
<ol type="1">
<li><p>先证<span class="math inline">\(Ker(f)\)</span>是<span
class="math inline">\(&lt;G,\cdot&gt;\)</span>的子群</p>
<p>设<span class="math inline">\(e&#39;\)</span>是H的幺元</p>
<p><span class="math inline">\(\forall x, y\in Ker(f),\therefore
f(x)=f(y)=e&#39;\)</span></p>
<p><span class="math inline">\(f(x\cdot y^{-1})=f(x)\circ
f(y^{-1})=f(x)\circ f^{-1}(y)=e&#39;\circ e&#39;=e&#39;\in
Ker(f)\)</span></p>
<p>所以<span class="math inline">\(Ker(f)\)</span>是<span
class="math inline">\(&lt;G,\cdot&gt;\)</span>的子群</p></li>
<li><p>再证是正规子群</p>
<p><span class="math inline">\(\forall x\in G,k\in Ker(f)\)</span></p>
<p><span class="math inline">\(f(x\cdot k\cdot x^{-1})=f(x)\circ
f(k)\circ f(x^{-1})=f(x)\circ f^{-1}(x)=e&#39;\in Ker(f)\)</span></p>
<p>所以<span class="math inline">\(Ker(f)\)</span>是<span
class="math inline">\(&lt;G,\cdot&gt;\)</span>的正规子群</p></li>
</ol>
<h3 id="环与域">环与域</h3>
<h4 id="环的定义及性质">环的定义及性质</h4>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是含有两个二元运算的代数系统。如果满足</strong></p>
<ol type="1">
<li><strong><span
class="math inline">\(&lt;R,+&gt;\)</span>是==交换群==</strong></li>
<li><strong><span
class="math inline">\(&lt;R,*&gt;\)</span>是==半群==</strong></li>
<li><strong><span class="math inline">\(\forall a, b, c\in
R,a*(b+c)=(a*b)+(a*c),(b+c)*a=(b*a)+(c*a)\)</span></strong></li>
</ol>
<p><strong>则称<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是==环==</strong></p>
</blockquote>
<p>约定加法幺元记为<span class="math inline">\(\theta\)</span>。</p>
<p>元<span class="math inline">\(b\)</span>的加法记为<span
class="math inline">\(-b\)</span>，并且<span
class="math inline">\(a+(-b)=a-b\)</span>。</p>
<blockquote>
<p><strong>定理 移项法则</strong></p>
<p><strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是环，<span
class="math inline">\(a,b,c\in R\)</span>，则下面两条等价：</strong></p>
<ol type="1">
<li><strong><span class="math inline">\(a+b=c\)</span></strong></li>
<li><strong><span
class="math inline">\(a+b-c=\theta\)</span></strong></li>
</ol>
</blockquote>
<blockquote>
<p><strong>定理</strong></p>
<p><strong>设<span class="math inline">\(&lt;R,+,*&gt;\)</span>是环<span
class="math inline">\(a,b,c\in R\)</span>，则：</strong></p>
<ul>
<li><strong><span class="math inline">\(a*\theta =\theta
*a=\theta\)</span>（加法幺元是乘法零元）</strong></li>
<li><strong><span
class="math inline">\(a*(-b)=-(a*b)=(-a)*b\)</span></strong></li>
<li><strong><span
class="math inline">\((-a)*(-b)=a*b\)</span></strong></li>
<li><strong><span
class="math inline">\(a*(b-c)=(a*b)-(a*c)\)</span></strong></li>
<li><strong><span
class="math inline">\((b-c)*a=(b*a)-(c*a)\)</span></strong></li>
</ul>
</blockquote>
<p>证明：</p>
<ol type="1">
<li><p><span class="math inline">\(a*\theta=a*(\theta
+\theta)=(a*\theta)+(a*\theta)\)</span></p>
<p>由移项法则，得到<span class="math inline">\(a*\theta =
\theta\)</span></p></li>
<li><p><span class="math inline">\((a*(-b))+(a*b)=a*(-b+b)=a*\theta
=\theta\)</span></p>
<p><span class="math inline">\(\therefore a*(-b)=-(a*b)\)</span></p>
<p>同理<span class="math inline">\((-a)*b=-(a*b)\)</span></p></li>
<li><p><span
class="math inline">\((-a)*(-b)-(a*b)=(-a)*(-b)+a*(-b)=(-a+a)*(-b)=\theta
*(-b)=\theta\)</span></p></li>
</ol>
<p>​ <span class="math inline">\(\therefore (-a)*(-b)=a*b\)</span></p>
<ol start="4" type="1">
<li><span
class="math inline">\(a*(b-c)=a*(b+(-c))=(a*b)+(a*(-c))=(a*b)-(a*c)\)</span></li>
<li>同4.</li>
</ol>
<blockquote>
<p><strong>定义</strong> <strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是环，<span
class="math inline">\(a,b\in R\)</span>。如果<span
class="math inline">\(a\ne \theta,b\ne \theta\)</span>，而<span
class="math inline">\(a*b=\theta\)</span>，则称<span
class="math inline">\(a\)</span>和<span
class="math inline">\(b\)</span>是<span
class="math inline">\(R\)</span>中的==零因子==。</strong></p>
</blockquote>
<p>例如，当<span class="math inline">\(m\)</span>不是素数时，<span
class="math inline">\(&lt;Z_m,\bigoplus,\bigotimes&gt;\)</span>有零因子，m是素数时有零因子。</p>
<p>n阶矩阵中存在零因子。</p>
<h4 id="整环与域">整环与域</h4>
<blockquote>
<p><strong>定义</strong></p>
<p><strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是==环==</strong></p>
<ol type="1">
<li><strong>如果<span
class="math inline">\(&lt;R,*&gt;\)</span>可交换，则称<span
class="math inline">\(&lt;R,+,*&gt;\)</span>为==交换环==。</strong></li>
<li><strong>如果<span
class="math inline">\(&lt;R,*&gt;\)</span>有幺元，则称<span
class="math inline">\(&lt;R,+,*&gt;\)</span>为==含幺环==。</strong></li>
<li><strong>如果1.2.成立，且无零因子，则称<span
class="math inline">\(&lt;R,+,*&gt;\)</span>为==整环==。</strong></li>
</ol>
</blockquote>
<blockquote>
<p><strong>定理</strong> <strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是环，则<span
class="math inline">\(R\)</span>中无零因子，当且仅当对任何<span
class="math inline">\(a,x,y\in R\)</span>，当<span
class="math inline">\(a\ne \theta\)</span>时，由<span
class="math inline">\(a*x=a*y\)</span>，必然得到<span
class="math inline">\(x=y\)</span>。</strong></p>
</blockquote>
<blockquote>
<p><strong>定义</strong> <strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是环，<span
class="math inline">\(S\)</span>是<span
class="math inline">\(R\)</span>的==非空子集==，如果<span
class="math inline">\(&lt;S,+,*&gt;\)</span>也是环，则称<span
class="math inline">\(S\)</span>是<span
class="math inline">\(R\)</span>的==子环==。</strong></p>
</blockquote>
<blockquote>
<p><strong>定义</strong> <strong>设<span
class="math inline">\(&lt;S,+,*&gt;\)</span>和<span
class="math inline">\(&lt;T,\bigoplus,\bigotimes&gt;\)</span>是两个环，<span
class="math inline">\(f:S\to T\)</span>是映射。如果对于任意<span
class="math inline">\(a.b\in S\)</span>，都有<span
class="math display">\[f(a+b)=f(a)\bigoplus f(b),f(a*b)=f(a)\bigotimes
f(b)\]</span>，则称<span class="math inline">\(f\)</span>是环<span
class="math inline">\(&lt;S,+,*&gt;\)</span>到<span
class="math inline">\(&lt;T,\bigoplus,\bigotimes&gt;\)</span>的==同态映射==。<span
class="math inline">\(f(S)\)</span>称谓<span
class="math inline">\(S\)</span>的==同态像==。当<span
class="math inline">\(f\)</span>是满射的时候，称<span
class="math inline">\(f\)</span>为==满同态==。是双射时，称<span
class="math inline">\(f\)</span>为==环同构映射==。</strong></p>
</blockquote>
<blockquote>
<p><strong>定义</strong> <strong>设<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是环，如果<span
class="math inline">\(&lt;R,+&gt;\)</span>和<span
class="math inline">\(&lt;R-\{\theta\},*&gt;\)</span>都是==交换群==，则称<span
class="math inline">\(&lt;R,+,*&gt;\)</span>是==域==。</strong></p>
</blockquote>
<blockquote>
<p><strong>定理</strong> <strong>有限整环<span
class="math inline">\(&lt;R,+,*&gt;\)</span>必是域</strong></p>
</blockquote>
]]></content>
      <categories>
        <category>笔记</category>
        <category>离散数学</category>
      </categories>
      <tags>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅ML2020Spring HW3</title>
    <url>/2022/02/13/%E6%9D%8E%E5%AE%8F%E6%AF%85ML2020Spring-HW3/</url>
    <content><![CDATA[<center>
李宏毅2020年春季机器学习课程HW3 食物分类
</center>
<span id="more"></span>
<p>数据特点是：带标签的数据量小，有大量无标签数据。</p>
<p>任务:</p>
<ol type="1">
<li>对带标签数据进行数据增强</li>
<li>对无标签数据采取自监督学习</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> ConcatDataset, DataLoader, Subset, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> DatasetFolder</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br><span class="line">train_tfm1 = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.RandomErasing(p=<span class="number">0.8</span>), <span class="comment"># 注意！RandomErasing不能处理PIL图像，只能先转换为Tensor再处理</span></span><br><span class="line">    transforms.RandomRotation(degrees=<span class="number">30</span>), <span class="comment"># 随机旋转+-30度</span></span><br><span class="line">    transforms.RandomHorizontalFlip(p=<span class="number">0.9</span>), <span class="comment"># 左右翻转</span></span><br><span class="line">])</span><br><span class="line"><span class="comment"># 对测试数据不需要进行转换</span></span><br><span class="line">test_tfm = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">128</span>, <span class="number">128</span>)),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对于数据按文件分好类的情况，直接使用DatasetFolder可以方便地进行处理</span></span><br><span class="line"><span class="comment"># loader是读取文件时进行的操作，输入地址，输出图像</span></span><br><span class="line"><span class="comment"># transform是在dataset getitem()的时候进行的</span></span><br><span class="line"></span><br><span class="line">train_set0 = DatasetFolder(<span class="string">&quot;../input/ml2021springhw3/food-11/training/labeled&quot;</span>, loader=<span class="keyword">lambda</span> x: Image.<span class="built_in">open</span>(x), extensions=<span class="string">&quot;jpg&quot;</span>, transform=train_tfm)</span><br><span class="line">train_set1 = DatasetFolder(<span class="string">&quot;../input/ml2021springhw3/food-11/training/labeled&quot;</span>, loader=<span class="keyword">lambda</span> x: Image.<span class="built_in">open</span>(x), extensions=<span class="string">&quot;jpg&quot;</span>, transform=train_tfm1)</span><br><span class="line">train_set = train_set0 + train_set1 </span><br><span class="line"><span class="comment"># Dataset的+被重载了，用ConcatDataset重载的，+相当于ConcatDataset</span></span><br><span class="line"><span class="comment"># 将原始图像和增强过的图像拼在一起当做训练数据</span></span><br><span class="line"></span><br><span class="line">valid_set = DatasetFolder(<span class="string">&quot;../input/ml2021springhw3/food-11/validation&quot;</span>, loader=<span class="keyword">lambda</span> x: Image.<span class="built_in">open</span>(x), extensions=<span class="string">&quot;jpg&quot;</span>, transform=test_tfm)</span><br><span class="line">unlabeled_set = DatasetFolder(<span class="string">&quot;../input/ml2021springhw3/food-11/training/unlabeled&quot;</span>, loader=<span class="keyword">lambda</span> x: Image.<span class="built_in">open</span>(x), extensions=<span class="string">&quot;jpg&quot;</span>, transform=train_tfm)</span><br><span class="line">test_set = DatasetFolder(<span class="string">&quot;../input/ml2021springhw3/food-11/testing&quot;</span>, loader=<span class="keyword">lambda</span> x: Image.<span class="built_in">open</span>(x), extensions=<span class="string">&quot;jpg&quot;</span>, transform=test_tfm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct data loaders.</span></span><br><span class="line">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>网络结构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        <span class="comment"># The arguments for commonly used modules:</span></span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># input image size: [3, 128, 128]</span></span><br><span class="line">        self.cnn_layers = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">1024</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),</span><br><span class="line">        )</span><br><span class="line">        self.fc_layers = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">1024</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.5</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.cnn_layers(x)</span><br><span class="line">        x = x.flatten(<span class="number">1</span>)</span><br><span class="line">        x = self.fc_layers(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>构建pseudodataset</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">pseudo_dataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, features, labels</span>):</span></span><br><span class="line">        self.x = features</span><br><span class="line">        self.y = labels</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.x[index], self.y[index].item(),</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_pseudo_labels</span>(<span class="params">dataset, model, threshold=<span class="number">0.65</span></span>):</span></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">    <span class="comment"># 先构建无标签数据的dataloader</span></span><br><span class="line">    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="comment"># 定义softmax函数</span></span><br><span class="line">    softmax = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    features, labels = [], []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">        img, _ = batch</span><br><span class="line">        <span class="comment"># 使用 torch.no_grad() 加速前向传播的速度</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            logits = model(img.to(device))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对输出的logits用softmax算出概率分布</span></span><br><span class="line">        probs = softmax(logits)</span><br><span class="line"></span><br><span class="line">        maxp, pos = torch.<span class="built_in">max</span>(probs, dim=-<span class="number">1</span>) <span class="comment"># 找到batch中每个图像的最大概率和类别</span></span><br><span class="line">        <span class="keyword">for</span> i, Img <span class="keyword">in</span> <span class="built_in">enumerate</span>(img):</span><br><span class="line">            <span class="keyword">if</span> maxp[i] &gt;= threshold: <span class="comment"># 如果每个最大概率超过阈值，则赋予其标签</span></span><br><span class="line">                features.append(Img.cpu())</span><br><span class="line">                labels.append(pos[i].cpu())</span><br><span class="line">     </span><br><span class="line">    psedodataset = pseudo_dataset(features, labels) <span class="comment"># 构建pseudodataset</span></span><br><span class="line">        </span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">return</span> psedodataset</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">try_gpu</span>(<span class="params">i=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.device_count() &gt;= i + <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> torch.device(<span class="string">f&#x27;cuda:<span class="subst">&#123;i&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> torch.device(<span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = Classifier().to(device=try_gpu())</span><br><span class="line"></span><br><span class="line">model = torch.load(<span class="string">&#x27;./verssion1.model&#x27;</span>).to(device=try_gpu())</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.0003</span>, weight_decay=<span class="number">1e-4</span>)</span><br><span class="line"></span><br><span class="line">n_epochs = <span class="number">80</span></span><br><span class="line"></span><br><span class="line">do_semi = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">lst_valid_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="comment"># 根据上一个epoch的validdata的acc，大于0.6才做自监督学习</span></span><br><span class="line">    <span class="keyword">if</span> lst_valid_acc &gt; <span class="number">0.6</span>:</span><br><span class="line">        do_semi = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        do_semi = <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> do_semi:</span><br><span class="line">        pseudo_set = get_pseudo_labels(unlabeled_set, model, threshold=<span class="number">0.65</span>)</span><br><span class="line">        concat_dataset = ConcatDataset([train_set, pseudo_set])</span><br><span class="line">        <span class="comment"># 注意：DataLoader里面的Dataset一定不能放进GPU中，否则多线程时候就会出错！！</span></span><br><span class="line">        train_loader = DataLoader(concat_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>, pin_memory=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># ---------- Training ----------</span></span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    train_loss = []</span><br><span class="line">    train_accs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(train_loader):</span><br><span class="line">        imgs, labels = batch</span><br><span class="line">        logits = model(imgs.to(device=try_gpu()))</span><br><span class="line">        loss = criterion(logits, labels.to(device=try_gpu()))</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 进行梯度剪裁</span></span><br><span class="line">        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算这一个batch的准确率</span></span><br><span class="line">        acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device=try_gpu())).<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 记录loss和axx</span></span><br><span class="line">        train_loss.append(loss.item())</span><br><span class="line">        train_accs.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 平均loss和acc</span></span><br><span class="line">    train_loss = <span class="built_in">sum</span>(train_loss) / <span class="built_in">len</span>(train_loss)</span><br><span class="line">    train_acc = <span class="built_in">sum</span>(train_accs) / <span class="built_in">len</span>(train_accs)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[ Train | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;train_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;train_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># ---------- Validation ----------</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    valid_loss = []</span><br><span class="line">    valid_accs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(valid_loader):</span><br><span class="line"></span><br><span class="line">        imgs, labels = batch</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">          logits = model(imgs.to(device=try_gpu()))</span><br><span class="line"></span><br><span class="line">        loss = criterion(logits, labels.to(device=try_gpu()))</span><br><span class="line"></span><br><span class="line">        acc = (logits.argmax(dim=-<span class="number">1</span>) == labels.to(device=try_gpu())).<span class="built_in">float</span>().mean()</span><br><span class="line"></span><br><span class="line">        valid_loss.append(loss.item())</span><br><span class="line">        valid_accs.append(acc)</span><br><span class="line"></span><br><span class="line">    valid_loss = <span class="built_in">sum</span>(valid_loss) / <span class="built_in">len</span>(valid_loss)</span><br><span class="line">    valid_acc = <span class="built_in">sum</span>(valid_accs) / <span class="built_in">len</span>(valid_accs)</span><br><span class="line">    lst_valid_acc = valid_acc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Print the information.</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[ Valid | <span class="subst">&#123;epoch + <span class="number">1</span>:03d&#125;</span>/<span class="subst">&#123;n_epochs:03d&#125;</span> ] loss = <span class="subst">&#123;valid_loss:<span class="number">.5</span>f&#125;</span>, acc = <span class="subst">&#123;valid_acc:<span class="number">.5</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>训练完模型，对测试数据进行预测</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">predictions = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(test_loader):</span><br><span class="line">    imgs, labels = batch</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        logits = model(imgs.to(device=try_gpu()))</span><br><span class="line">    predictions.extend(logits.argmax(dim=-<span class="number">1</span>).cpu().numpy().tolist())</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;./predict.csv&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&quot;Id,Category\n&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, pred <span class="keyword">in</span>  <span class="built_in">enumerate</span>(predictions):</span><br><span class="line">         f.write(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>,<span class="subst">&#123;pred&#125;</span>\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>最终提交后private的准确率仅来到了0.70412，离strong
baseline还有很远距离，但实在没有心情train它了。</p>
<p>train不起来真难受555.</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>李宏毅ML2020Spring-HW4</title>
    <url>/2022/02/15/%E6%9D%8E%E5%AE%8F%E6%AF%85ML2020Spring-HW4/</url>
    <content><![CDATA[<center>
李宏毅2020年春季机器学习课程HW4 语音辨识
</center>
<center>
学习代码...
</center>
<span id="more"></span>
<p>任务描述：根据语音辨识说话的人是谁。</p>
<p>数据包括600个人，所有数据都经过了处理，处理成mel-spectrogram。</p>
<p>数据构成：</p>
<p><img src="https://s2.loli.net/2022/02/15/tXM9uy27KH5NqQJ.png" /></p>
<p>其中mapping.json内包括speaker2id和id2speaker</p>
<p><img src="https://s2.loli.net/2022/02/15/HCscz4b5k6LnFlQ.png" /></p>
<p>metadata.json内是训练数据，n_mels是mel-spectrograms的特征长度，为40。里面还包括了speakers。</p>
<p><img src="https://s2.loli.net/2022/02/15/vyzcW9iA8QdgajI.png" /></p>
<p>speakers里有很多id，对应的是对应人的声音的数据，feature_path是数据地址，mel_len是这个特征包括了多少个mel（每个的特征长度都是40）</p>
<p><img src="https://s2.loli.net/2022/02/15/kZVbB4idUTOLoGp.png" /></p>
<p><img src="https://s2.loli.net/2022/02/15/wF9DE3tPNK725zm.png" /></p>
<p>testdata.json类似，只不过没有speakers标签。</p>
<p><img src="https://s2.loli.net/2022/02/15/J8cx3WATMuPD25a.png" /></p>
<p>代码如下：</p>
<p>构建数据集类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">myDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_dir, segment_len=<span class="number">128</span></span>):</span> <span class="comment"># segment_len是把一个数据切成长度只有128，方便一个batch处理</span></span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.segment_len = segment_len</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load the mapping from speaker neme to their corresponding id. </span></span><br><span class="line">        mapping_path = Path(data_dir) / <span class="string">&quot;mapping.json&quot;</span></span><br><span class="line">        mapping = json.load(mapping_path.<span class="built_in">open</span>())</span><br><span class="line">        self.speaker2id = mapping[<span class="string">&quot;speaker2id&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Load metadata of training data.</span></span><br><span class="line">        metadata_path = Path(data_dir) / <span class="string">&quot;metadata.json&quot;</span></span><br><span class="line">        metadata = json.load(<span class="built_in">open</span>(metadata_path))[<span class="string">&quot;speakers&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Get the total number of speaker.</span></span><br><span class="line">        self.speaker_num = <span class="built_in">len</span>(metadata.keys())</span><br><span class="line">        self.data = []</span><br><span class="line">        <span class="keyword">for</span> speaker <span class="keyword">in</span> metadata.keys():</span><br><span class="line">            <span class="keyword">for</span> utterances <span class="keyword">in</span> metadata[speaker]:</span><br><span class="line">                self.data.append([utterances[<span class="string">&quot;feature_path&quot;</span>], self.speaker2id[speaker]])</span><br><span class="line">                <span class="comment"># self.data内存放训练数据的地址和标签。</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        feat_path, speaker = self.data[index]</span><br><span class="line">        <span class="comment"># Load preprocessed mel-spectrogram.</span></span><br><span class="line">        mel = torch.load(os.path.join(self.data_dir, feat_path))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Segmemt mel-spectrogram into &quot;segment_len&quot; frames.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(mel) &gt; self.segment_len:</span><br><span class="line">          <span class="comment"># Randomly get the starting point of the segment.</span></span><br><span class="line">            start = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(mel) - self.segment_len)</span><br><span class="line">          <span class="comment"># Get a segment with &quot;segment_len&quot; frames.</span></span><br><span class="line">            mel = torch.FloatTensor(mel[start:start+self.segment_len])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            mel = torch.FloatTensor(mel)</span><br><span class="line">    <span class="comment"># Turn the speaker id into long for computing loss later.</span></span><br><span class="line">        speaker = torch.FloatTensor([speaker]).long()</span><br><span class="line">        <span class="keyword">return</span> mel, speaker</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_speaker_number</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.speaker_num</span><br></pre></td></tr></table></figure>
<p>构建DataLoader类：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, random_split</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collate_batch</span>(<span class="params">batch</span>):</span> <span class="comment"># 整理一个batch的数据</span></span><br><span class="line">    <span class="comment"># 输入是batch_size个tuple，每个tuple长相是(feature, label)，返回值是两个tensor,features和labels,features的形状是(batch_size, .....)，labels的形状是(batch_size, 1)。简而言之就是把一堆tuple转换成两个Tensor，分别为x和y。</span></span><br><span class="line">    mel, speaker = <span class="built_in">zip</span>(*batch)</span><br><span class="line">    <span class="comment"># Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.</span></span><br><span class="line">    <span class="comment"># 我们需要把一个batch内的数据长度都弄成一样的，否则没办法矩阵运算。</span></span><br><span class="line">    mel = pad_sequence(mel, batch_first=<span class="literal">True</span>, padding_value=-<span class="number">20</span>)    <span class="comment"># pad log 10^(-20) which is very small value</span></span><br><span class="line">    <span class="comment"># 如果batch_first是flase的话，会按照rnn一样把batch放到第二维，但这是我们现在不希望的。</span></span><br><span class="line">    <span class="comment"># mel: (batch size, length, 40)</span></span><br><span class="line">    <span class="keyword">return</span> mel, torch.FloatTensor(speaker).long()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataloader</span>(<span class="params">data_dir, batch_size, n_workers</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate dataloader&quot;&quot;&quot;</span></span><br><span class="line">    dataset = myDataset(data_dir) <span class="comment"># 构建数据集</span></span><br><span class="line">    speaker_num = dataset.get_speaker_number() </span><br><span class="line">    <span class="comment"># Split dataset into training dataset and validation dataset</span></span><br><span class="line">    trainlen = <span class="built_in">int</span>(<span class="number">0.9</span> * <span class="built_in">len</span>(dataset))</span><br><span class="line">    lengths = [trainlen, <span class="built_in">len</span>(dataset) - trainlen]</span><br><span class="line">    trainset, validset = random_split(dataset, lengths) <span class="comment"># 随机分割数据集</span></span><br><span class="line"></span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        trainset,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        drop_last=<span class="literal">True</span>,</span><br><span class="line">        num_workers=n_workers,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        collate_fn=collate_batch,</span><br><span class="line">      )</span><br><span class="line">    valid_loader = DataLoader(</span><br><span class="line">        validset,</span><br><span class="line">        batch_size=batch_size,</span><br><span class="line">        num_workers=n_workers,</span><br><span class="line">        drop_last=<span class="literal">True</span>,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        collate_fn=collate_batch,</span><br><span class="line">      )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_loader, valid_loader, speaker_num</span><br></pre></td></tr></table></figure>
<p>构建网络架构：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Classifier</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, d_model=<span class="number">80</span>, n_spks=<span class="number">600</span>, dropout=<span class="number">0.1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># Project the dimension of features from that of input into d_model.</span></span><br><span class="line">        <span class="comment"># 因为一个mel的特征维度是40，我们要先把mel特征投射到d_model维上</span></span><br><span class="line">        self.prenet = nn.Linear(<span class="number">40</span>, d_model)</span><br><span class="line">        <span class="comment"># Transformer的Encoder层，d_model是QKV的维度，dim_feedforwoard是前馈网络的中间层维度（输出还是d__model维），nhead是几个头</span></span><br><span class="line">        self.encoder_layer = nn.TransformerEncoderLayer(</span><br><span class="line">          d_model=d_model, dim_feedforward=<span class="number">256</span>, nhead=<span class="number">1</span></span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 如果需要多个encoder层</span></span><br><span class="line">        <span class="comment"># self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Project the the dimension of features from d_model into speaker nums.</span></span><br><span class="line">        self.pred_layer = nn.Sequential(</span><br><span class="line">          nn.Linear(d_model, n_spks),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, mels</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        args:</span></span><br><span class="line"><span class="string">          mels: (batch size, length, 40)</span></span><br><span class="line"><span class="string">        return:</span></span><br><span class="line"><span class="string">          out: (batch size, n_spks)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># out: (batch size, length, d_model)</span></span><br><span class="line">        out = self.prenet(mels)</span><br><span class="line">        <span class="comment"># out: (length, batch size, d_model)</span></span><br><span class="line">        out = out.permute(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="comment"># The encoder layer expect features in the shape of (length, batch size, d_model).</span></span><br><span class="line">        <span class="comment"># ！！！注意</span></span><br><span class="line">        out = self.encoder_layer(out)</span><br><span class="line">        <span class="comment"># out: (batch size, length, d_model)</span></span><br><span class="line">        out = out.transpose(<span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># mean pooling</span></span><br><span class="line">        stats = out.mean(dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># out: (batch, n_spks)</span></span><br><span class="line">        out = self.pred_layer(stats)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>学习率调整，先warmup再逐渐降低：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> Optimizer</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> LambdaLR</span><br><span class="line"></span><br><span class="line"><span class="comment"># LambdaLR内的optimizer是要调整学习率的优化器；lr_lambda是一个函数，输入是参数更新次数，输出是一个系数w，lr=base_lr * w；</span></span><br><span class="line"><span class="comment"># new_lr=lr_lambda(last_epoch) * base_lr，每次执行schedule.step()时，last_epoch=last_epoch+1，当last_epoch=-1时，base_lr为optimizer内的lr</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cosine_schedule_with_warmup</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">  optimizer: Optimizer,</span></span></span><br><span class="line"><span class="params"><span class="function">  num_warmup_steps: <span class="built_in">int</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">  num_training_steps: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  num_cycles: <span class="built_in">float</span> = <span class="number">0.5</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">  last_epoch: <span class="built_in">int</span> = -<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">lr_lambda</span>(<span class="params">current_step</span>):</span></span><br><span class="line">        <span class="comment"># Warmup</span></span><br><span class="line">        <span class="keyword">if</span> current_step &lt; num_warmup_steps:</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">float</span>(current_step) / <span class="built_in">float</span>(<span class="built_in">max</span>(<span class="number">1</span>, num_warmup_steps))</span><br><span class="line">        <span class="comment"># decadence</span></span><br><span class="line">        progress = <span class="built_in">float</span>(current_step - num_warmup_steps) / <span class="built_in">float</span>(</span><br><span class="line">          <span class="built_in">max</span>(<span class="number">1</span>, num_training_steps - num_warmup_steps)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">max</span>(</span><br><span class="line">          <span class="number">0.0</span>, <span class="number">0.5</span> * (<span class="number">1.0</span> + math.cos(math.pi * <span class="built_in">float</span>(num_cycles) * <span class="number">2.0</span> * progress))</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> LambdaLR(optimizer, lr_lambda, last_epoch)</span><br></pre></td></tr></table></figure>
<p>定义模型运行，输入一个batch的数据，输出损失和准确率</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_fn</span>(<span class="params">batch, model, criterion, device</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Forward a batch through the model.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    mels, labels = batch</span><br><span class="line">    mels = mels.to(device) <span class="comment"># 将数据放到gpu中</span></span><br><span class="line">    labels = labels.to(device) </span><br><span class="line"></span><br><span class="line">    outs = model(mels)</span><br><span class="line"></span><br><span class="line">    loss = criterion(outs, labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get the speaker id with highest probability.  </span></span><br><span class="line">    preds = outs.argmax(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># Compute accuracy.</span></span><br><span class="line">    accuracy = torch.mean((preds == labels).<span class="built_in">float</span>())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss, accuracy</span><br></pre></td></tr></table></figure>
<p>定义模型在验证集上运行</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">valid</span>(<span class="params">dataloader, model, criterion, device</span>):</span> </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    running_accuracy = <span class="number">0.0</span></span><br><span class="line">    pbar = tqdm(total=<span class="built_in">len</span>(dataloader.dataset), ncols=<span class="number">0</span>, desc=<span class="string">&quot;Valid&quot;</span>, unit=<span class="string">&quot; uttr&quot;</span>)</span><br><span class="line">    <span class="comment"># total是总长度，ncols是进度条的列数（宽度），desc是进度条左边的说明, unit是单位</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            loss, accuracy = model_fn(batch, model, criterion, device)</span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            running_accuracy += accuracy.item()</span><br><span class="line"></span><br><span class="line">        pbar.update(dataloader.batch_size) <span class="comment"># 进度条加batch_size</span></span><br><span class="line">        pbar.set_postfix(loss=<span class="string">f&quot;<span class="subst">&#123;running_loss / (i+<span class="number">1</span>):<span class="number">.2</span>f&#125;</span>&quot;</span>,accuracy=<span class="string">f&quot;<span class="subst">&#123;running_accuracy / (i+<span class="number">1</span>):<span class="number">.2</span>f&#125;</span>&quot;</span>,) <span class="comment"># 这个是在进度条后面显示的，每次可以刷新</span></span><br><span class="line"></span><br><span class="line">    pbar.close()</span><br><span class="line">    model.train()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> running_accuracy / <span class="built_in">len</span>(dataloader) <span class="comment"># 返回总准确率</span></span><br></pre></td></tr></table></figure>
<p>开始训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, random_split</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span>():</span></span><br><span class="line">    config = &#123;</span><br><span class="line">        <span class="string">&quot;data_dir&quot;</span>: <span class="string">&quot;../input/ml2021springhw43/Dataset&quot;</span>,</span><br><span class="line">        <span class="string">&quot;save_path&quot;</span>: <span class="string">&quot;./model.ckpt&quot;</span>,</span><br><span class="line">        <span class="string">&quot;batch_size&quot;</span>: <span class="number">32</span>,</span><br><span class="line">        <span class="string">&quot;n_workers&quot;</span>: <span class="number">2</span>,</span><br><span class="line">        <span class="string">&quot;valid_steps&quot;</span>: <span class="number">2000</span>,</span><br><span class="line">        <span class="string">&quot;warmup_steps&quot;</span>: <span class="number">1000</span>,</span><br><span class="line">        <span class="string">&quot;save_steps&quot;</span>: <span class="number">10000</span>,</span><br><span class="line">        <span class="string">&quot;total_steps&quot;</span>: <span class="number">70000</span>,</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="comment"># data_dir是数据集地址,save_path是模型保存地址,valid_steps是每隔valid_steps步进行一次验证，warm_steps是预热的参数更新次数，save_step是每次保存参数间隔的参数更新次数，total_steps是模型总共更新这么多次参数</span></span><br><span class="line">    <span class="keyword">return</span> config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">data_dir, save_path, batch_size, n_workers, valid_steps, warmup_steps, total_steps, save_steps</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Main function.&quot;&quot;&quot;</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Info]: Use <span class="subst">&#123;device&#125;</span> now!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)</span><br><span class="line">    train_iterator = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Info]: Finish loading data!&quot;</span>,flush = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    model = Classifier(n_spks=speaker_num).to(device)</span><br><span class="line">    criterion = nn.CrossEntropyLoss()</span><br><span class="line">    optimizer = AdamW(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line">    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Info]: Finish creating model!&quot;</span>,flush = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    best_accuracy = -<span class="number">1.0</span></span><br><span class="line">    best_state_dict = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    pbar = tqdm(total=valid_steps, ncols=<span class="number">0</span>, desc=<span class="string">&quot;Train&quot;</span>, unit=<span class="string">&quot; step&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(total_steps):</span><br><span class="line">        <span class="comment"># Get data</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            batch = <span class="built_in">next</span>(train_iterator)</span><br><span class="line">        <span class="keyword">except</span> StopIteration: <span class="comment"># 如果train_iterator后面没有数据了，则从头再来</span></span><br><span class="line">            train_iterator = <span class="built_in">iter</span>(train_loader)</span><br><span class="line">            batch = <span class="built_in">next</span>(train_iterator)</span><br><span class="line"></span><br><span class="line">        loss, accuracy = model_fn(batch, model, criterion, device) <span class="comment"># 用这一batch的数据forward一次</span></span><br><span class="line">        batch_loss = loss.item()</span><br><span class="line">        batch_accuracy = accuracy.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Updata model</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        scheduler.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">        <span class="comment"># Log</span></span><br><span class="line">        pbar.update()</span><br><span class="line">        pbar.set_postfix(</span><br><span class="line">          loss=<span class="string">f&quot;<span class="subst">&#123;batch_loss:<span class="number">.2</span>f&#125;</span>&quot;</span>,</span><br><span class="line">          accuracy=<span class="string">f&quot;<span class="subst">&#123;batch_accuracy:<span class="number">.2</span>f&#125;</span>&quot;</span>,</span><br><span class="line">          step=step + <span class="number">1</span>,</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Do validation</span></span><br><span class="line">        <span class="keyword">if</span> (step + <span class="number">1</span>) % valid_steps == <span class="number">0</span>: <span class="comment"># 到了该验证的时刻了</span></span><br><span class="line">            pbar.close()</span><br><span class="line"></span><br><span class="line">            valid_accuracy = valid(valid_loader, model, criterion, device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># keep the best model</span></span><br><span class="line">            <span class="keyword">if</span> valid_accuracy &gt; best_accuracy:</span><br><span class="line">                best_accuracy = valid_accuracy</span><br><span class="line">                best_state_dict = model.state_dict() <span class="comment"># 保存最好的模型参数</span></span><br><span class="line"></span><br><span class="line">            pbar = tqdm(total=valid_steps, ncols=<span class="number">0</span>, desc=<span class="string">&quot;Train&quot;</span>, unit=<span class="string">&quot; step&quot;</span>) <span class="comment"># 再生成一个新的pbar</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save the best model so far.</span></span><br><span class="line">        <span class="keyword">if</span> (step + <span class="number">1</span>) % save_steps == <span class="number">0</span> <span class="keyword">and</span> best_state_dict <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>: <span class="comment"># 到了该保存模型的时候了</span></span><br><span class="line">            torch.save(best_state_dict, save_path)</span><br><span class="line">            pbar.write(<span class="string">f&quot;Step <span class="subst">&#123;step + <span class="number">1</span>&#125;</span>, best model saved. (accuracy=<span class="subst">&#123;best_accuracy:<span class="number">.4</span>f&#125;</span>)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    pbar.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main(**parse_args())</span><br></pre></td></tr></table></figure>
<p>接下来是在test数据上跑，然后保存结果</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">InferenceDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, data_dir</span>):</span></span><br><span class="line">        testdata_path = Path(data_dir) / <span class="string">&quot;testdata.json&quot;</span></span><br><span class="line">        metadata = json.load(testdata_path.<span class="built_in">open</span>())</span><br><span class="line">        self.data_dir = data_dir</span><br><span class="line">        self.data = metadata[<span class="string">&quot;utterances&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        utterance = self.data[index]</span><br><span class="line">        feat_path = utterance[<span class="string">&quot;feature_path&quot;</span>]</span><br><span class="line">        mel = torch.load(os.path.join(self.data_dir, feat_path))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_path, mel</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inference_collate_batch</span>(<span class="params">batch</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Collate a batch of data.&quot;&quot;&quot;</span></span><br><span class="line">    feat_paths, mels = <span class="built_in">zip</span>(*batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feat_paths, torch.stack(mels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> tqdm.notebook <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span>():</span></span><br><span class="line">    config = &#123;</span><br><span class="line">        <span class="string">&quot;data_dir&quot;</span>: <span class="string">&quot;../input/ml2021springhw43/Dataset&quot;</span>,</span><br><span class="line">        <span class="string">&quot;model_path&quot;</span>: <span class="string">&quot;./model.ckpt&quot;</span>,</span><br><span class="line">        <span class="string">&quot;output_path&quot;</span>: <span class="string">&quot;./output.csv&quot;</span>,</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">data_dir, model_path, output_path</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Main function.&quot;&quot;&quot;</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Info]: Use <span class="subst">&#123;device&#125;</span> now!&quot;</span>)</span><br><span class="line"></span><br><span class="line">    mapping_path = Path(data_dir) / <span class="string">&quot;mapping.json&quot;</span></span><br><span class="line">    mapping = json.load(mapping_path.<span class="built_in">open</span>())</span><br><span class="line"></span><br><span class="line">    dataset = InferenceDataset(data_dir)</span><br><span class="line">    dataloader = DataLoader(</span><br><span class="line">        dataset,</span><br><span class="line">        batch_size=<span class="number">1</span>,</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        drop_last=<span class="literal">False</span>,</span><br><span class="line">        num_workers=<span class="number">2</span>,</span><br><span class="line">        collate_fn=inference_collate_batch,</span><br><span class="line">      )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Info]: Finish loading data!&quot;</span>,flush = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    speaker_num = <span class="built_in">len</span>(mapping[<span class="string">&quot;id2speaker&quot;</span>])</span><br><span class="line">    model = Classifier(n_spks=speaker_num).to(device)</span><br><span class="line">    model.load_state_dict(torch.load(model_path))</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[Info]: Finish creating model!&quot;</span>,flush = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    results = [[<span class="string">&quot;Id&quot;</span>, <span class="string">&quot;Category&quot;</span>]]</span><br><span class="line">    <span class="keyword">for</span> feat_paths, mels <span class="keyword">in</span> tqdm(dataloader):</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            mels = mels.to(device)</span><br><span class="line">            outs = model(mels)</span><br><span class="line">            preds = outs.argmax(<span class="number">1</span>).cpu().numpy()</span><br><span class="line">            <span class="keyword">for</span> feat_path, pred <span class="keyword">in</span> <span class="built_in">zip</span>(feat_paths, preds):</span><br><span class="line">                results.append([feat_path, mapping[<span class="string">&quot;id2speaker&quot;</span>][<span class="built_in">str</span>(pred)]])</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_path, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>) <span class="keyword">as</span> csvfile:</span><br><span class="line">        writer = csv.writer(csvfile)</span><br><span class="line">        writer.writerows(results)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main(**parse_args())</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>[论文阅读] Improving Transferability of Adversarial Patches on Face Recognition with Generative Models</title>
    <url>/2022/07/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Improving-Transferability-of-Adversarial-Patches-on-Face-Recognition-with-Generative-Models/</url>
    <content><![CDATA[<center>
CVPR2021 使用生成模型提高对抗补丁在人脸识别上的迁移性
</center>
<span id="more"></span>
<p>题目： Improving Transferability of Adversarial Patches on Face
Recognition with Generative Models</p>
<p>作者： Zihao Xiao, ..., Jun Zhu</p>
<p>会议：CVPR2021</p>
<p>链接：<a
href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xiao_Improving_Transferability_of_Adversarial_Patches_on_Face_Recognition_With_Generative_CVPR_2021_paper.pdf">文章链接</a></p>
<hr />
<h3 id="摘要翻译">摘要翻译</h3>
<p>       深度卷积神经网络大大提升了人脸识别性能。最近，人脸识别模型已经被用于安全敏感应用的身份认证。然而，深度CNN对于对抗补丁来说很脆弱，这些对抗补丁可以在现实中实现并且隐蔽，这对这些模型在现实世界中的应用提出的新的安全问题。</p>
<p>       在本文中，我们使用基于可迁移的对抗补丁来<strong>评估人脸识别模型的鲁棒性</strong>，其中攻击者对目标模型的可访问性有限。</p>
<p>       首先，我们<strong>对现有的基于迁移的攻击方法进行扩展</strong>，生成可迁移的对抗补丁。然而，我们发现迁移性对初始化很敏感，当扰动较大时迁移性下降，表明对替代模型过拟合。</p>
<p>       其次，我们提出了<strong>在低维数据流形上对对抗补丁进行正则化</strong>。这个流形有在合法人脸图像上预训练的生成模型表示。将像人脸的特征(face-like
feature)作为对抗扰动，通过在流形上的优化，我们表明替代模型和目标模型之间的响应差距显著减小，并且表现出更好的迁移性。</p>
<p>       大量的数字世界实验证明了该方法在黑箱设定下的优越性。我们也将提出的方法应用于物理世界中。</p>
<h3 id="基本问题">基本问题</h3>
<ul>
<li><p><strong>论文解决的问题：</strong>提升人脸识别中对抗补丁的迁移性</p></li>
<li><p><strong>动机：</strong></p>
<p>       先前的对抗补丁的工作基于白盒设定，或者基于询问的设定，但部署在现实世界中的模型不能轻易被访问。所以本文聚焦于提升<strong>query-free
black-box
setting</strong>的迁移性。在这个设定下，基于迁移的对抗攻击被广泛使用。</p>
<p>       现有的提升对抗样本迁移性的方法聚焦于使用先进的非凸优化、数据增强等方法，这些方法通常是为了生成<span
class="math inline">\(L_p\)</span>约束的对抗样本，我们发现这些方法也提升对抗补丁的迁移性，但我们发现这样也容易陷入局部最优，迁移性不令人满意的。首先，迁移性对算法的初始化很敏感。其次，随着扰动强度增加，迁移性先上升后下降，有过拟合现象。所以需要<strong>新的正则化方法</strong>以减轻对代理模型的过拟合。</p></li>
<li><p><strong>相关工作</strong></p>
<ul>
<li>对抗补丁。先前工作都是基于白盒设定的。</li>
<li>可迁移的对抗样本。大多数是用在生成<span
class="math inline">\(L_p\)</span>约束下的对抗样本，但可以被迁移至对抗补丁中。但易陷入局部最优。</li>
<li>对抗样本的生成式模型。现有的生成式方法迁移性有限，如SemanticAdv。</li>
</ul></li>
<li><p><strong>科学假设：</strong>不同的人脸识别模型对<strong>类人脸特征(face-like
features)</strong>的响应是有效相关的，这可以提高对抗补丁的迁移性。</p></li>
<li><p><strong>贡献：</strong>提出通过在低维流形上对对抗补丁进行优化来进行正则化，流形用生成模型表示，在其latent
space内进行优化。</p></li>
</ul>
<h3 id="方法">方法</h3>
<h4 id="tap-tidim">TAP-TIDIM</h4>
<p>即用momentum、diversity
input、transform方法生成可迁移对抗补丁，很简单。</p>
<figure>
<img src="https://s2.loli.net/2022/07/19/v78yOS1ZD5UBE4P.png"
alt="TAP-TIDIM algorithm" />
<figcaption aria-hidden="true">TAP-TIDIM algorithm</figcaption>
</figure>
<p>但容易过拟合，</p>
<ul>
<li><p>迁移性对初值很敏感。对于目标攻击，仅把初始值换成目标人脸，就有很大的迁移性提升。</p></li>
<li><p>当搜索空间变大时，迁移性降低。对于<span
class="math inline">\(L_\infin\)</span>约束，当可改变像素值越大时，性能先提升后下降，这是过拟合的体现。</p>
<figure>
<img src="https://s2.loli.net/2022/07/19/MmCz4tTw8N7g1QR.png"
alt="Figure 3. The success rates of TAP-TIDIM on the black-box models first rise and then fall when the maximal perturbation magnitude increases. This indicates that the adversarial patches are overfitting the substitute model. The results are black-box impersonation attack on FaceNet and CosFace under the face verification task. The adversarial examples are generated against ArcFace by restricting the adversarial patches to an eyeglass frame region. 200 image pairs from the LFW dataset are used." />
<figcaption aria-hidden="true">Figure 3. The success rates of TAP-TIDIM
on the black-box models first rise and then fall when the maximal
perturbation magnitude increases. This indicates that the adversarial
patches are overfitting the substitute model. The results are black-box
impersonation attack on FaceNet and CosFace under the face verification
task. The adversarial examples are generated against ArcFace by
restricting the adversarial patches to an eyeglass frame region. 200
image pairs from the LFW dataset are used.</figcaption>
</figure></li>
</ul>
<h4 id="generative-adversarial-patch">Generative adversarial patch</h4>
<p>提出在低维流形上对对抗补丁进行正则化优化，以避免优化问题中迁移性不佳的局部最优情况。</p>
<p>这个流形需要具备的性质：</p>
<ul>
<li>足够的能力。即可以成功攻击白盒代理模型。</li>
<li>良好的正则化。即使代理模型和目标模型的响应是相关的，以减轻过拟合。</li>
</ul>
<p>文章使用了一个生成模型学习到的流形，这个生成模型是在正常人脸图像上训练的。使用<span
class="math inline">\(h(S):S\to R^n\)</span> 表示这个生成模型，<span
class="math inline">\(S\)</span>表示latent space。之后就是对某一个latent
code进行优化，文章中用的Adam。</p>
<p>优化问题就变为：</p>
<figure>
<img src="https://s2.loli.net/2022/07/19/bW83wMTnCIDaYpB.png"
alt="优化问题" />
<figcaption aria-hidden="true">优化问题</figcaption>
</figure>
<h3 id="实验">实验</h3>
<h4 id="实验设定">实验设定</h4>
<ul>
<li><p><strong>数据集</strong>：LFW和Celeb_HQ。对于face
verification，选择400对不同身份的人脸图像。对于face
identification，选择400个图像作为gallery
set，选择与之前400对应相同身份的400张图片作为probe set。</p></li>
<li><p><strong>人脸识别模型</strong>：FaceNet, CosFace,
ArcFace，在LFW数据集上达到了99%正确率。每个模型的cosine相似度阈值都是通过在6000对（3000对相同身份、3000对不同身份）图像上测试的最好阈值。同时用了Face++和Aliyun的模型。</p></li>
<li><p><strong>生成模型</strong>：ProGAN, StyleGAN, StyleGAN2</p></li>
<li><p><strong>补丁位置</strong>：眼镜和口罩....</p>
<p><img src="https://s2.loli.net/2022/07/19/nJlSVLjtKED96sw.png" alt="Figure 2. The binary masks M indicating the regions of the designed patches. (a) An eyeglass frame. (b) A respirator." style="zoom:50%;" /></p></li>
<li><p><strong>度量准则</strong>：对于face verification使用阈值，对face
identification使用最近邻。用成功率衡量。</p></li>
</ul>
<h4 id="实验结果">实验结果</h4>
<p>在dodging和impersonation设定下分别进行实验</p>
<figure>
<img src="https://s2.loli.net/2022/07/19/9pFTxP64WBEjcIZ.png"
alt="Table 1. The success rates of black-box dodging attack on FaceNet, CosFace, ArcFace, Face++ and Aliyun in the digital world under the face verification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to an eyeglass frame region. ∗ indicates white-box attacks." />
<figcaption aria-hidden="true">Table 1. The success rates of black-box
dodging attack on FaceNet, CosFace, ArcFace, Face++ and Aliyun in the
digital world under the face verification task. The adversarial examples
are generated against FaceNet, CosFace, and ArcFace by restricting the
adversarial patches to an eyeglass frame region. ∗ indicates white-box
attacks.</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/07/19/5UEjCk4NvOJD9hQ.png"
alt="Table 2. The success rates of black-box impersonation attack on FaceNet, CosFace, ArcFace, Face++ and Aliyun in the digital world under the face verification task. The adversarial examples are generated against FaceNet, CosFace, and ArcFace by restricting the adversarial patches to an eyeglass frame region. ∗ indicates white-box attacks." />
<figcaption aria-hidden="true">Table 2. The success rates of black-box
impersonation attack on FaceNet, CosFace, ArcFace, Face++ and Aliyun in
the digital world under the face verification task. The adversarial
examples are generated against FaceNet, CosFace, and ArcFace by
restricting the adversarial patches to an eyeglass frame region. ∗
indicates white-box attacks.</figcaption>
</figure>
<ol type="1">
<li>TAP-TIDIM表现好于TAP-MIM。表明先前提高迁移性的方法在对抗补丁上仍然有用。</li>
<li>单纯的GenAP在大多数情况下好于TAP方法，证明提出的正则化方法的有效性。</li>
<li>GenAP和GenAP-DI表现相似，在本方法上增加di没用。</li>
<li>GenAP比简单的PASTE效果好很多，表明GenAP不仅在生成目标人脸的特征，也在寻找适合攻击者面部特征的对抗性特征。</li>
<li>商业模型Face++和Aliyun对对抗补丁的脆弱性。</li>
</ol>
<h4 id="ablation-study-on-genap">Ablation study on GenAP</h4>
<figure>
<img src="https://s2.loli.net/2022/07/19/8phkHbiSEfewnG5.png"
alt="Table 3. The success rates of black-box impersonation attack when the architectures, the parameter and the latent space are changed in the proposed GenAP algorithm. The adversarial examples are generated against ArcFace by restricting the adversarial patches to an eyeglass frame region, and are tested on FaceNet, CosFace and ArcFace in the digital world under the face verification task. ∗ indicates white-box attacks. The ablation studies are on (a) the parameters (RAND, CAR and FFHQ) of the StyleGAN2, (b) the architectures of the generative model (ProGAN, StyleGAN, StyleGAN2) and (c) the latent space (Z,W,W+ and noise) used by StyleGAN2 trained on FFHQ." />
<figcaption aria-hidden="true">Table 3. The success rates of black-box
impersonation attack when the architectures, the parameter and the
latent space are changed in the proposed GenAP algorithm. The
adversarial examples are generated against ArcFace by restricting the
adversarial patches to an eyeglass frame region, and are tested on
FaceNet, CosFace and ArcFace in the digital world under the face
verification task. ∗ indicates white-box attacks. The ablation studies
are on (a) the parameters (RAND, CAR and FFHQ) of the StyleGAN2, (b) the
architectures of the generative model (ProGAN, StyleGAN, StyleGAN2) and
(c) the latent space (Z,W,W+ and noise) used by StyleGAN2 trained on
FFHQ.</figcaption>
</figure>
<h5 id="生成器模型的参数">生成器模型的参数</h5>
<p>使用StyleGAN2，改变参数进行实验。分别是随机、在car数据集上训练、在人脸数据集上训练。</p>
<p>使用<span class="math inline">\(W^+\)</span>和Noise作为latent
space。</p>
<p>Table3(a)说明，在CAR数据集上训练的模型白盒攻击表现较好，但是基本没有迁移性；在人脸数据集上训练迁移性好很多。表明使用face-like特征作为扰动，
is important for bridging the gap between the substitute and the target
face recognition models to improve transferability in the GenAP
methods.</p>
<h5 id="生成器模型架构">生成器模型架构</h5>
<p>Table3(b)， StyleGAN2表现最好。</p>
<h5 id="生成模型的latent-space">生成模型的latent space</h5>
<p>Table3(c)， <span class="math inline">\(W^+\)</span>+ Noise
最好。</p>
<p>（这跟跟直觉很符合，靠近StyleGAN主干更利于编辑，更富于语义信息）</p>
<h4 id="物理世界实验">物理世界实验</h4>
<p>具体来说，从CelebA-HQ数据集中选择了一名志愿者作为攻击者和3个目标身份(一男两女)。对于每个目标身份，我们为攻击者生成一个眼镜框来模拟该身份。攻击者戴上对抗性镜框后，我们从正面拍摄他的视频，随机选取100帧视频。视频帧用于人脸验证。我们使用余弦相似度来评估补丁的可转移性。相似度越高，可转移性越好。从图4的结果可以看出，本文所提出的GenAP-DI生成的patch在打印和拍照后仍然保持较高的可转移性。</p>
<p><img src="https://pdf.cdn.readpaper.com/parsed/fetch_target/0ffae3af6739db9fec3b99e94d47e6ec_7_Table_4.png" alt="Table 4. The cosine similarties between the attacker wearing the adversarial eyeglass frame and three different target identities in the physical-world. The target identities are randomly drawn from CelebA-HQ. The adversarial eyeglass frame is crafted by the TAPTIDIMv2 and the proposed GenAP-DI algorithms on ArcFace, and is tested on CosFace and FaceNet." style="zoom:67%;" /></p>
<h4 id="其他实验">其他实验</h4>
<p>说明了SemanticAdv方法的次优，并将本方法拓展到其他任务。</p>
<p>待填！！！！！！！！！！！！！！</p>
<h3 id="结论">结论</h3>
<p>本文研究了query-free
black-box设定下人脸识别模型对对抗补丁的鲁棒性。首先，我们将现有的技术从<span
class="math inline">\(l_p\)</span>约束(p &gt;
0)的设置扩展到patch的设定，生成可迁移的对抗patch的TAP算法。然而，一些实验现象表明，TAP算法很难摆脱局部最优，迁移性性不理想。因此，我们提出在人脸图像上预先训练的生成模型学习的流形上对对抗补丁进行正则化。所提出的GenAP算法中的扰动类似于人脸特征，这对于减少替代模型与目标人脸识别模型之间的差距具有重要意义。实验验证了所提方法的优越性。</p>
<h3 id="思考">思考</h3>
<p>问题：</p>
<ol type="1">
<li>使用StyleGAN模型有点庞大。</li>
</ol>
<p>思考：</p>
<ol type="1">
<li><p>不同GAN模型之间的差距还是很大的，越有语义编辑特性的模型效果越好。并且对Z的优化竟然效果那么差....原因？</p></li>
<li><p>为什么之前的方法那么容易陷入局部最优。</p></li>
<li><p>新提出的正则方法就是将扰动局限在人脸特征中，并且还能在这个latent
space中找到对抗样本，对GAN的要求有点高。</p></li>
<li><p>有没有别的方法可以达到类似的效果</p></li>
<li><p>发现这个方法有目标攻击生成的补丁和目标人的特征很相似，其实就相当于保留目标人脸的特征的前提下（本文提出的正则化），尽可能搜索对抗样本。有没有其他方法可以在修改的时候既保留人脸特征又有对抗性？</p></li>
</ol>
<figure>
<img
src="https://pdf.cdn.readpaper.com/parsed/fetch_target/0ffae3af6739db9fec3b99e94d47e6ec_12_Figure_4.png"
alt="Figure 4. Visualization of adversarial eyeglass frames generated by the TAP-TIDIM and the GenAP-DI methods for dodging attack. The first three rows are the demonstrations on CelebA-HQ dataset and the others are from LFW dataset. And the three columns denotes the pictures of attackers and attackers with the adversarial eyeglass frames by generated by TAP-TIDIM and GenAP-DI methods separately. In TAP-TIDIM, we use = 255." />
<figcaption aria-hidden="true">Figure 4. Visualization of adversarial
eyeglass frames generated by the TAP-TIDIM and the GenAP-DI methods for
dodging attack. The first three rows are the demonstrations on CelebA-HQ
dataset and the others are from LFW dataset. And the three columns
denotes the pictures of attackers and attackers with the adversarial
eyeglass frames by generated by TAP-TIDIM and GenAP-DI methods
separately. In TAP-TIDIM, we use = 255.</figcaption>
</figure>
<figure>
<img
src="https://pdf.cdn.readpaper.com/parsed/fetch_target/0ffae3af6739db9fec3b99e94d47e6ec_13_Figure_5.png"
alt="Figure 5. Visualization of adversarial eyeglass frames generated by the TAP-TIDIM and the GenAP-DI methods for impersonation attack. The first three rows are the demonstrations on CelebA-HQ dataset and the others are from LFW dataset. The first two columns are the photos of attackers and their target identities, and the following two columns show the attackers with the adversarial eyeglass frames generated by the proposed TAP-TIDIM and GenAP-DI methods. In TAP-TIDIM, we use = 40." />
<figcaption aria-hidden="true">Figure 5. Visualization of adversarial
eyeglass frames generated by the TAP-TIDIM and the GenAP-DI methods for
impersonation attack. The first three rows are the demonstrations on
CelebA-HQ dataset and the others are from LFW dataset. The first two
columns are the photos of attackers and their target identities, and the
following two columns show the attackers with the adversarial eyeglass
frames generated by the proposed TAP-TIDIM and GenAP-DI methods. In
TAP-TIDIM, we use = 40.</figcaption>
</figure>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>[论文阅读] OPOM: Customized Invisible Cloak towards Face Privacy Protection</title>
    <url>/2022/08/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-OPOM-Customized-Invisible-Cloak-towards-Face-Privacy-Protection/</url>
    <content><![CDATA[<center>
TPAMI2022 OPOM-为人脸隐私保护的定制隐身衣
</center>
<span id="more"></span>
<p>题目： OPOM: Customized Invisible Cloak towards Face Privacy
Protection</p>
<p>作者： Yaoyao Zhong, Weihong Deng</p>
<p>链接： <a
href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9778974">文章链接</a></p>
<hr />
<p>[TOC]</p>
<h2 id="摘要翻译">1 摘要翻译</h2>
<p>人脸识别技术虽然在日常生活中很方便，但它可以在没有任何安全限制的情况下高效、隐蔽地分析人脸图像和视频，这也引起了社交媒体上普通用户的隐私担忧。在本文中，我们从技术的角度研究了人脸隐私保护，基于一种新型的定制隐身衣，它可以应用于普通用户的所有图像，以防止恶意的人脸识别系统发现他们的身份。具体地说，我们提出了一种名为“one
person one
mask”(OPOM)的新方法，该方法通过优化每个训练样本在<strong>远离源身份特征子空间的方向</strong>来生<strong>成针对个人(类)的通用掩码</strong>。为了充分利用有限的训练图像，我们研究了几种建模方法，包括<strong>仿射包、类中心和凸包</strong>，以更好地描述源身份的特征子空间。针对不同损失函数和网络结构的黑箱人脸识别模型，在普通数据集和名人数据集上评估了该方法的有效性。此外，我们还讨论了该方法的优点和潜在的问题。特别地，我们对视频数据集Sherlock的隐私保护进行了应用研究，以展示所提方法的潜在实际用途。</p>
<h3 id="基本问题">基本问题</h3>
<ul>
<li>论文解决的问题：生成针对个人的<strong>通用掩码</strong>来进行人脸隐私保护，这是一个新问题。</li>
<li>假设：通过更好地建模身份的特征子空间，可以提高Image
Universality和Model Transferability。</li>
</ul>
<h2 id="introduction">2 Introduction</h2>
<p>为保护隐私，一些研究旨在对人脸图像进行去识别
(<strong>de-identify</strong>)，从而保留许多面部特征，但无法可靠地识别图像中的人的身份。考虑到生成的图像与原始图像可能具有不同的视觉外观，或表现不自然，出现不良伪影，一些最新的方法通过生成不易察觉的<strong>对抗样本</strong>作为掩码，既能隐藏识别信息，又能保持人脸图像的视觉质量。尽管这种方法生成的掩码很自然、很有效，但对于普通用户来说，为每张照片或每一帧视频生成不同的隐私掩码是非常<strong>不友好</strong>的。（现有方法不足）</p>
<p>为公众提供更有效、更简单的面部隐私保护，需要进一步研究。现有的方法针对一个人的不同面部图像生成不同的对抗mask，与之相比，我们的目标是生成一种<strong>针对个人的(类别)通用mask</strong>。通过这种方式，普通用户只用生成一次隐私保护mask，然后将其应用到他所有的照片和视频中。（针对现有方法不足提出的改进方向）</p>
<p>与image-specific的隐私面具相比，person-specific的通用mask有两方面的好处。首先，只生成一次针对个人的掩码，省去了生成新图像的掩码时间，在<strong>效率</strong>上有利于普通用户和一些实时隐私保护应用。其次，与image-specific掩码需要在用户和服务器之间多次传输新图像相比，person-specific的掩码只需要一次传输，可以<strong>降低隐私泄露的风险</strong>。（提出的改进方向的优点）</p>
<p>在生成针对个人的隐私掩码方面存在两个挑战。(1) <strong>Individual
Universality</strong>。与image-specific的隐私掩码相比，person-specific的隐私掩码只需要用一个身份的<strong>少量图像</strong>生成，可以应用于不同的未知图像。而相同身份的面部图像可能因姿势、光照、表情和遮挡而不同。这种多样性无疑会增加为不同人脸图像生成隐私掩码的难度。因此，提高对抗型掩码的<strong>个体普适性</strong>对个人隐私保护至关重要。(2)
<strong>Model Transferability
</strong>。隐私掩码需要在不同模型之间有<strong>迁移性</strong>。这意味着它们是由代理模型生成的，并应用于不同的未知识别系统。对于未知的人脸识别模型，有广泛的选择训练数据库，训练损失函数和网络架构。无疑会增加生产可迁移对抗掩码的难度。（提出新方向的挑战）</p>
<p>在本文中，我们提出了一种名为OPOM (one person one
mask)的方法，为一个人的所有面部图像提供一个隐私掩码，类似于定制的隐身衣。具体而言，为了增加Individual
Universality，<strong>OPOM通过解决优化问题生成隐私掩码</strong>，使训练图像的不同深度特征与身份特征子空间之间的距离最大化。我们研究了不同的建模方法，包括<strong>仿射包、类中心和凸包</strong>，以建模每个身份的特征子空间，以<strong>更好地描述有限的图像</strong>。我们通过实证发现，在掩码生成过程中，更好地描述特征子空间，可以提高个体的通用性和模型的可迁移性。此外，为了增加模型的可迁移性，OPOM还可以与多种模型可迁移性方法相结合，如<strong>动量法和DFANet</strong>。本文的主要贡献如下:</p>
<ul>
<li>我们揭示了一种新型的<strong>person-specific(class-wise)通用对抗性隐私掩码的存在</strong>，它的生成是为了保护相同身份的不同人脸图像，因此可以更容易地为普通用户使用。</li>
<li>我们对这种新型的针对个人的隐私掩码进行了研究，<strong>提出了一种高效的对抗式掩码生成方法OPOM</strong>，该方法可以同时提高Image
Universality和Model Transferability，从而实现更有效的隐私保护。</li>
<li>与以往的通用对抗扰动方法相比，本文提出的OPOM方法在不同的黑盒深度人脸识别模型下保护无约束人脸图像的<strong>有效性</strong>得到了实证验证。</li>
</ul>
<h2 id="person-specific-privacy-masks">3 Person-Specific Privacy
Masks</h2>
<h3 id="problem-formulation">3.1 Problem Formulation</h3>
<p>person-specific对抗掩码的目标是去产生一个扰动<span
class="math inline">\(\Delta X\)</span>，可以用于任何属于身份<span
class="math inline">\(k\)</span>的人脸图像<span
class="math inline">\(X^k=\{X_1^k, X_2^k, \dots,
X_i^k,\dots\}\)</span>来欺骗各种深度人脸识别模型 <span
class="math inline">\(f(·)\)</span> ，就是寻找<span
class="math inline">\(\Delta X\)</span> 使得 <span
class="math inline">\(X_i^k\in X^k\)</span> <span
class="math display">\[
D(f(X_i^k+\Delta X), f_{X^k})&gt;t, ||\Delta X||_\infty &lt;
\epsilon  \,\,\,\,\,\,\,\,(1)
\]</span> 其中<span class="math inline">\(f(X_i^k)\in
R^d\)</span>是图像<span
class="math inline">\(X_i^k\)</span>的归一化特征，<span
class="math inline">\(f_{X^k}\)</span>表示身份<span
class="math inline">\(k\)</span>的特征子空间，<span
class="math inline">\(t\)</span>是决定两个图像是否是相同身份的阈值。<span
class="math inline">\(D(x_1,
x_2)\)</span>是欧几里得距离或者余弦距离。<span
class="math inline">\(\epsilon\)</span>是控制扰动像素值的范围。</p>
<h3 id="one-person-one-mask-opom">3.2 One person one mask (OPOM)</h3>
<p>上式的关键点在于<span
class="math inline">\(f_{X^k}\)</span>，但对于open-set人脸识别模型，被保护的人可能不在训练集中，就不能像以前的close-set任务的方法一样直接从模型中获取类别信息。因此，唯一的选择是从给定的人脸图像集<span
class="math inline">\(X_k\)</span>中描述身份<span
class="math inline">\(f_{X^k}\)</span>。目标是通过尽可能少的图像<span
class="math inline">\(\tilde X_k=\{X_1^k, X_2^k, \dots,
X_{n_k}^k\}\)</span>来<strong>近似</strong>描述<span
class="math inline">\(f_{X_k}\)</span></p>
<p>提出假设：有对特征子空间更精确的近似，Individual
Universality可以提升；在近似表达式中有更多样的梯度信息，Model
Transferability可以提升。</p>
<p>如图Figure2，用相同代理模型下不同图像的保护成功率来表示Individual
Universality，用不同黑盒模型的平均保护成功率来表示Model
Transferability， 实验表明假设成立。</p>
<figure>
<img src="https://s2.loli.net/2022/08/03/slWGZjO8ULuknRY.png"
alt="Fig. 2. With better approximation methods (red) for the feature subspace of each identity in the mask generation process, both individual universality and model transferability can be improved, which will lead to more effective privacy protection. Experimental results on two datasets (Privacy-Commons and Privacy-Celebrities) are shown." />
<figcaption aria-hidden="true">Fig. 2. With better approximation methods
(red) for the feature subspace of each identity in the mask generation
process, both individual universality and model transferability can be
improved, which will lead to more effective privacy protection.
Experimental results on two datasets (Privacy-Commons and
Privacy-Celebrities) are shown.</figcaption>
</figure>
<h4 id="approximation-methods-of-the-feature-subspace">3.2.1
Approximation methods of the feature subspace</h4>
<h5 id="affine-hulls">3.2.1.1.Affine Hulls</h5>
<p>使用图像集合中特征的仿射组合来表示特征子空间，即 <span
class="math display">\[
H(f_{\tilde
X^k})=\{x=\sum_{i=1}^{n_k}\alpha_i^kf(X_i^k)|\sum_{i=1}^{n_k}\alpha_i^k=1\}
\,\,\,\,\,\,\,(2)
\]</span> 于是可以优化以下式子来生成身份<span
class="math inline">\(k\)</span>的隐私掩码<span
class="math inline">\(\Delta X\)</span>：</p>
<p><img src="https://s2.loli.net/2022/08/03/p2luFcXNgirETOP.png" style="zoom:67%;" /></p>
<p>其中，<span class="math inline">\(n_k\)</span>是图像数量，<span
class="math inline">\(H(f_{\tilde
X^k})\)</span>是归一化特征的仿射包。</p>
<p>为计算<span class="math inline">\(D(f(X_i^k+\Delta X), H(f_{\tilde
X^k}))\)</span>，可以把<span class="math inline">\(H(f_{\tilde
X^k})\)</span>写成以下形式来参数化仿射包：</p>
<p><img src="https://s2.loli.net/2022/08/03/bhTurCdEB4kLSaV.png" style="zoom:67%;" /></p>
<p>其中， <span class="math inline">\(\mu
^k=\frac{1}{n_k}\sum_{i=1}^{n_k}f(X_i^k)\)</span>， <span
class="math inline">\(U^k\in R^{d\times n_k}\)</span>
是张成仿射包的正交基，用<span
class="math inline">\([f(X_1^k)-\mu^k,\dots,
f(X_{n_k}^k)-\mu^k]\)</span>做SVD求得， <span
class="math inline">\(V^k\in
R^{n_k}\)</span>是自由参数的向量，即正交基各方向的坐标。于是<span
class="math inline">\(D(f(X_i^k+\Delta X), H(f_{\tilde
X^k}))\)</span>可以写成：</p>
<p><img src="https://s2.loli.net/2022/08/03/jDNWeTh1ZbxHOMp.png" style="zoom:67%;" /></p>
<p>这个可以被写为标准的最小二乘问题：</p>
<p><img src="https://s2.loli.net/2022/08/03/Y6q3Gt4KXgSjciT.png" style="zoom:67%;" /></p>
<p>这个问题的解为，</p>
<p><img src="https://s2.loli.net/2022/08/03/198zU5OAYtynRvI.png" style="zoom: 67%;" /></p>
<p>最后，生成隐私掩码<span class="math inline">\(\Delta
X\)</span>就把以上(3)公式变为：</p>
<p><img src="https://s2.loli.net/2022/08/03/MBCs9a7mn3YVX1t.png" style="zoom:67%;" /></p>
<h5 id="class-centers-and-convex-hulls">3.2.1.2 Class Centers and Convex
Hulls</h5>
<p>以上的仿射包对特征子空间进行的估计可能太过于松，因为仿射包上的许多点都没有用，甚至可能有副作用。于是我们引入了<span
class="math inline">\(a_i^k\)</span>系数的最低值和最高值，来控制松弛度：</p>
<p><img src="https://s2.loli.net/2022/08/03/hl6CBMW3duPFRmy.png" style="zoom:67%;" /></p>
<p>如果 <span class="math inline">\(L=-\infty,
U=\infty\)</span>，则变成了<strong>仿射包</strong>。其他情况下，将会缩减过大的空间。当<span
class="math inline">\(L=U=1/n_k\)</span>时，身份特征就是<span
class="math inline">\(H(f_{\tilde
{X^k}})=\frac{1}{n_k}\sum_{i=1}^{n_k}f(X_i^k)\)</span>，即<strong>类中心</strong>。在这个设定下，隐私掩码的生成可以表示为：</p>
<p><img src="https://s2.loli.net/2022/08/03/ynVWFtcBTjvzIYl.png" style="zoom:67%;" /></p>
<p>如果<span class="math inline">\(L=0, U=1\)</span>，则<span
class="math inline">\(H(f_{\tilde{X^k}})\)</span>就是特征<span
class="math inline">\(f(X_i^k)\)</span>的<strong>凸包</strong>，这也是实验表明最有效的估计。在这个设定下，计算<span
class="math inline">\(D(f(X_i^k+\Delta X), H(f_{\tilde
X^k}))\)</span>就是一个有方形约束的最小二乘问题：</p>
<p><img src="https://s2.loli.net/2022/08/03/MnQBfNF7HSYmkXo.png" style="zoom:67%;" /></p>
<p>其中，<span class="math inline">\(F^k\in R^{d\times
n_k}\)</span>是一个列是<span
class="math inline">\(f(X_i^k)\)</span>的矩阵，<span
class="math inline">\(A_k\in R^{n_k}\)</span>是包含对应系数(<span
class="math inline">\(a_i^k\)</span>)的向量。于是隐私掩码<span
class="math inline">\(\Delta X\)</span>的生成可以表示为：</p>
<p><img src="https://s2.loli.net/2022/08/03/9bOIfuyMd2gV5tv.png" style="zoom:67%;" /></p>
<p>其中<span
class="math inline">\(A_i^k\)</span>可以由公式(12)求得。</p>
<h4 id="generation-of-privacy-masks">3.2.2 Generation of Privacy
Masks</h4>
<p><img src="https://s2.loli.net/2022/08/03/ZSOmwornlWMyxeI.png" /></p>
<p><img src="https://s2.loli.net/2022/08/03/xHTihVlmwZQgMCy.png" /></p>
<p>坐标<span class="math inline">\(V_i^k\)</span>和系数<span
class="math inline">\(A_i^k\)</span>要在每次迭代开始的时候计算。<span
class="math inline">\(V_i^k\)</span>有closed-form solution，<span
class="math inline">\(A_i^k\)</span>没有closed-form
solution，但可以通过凸优化工具箱CVX高效求解。</p>
<h4 id="combination-with-model-transferability-methods">3.2.3
Combination with Model Transferability Methods</h4>
<p>与MI和DFANet结合。</p>
<h3 id="comparison-methods">3.3 Comparison methods</h3>
<p><strong>GD-UAP.</strong></p>
<p><strong>FI-UAP.</strong></p>
<p>用UAP的方法与FIM结合。UAP的方法是使用一些图像用DeepFool迭代去求最小扰动，并将它们聚合为通用扰动。我们将<span
class="math inline">\(\tilde X_k=\{X_1^k, X_2^k, \dots,
X_{n_k}^k\}\)</span>的梯度聚合去生成person-specific的掩码：</p>
<p><img src="https://s2.loli.net/2022/08/05/ZiIytX4uYk7oRJQ.png" style="zoom:67%;" /></p>
<p>可以被看做式子(13)的特殊情况，即对角线只有对应位置为1，其余都是0。</p>
<p><strong>FI-UAP+.</strong></p>
<p>FI-UAP也可以使用类内交互来加强，即：</p>
<p><img src="https://s2.loli.net/2022/08/05/fXr1iLYW4o9t36I.png" style="zoom:67%;" /></p>
<p>可以看做是OPOM-ClassCenter类似方法。</p>
<p><strong>FI-UAP-all.</strong></p>
<p>使用所有的训练图像去做FI-UAP.</p>
<p><strong>GAP.</strong></p>
<p>用生成式方法，根据原论文使用ResNet做generator，使用Feature-level
loss.</p>
<h2 id="experiments">4 Experiments</h2>
<p>实验包括：对OPOM保护性能的评估，OPOM与其他可迁移方法的结合性能，对商业API的性能。最后提出了person-specific隐私掩码的优缺点，OPOM在视频隐私保护中的作用和为应对潜在的隐私掩码泄露的掩码多样性。</p>
<h3 id="实验设置">4.1 实验设置</h3>
<p>使用正常人和名人两个数据集，使用1:N识别表现来衡量隐私保护率。每个人用M张图片进行测试，测试的时候每次选择1张图片放到gallery
set中，用剩下M-1张图片加上隐私掩码做probe。使用Top-1和Top-5保护成功率来进行评价。</p>
<p>代理模型使用在在CAISA-WebFace数据集上训练的Resnet50，分别用 Softmax
loss, CosFace,
ArcFace监督。使用六个黑盒模型，其中三个损失函数不同，分别用CosFace,
ArcFace, SFace;另外三个模型架构不同，分别用SENet, MobileNet,
Inception-ResNet.</p>
<h3 id="实验结果">4.2 实验结果</h3>
<h4 id="opom保护效果">4.2.1 OPOM保护效果</h4>
<p>在常人数据集合名人数据集的测试结果。</p>
<figure>
<img src="https://s2.loli.net/2022/08/05/UOiYkcBQteWFxIf.png"
alt="TABLE 2 Comparison of different methods to generate person-specific privacy masks (𝜀 = 8) from a single source model to protect face images against black-box models. We report Top-1 and Top-5 protection success rate (%) under 1:N identification setting of the Privacy-Commons dataset. The higher protection success rate is better." />
<figcaption aria-hidden="true">TABLE 2 Comparison of different methods
to generate person-specific privacy masks (𝜀 = 8) from a single source
model to protect face images against black-box models. We report Top-1
and Top-5 protection success rate (%) under 1:N identification setting
of the Privacy-Commons dataset. The higher protection success rate is
better.</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/08/05/7uX8QS52dkj6mZC.png"
alt="TABLE 3 Comparison of different methods to generate person-specific privacy masks (𝜀 = 8) from a single source model to protect face images against black-box models. We report Top-1 and Top-5 protection success rate under 1:N identification setting of the Privacy-Celebrities dataset. The higher protection success rate is better." />
<figcaption aria-hidden="true">TABLE 3 Comparison of different methods
to generate person-specific privacy masks (𝜀 = 8) from a single source
model to protect face images against black-box models. We report Top-1
and Top-5 protection success rate under 1:N identification setting of
the Privacy-Celebrities dataset. The higher protection success rate is
better.</figcaption>
</figure>
<p>可以发现，描述特征子空间的近似方法对个体隐私保护任务有影响。</p>
<p>FI-UAP只使用单个特征，不能使用其他图像的特征。OPOM-AffineHull增加了特征空间，但是过于宽松。OPOM-ClassCenter与FI-UAP+很类似，但它可能忽略不同训练点<span
class="math inline">\(f(X_i^k+\Delta
X)\)</span>的差别。OPOM-ConvexHull增加了特征空间到合适的程度，对于不同的训练点<span
class="math inline">\(f(X_i^k+\Delta
X)\)</span>使用不同的支撑点，更有效地适应不同人脸图像。</p>
<h4 id="与可迁移性方法的组合">4.2.2 与可迁移性方法的组合</h4>
<p>这两张表表示在常人和名人数据集上，与可迁移性方法结合的保护效果的提升。</p>
<figure>
<img src="https://s2.loli.net/2022/08/05/RdB51JIDKzNotUh.png"
alt="TABLE 4 Comparison of different methods combined with the momentum boosting method [32] and DFANet [34] to generate more transferable person-specific privacy masks (𝜀 = 8) from a single source model to protect face images against black-box models. We report Top-1 and Top-5 protection success rate (%) under 1:N identification setting of the Privacy-Commons dataset. The increment compared with TABLE 2 is indicated by symbol ↑." />
<figcaption aria-hidden="true">TABLE 4 Comparison of different methods
combined with the momentum boosting method [32] and DFANet [34] to
generate more transferable person-specific privacy masks (𝜀 = 8) from a
single source model to protect face images against black-box models. We
report Top-1 and Top-5 protection success rate (%) under 1:N
identification setting of the Privacy-Commons dataset. The increment
compared with TABLE 2 is indicated by symbol ↑.</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/08/05/e2pc9RjXKNLwISz.png"
alt="TABLE 5 Comparison of different methods combined with the momentum boosting method [32] and DFANet [34] to generate more transferable person-specific privacy masks (𝜀 = 8) from a single source model to protect face images against black-box models. We report Top-1 and Top-5 protection success rate (%) under 1:N identification setting of the Privacy-Celebrities dataset. The increment compared with TABLE 3 is indicated by symbol ↑." />
<figcaption aria-hidden="true">TABLE 5 Comparison of different methods
combined with the momentum boosting method [32] and DFANet [34] to
generate more transferable person-specific privacy masks (𝜀 = 8) from a
single source model to protect face images against black-box models. We
report Top-1 and Top-5 protection success rate (%) under 1:N
identification setting of the Privacy-Celebrities dataset. The increment
compared with TABLE 3 is indicated by symbol ↑.</figcaption>
</figure>
<p>随着使用动量法和DFANet，保护成功率进一步提高，但仍有提升空间。</p>
<h4 id="在商业api上的保护">4.2.3 在商业API上的保护</h4>
<figure>
<img src="https://s2.loli.net/2022/08/05/NnTrP5Lb68DOGya.png"
alt="Fig. 4. Protection against Commercial APIs (Amazon [62], Microsoft [63], Baidu [64] and Face++ [65]). Fifty identities in the PrivacyCommons dataset, each with 5 test images are used for the face verification test. The normalized average similarity/confidence scores are shown (lower is better). The original scores are listed above the bar." />
<figcaption aria-hidden="true">Fig. 4. Protection against Commercial
APIs (Amazon [62], Microsoft [63], Baidu [64] and Face++ [65]). Fifty
identities in the PrivacyCommons dataset, each with 5 test images are
used for the face verification test. The normalized average
similarity/confidence scores are shown (lower is better). The original
scores are listed above the bar.</figcaption>
</figure>
<p>可以发现，由于商业的算法训练数据比较大，单纯用CASIA-WebFace数据集训练的代理模型表现并不好，在用更多数据集进行训练后，发现保护效果大大提升。</p>
<h3 id="discussion">4.3 Discussion</h3>
<h4 id="failure-case-analysis">4.3.1 Failure Case Analysis</h4>
<p>文章给出了较容易失败的案例，每一行是一个人，左边是训练数据，中间是容易成功的图像，右边是容易失败的图像。生成的掩码在一定程度上可以泛化到其他图像上，但是如果测试图像和训练图像有显著差异，包括较大的姿势不同、光照和遮挡等，则容易失败。</p>
<figure>
<img src="https://s2.loli.net/2022/08/05/ysR3rg5IqQCKBcj.png"
alt="Fig. 5. Some failure cases, as well as the corresponding training samples and successful easily protected samples for analysis. Each row represents an identity. The privacy masks generated with OPOM can generalize to different testing images to some degree. However, if there are obvious differences between the testing images and the training samples, such as, large poses, different illuminations, and occlusions, the mask protection tends to break down." />
<figcaption aria-hidden="true">Fig. 5. Some failure cases, as well as
the corresponding training samples and successful easily protected
samples for analysis. Each row represents an identity. The privacy masks
generated with OPOM can generalize to different testing images to some
degree. However, if there are obvious differences between the testing
images and the training samples, such as, large poses, different
illuminations, and occlusions, the mask protection tends to break
down.</figcaption>
</figure>
<h4 id="why-person-spercific-effectiveness-and-efficiency">4.3.2 Why
person-spercific? Effectiveness and Efficiency</h4>
<p>文章分析了person-specific, image-specific和universal
mask的效果和效率。</p>
<p><strong>Person-specific</strong>: FI-UAP, OPOMAffineHull and
OPOM-ConvexHull.</p>
<p><strong>Universal</strong>: GD-UAP, GAP and FIUAP-all.</p>
<p><strong>Image-specific</strong>: FIM, LowKey and M-DI2-APF</p>
<p>用六个黑盒模型的平均保护率来表示效果，用Resnet-50生成100张图片的平均时间表示效率：</p>
<figure>
<img src="https://s2.loli.net/2022/08/05/2WUM1zjCOklVQDS.png"
alt="Fig. 6. Comparison of universal, person-specific (class-wise) and imagespecific masks in terms of effectiveness and efficiency." />
<figcaption aria-hidden="true">Fig. 6. Comparison of universal,
person-specific (class-wise) and imagespecific masks in terms of
effectiveness and efficiency.</figcaption>
</figure>
<p>相比于Image-specific和Universal
Mask，Person-specific在效率和效果上进行了tradeoff，更有利于普通用户和实时视频应用程序使用。</p>
<h4 id="privacy-protection-in-videos">4.3.3 Privacy Protection in
Videos</h4>
<p>在《神探夏洛克》上抽取一些帧进行实验，用在6个黑盒模型上的余弦面部相似度的平均值和标准差来证明OPOM有效性。没有隐私掩码很容易识别角色，有隐私掩码可免于被识别。并发现使用15张图片进行训练，保护效果最好。</p>
<figure>
<img src="https://s2.loli.net/2022/08/05/qmjBXga1vwRIGCp.png"
alt="Fig. 8. Application of OPOM in video privacy protection, Sherlock [66]. The privacy masks are trained with other face images of actors (Benedict Cumberbatch and Martin Freeman). The average cosine similarity between the deep features of the detected face in the video and the deep features of the corresponding characters (Sherlock Holmes and Doctor John Watson) is used to demonstrate the effectiveness." />
<figcaption aria-hidden="true">Fig. 8. Application of OPOM in video
privacy protection, Sherlock [66]. The privacy masks are trained with
other face images of actors (Benedict Cumberbatch and Martin Freeman).
The average cosine similarity between the deep features of the detected
face in the video and the deep features of the corresponding characters
(Sherlock Holmes and Doctor John Watson) is used to demonstrate the
effectiveness.</figcaption>
</figure>
<h4 id="diversity-of-privacy-masks">4.3.4 Diversity of Privacy
Masks</h4>
<p>如果存在信息泄露，则设计的隐私掩码有可能失效，于是本文设计了多个隐私掩码，向不同的方向进行优化。</p>
<p><img src="https://s2.loli.net/2022/08/05/mJTHcsVMLphkE3w.png" style="zoom:67%;" /></p>
<p>即保证隐私保护效果，也让不同掩码之间的距离足够大。</p>
<p>在实验中，也考虑到不同的被掩码保护的图像放在gallery
set中，但文章没有给出具体细节。</p>
<p><img src="https://s2.loli.net/2022/08/05/5TR4HnXC7bOM9om.png"
alt="TABLE 6 Diverse person-specific privacy masks (𝜀 = 8) from a single source model to protect face images against black-box models. Here, “M-O” denotes that the masked image is used as the probe, while the original image is recorded in the gallery set. “M-M” represents masked image has been collected and applied in the gallery set, and new masked image is used as the probe. (The same mask is used for 𝑛𝑀=1.) We report the Top-1 protection success rate (%) under 1:N identification setting of Privacy-Commons dataset. The higher protection success rate is better." />实验结果表明，person-specific的隐私掩码可以是多样的，但随着隐私掩码数量增多，保护率会下降。</p>
<h2 id="conclusion">5. Conclusion</h2>
<p>本文提出了一种class-wise的通用对抗扰动进行隐私保护的方法，通过生成一个可用于一个人所有图像的<strong>person-specific掩码</strong>。实验结果表明了该方法在定制化隐私保护任务中的有效性和优越性。我们已经证明了所提出的方法可以<strong>用于视频</strong>的隐私保护。已经取得了巨大的进展，但仍有许多工作要做。正如之前所说的，如果<strong>测试图像和训练样本之间存在明显的差异，那么提供保护是具有挑战性的</strong>。因此，需要进一步提高<strong>Individual
Universality</strong>，以覆盖人脸图像潜在的多种变换，如较大姿态不同、不同光照和遮挡。如前所述，我们考虑了多掩码来解决隐私掩码泄漏的潜在问题。然而，<strong>所提出的方法在隐私掩码的多样性和效果方面存在挑战</strong>，因此仍是一个初步的探索。此外，我们目前正处于生成只能用于社交媒体上的数字图像和视频的数字隐身衣的实施阶段。如果它们能应用于<strong>现实世界</strong>的视频监控，将会产生更大的影响。</p>
<hr />
<h2 id="总结">总结</h2>
<ol type="1">
<li><p>提出person-specific隐私掩码的新方向，有很大的启发意义，后续研究空间也很大。</p></li>
<li><p>提出的估计特征子空间的方法用到凸优化一些定义，很有趣，但估计特征子空间的方法只有ConvexHull比FI-UAP+(ClassCenter)效果好，提升也不是很大，有较大的改进空间。</p></li>
<li><p>但有趣的一点是，在与迁移性方法结合后，各方法性能提升都很多，但AffineHull,
ClassCenter和ConvexHull效果十分相近，文章并没有分析并给出解释。这么看起来就有了疑问，提出的估计特征子空间的方法得到的性能提升，到底是因为估计得更精准而提高了Individual
Universality，还是在另一个方向上提高了Model Transferability？
我觉得应该补充实验，在白盒的设定下评估Individual
Universality。（更正：可能有白盒设定，但文章里写得也不清晰。如果确实有白盒的话，则确实能表示提出的方法在估计特征子空间提高Individual
Universality的有效性，但为何与迁移性方法结合之后就抹平了差距？）</p></li>
<li><p>在商业API的实验中，生成的掩码的保护效果与代理模型关系很大，用大量数据训练的代理模型与商业黑盒模型的gap可能更小，得到的掩码保护效果更好（其实还是Model
Transferability的问题）。</p></li>
</ol>
<p><strong>不足</strong></p>
<ol type="1">
<li>在处理训练图像与测试图像gap较大场景时效果很差，Individual
Universality的问题，需要更好的估计特征子空间的方法。</li>
<li>在代理模型和黑盒模型训练数据有较大差距的时候，即代理模型与黑盒模型gap很大，则生成的掩码效果差，是Model
Transferability的问题，需要更好的方法来提高迁移性。</li>
<li>隐私掩码多样性也需要探索，直接生成相距较远的多个隐私掩码，得到的保护率会下降。</li>
<li>现实世界的应用，较为困难。</li>
</ol>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>[论文阅读] Transferable Sparse Adversarial Attack</title>
    <url>/2022/07/16/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Transferable-Sparse-Adversarial-Attack/</url>
    <content><![CDATA[<center>
CVPR2022 可迁移的稀疏对抗攻击
</center>
<span id="more"></span>
<p>题目：Transferable Sparse Adversarial Attack</p>
<p>作者：Ziwen He</p>
<p>会议：CVPR2022</p>
<p>链接：<a
href="https://openaccess.thecvf.com/content/CVPR2022/papers/He_Transferable_Sparse_Adversarial_Attack_CVPR_2022_paper.pdf">文章链接</a></p>
<hr />
<h3 id="摘要翻译">摘要翻译</h3>
<p>​
深度神经网络已经表现出对对抗攻击的脆弱性。在本文中，我们聚焦于<strong>基于l0范数的稀疏对抗攻击</strong>，只用次改几个像素即可攻击成功。先前的稀疏攻击方法尽管有高攻击成功率，但在黑盒设置下，由于对代理模型的过拟合，对抗样本具有较低的迁移性。因此，我们提出了一个生成器架构去减轻过拟合问题，并且有效地生成可迁移的稀疏对抗样本。<strong>特别的，我们提出的生成器将稀疏扰动解耦为振幅和位置分量。我们精心设计了一个随机量化算子，以用端到端的方法联合优化这两个分量。</strong>实验表明我们的方法在相似的系数性设置下，相比于SOTA已经大大提升了迁移性。除此之外，我们的方法也实现了优越的<strong>推理速度</strong>，比其他基于优化的方法快了700倍。代码已公开。</p>
<h3 id="基本问题">基本问题</h3>
<ul>
<li><strong>论文解决的问题：</strong> 基于L0范数的稀疏对抗攻击</li>
<li><strong>动机：</strong>
<ol type="1">
<li>现有的稀疏对抗方法如PGD0, SparseFool,
GreedyFool依赖于目标模型的梯度或其估计，具有较低的迁移性。并且有研究表明<span
class="math inline">\(l_2\)</span>和<span
class="math inline">\(l_\infin\)</span>范数限制的攻击在不同架构模型下更具有迁移性，<span
class="math inline">\(l_0\)</span>范数限制的稀疏对抗样本的迁移性还未知。</li>
<li>之前的生成式方法都只生成稠密扰动，本文工作与之前生成式方法最大的不同就是有稀疏性的限制。</li>
</ol></li>
<li><strong>贡献：</strong>
<ul>
<li>探索稀疏对抗样本迁移性问题，并提出一个生成可迁移的稀疏对抗样本的方法。</li>
</ul></li>
</ul>
<h3 id="method">Method</h3>
<h4 id="analysis">Analysis</h4>
<p>对于无目标攻击，要优化的问题是：</p>
<p><img src="https://s2.loli.net/2022/07/16/QZKBAzEDCjrf5s2.png" /></p>
<p>其中 <span class="math inline">\(\epsilon\)</span> 是<span
class="math inline">\(l_\infty\)</span>的扰动限制，如果是有目标攻击，则第二行要换为<span
class="math inline">\(arg\,max_c\,\,F(x_{adv})_c=y_t\)</span>， <span
class="math inline">\(f(x)_c\)</span> 是类别c的logit值，目标类别是<span
class="math inline">\(y_t\)</span> 。</p>
<p>之前的稀疏攻击方法很大的依赖于单个图像的梯度，而基于生成的方法，生成器可以学到自然图像到稀疏对抗图像的映射，生成器的参数是由数据分布学习到的，而不是单个图像。大量的训练数据可以减轻过拟合，增加迁移性。</p>
<p>（这里提出了用生成式的方法提升稀疏样本的迁移性，于是以下该探索如何设计一个生成器架构）。</p>
<p>但是优化上式是一个Np hard的问题，先前的工作是优化近似的<span
class="math inline">\(l_1\)</span>约束问题，如SparseFool，但其方法中包含了不可微分的步骤，于是不能进行端到端训练。</p>
<p>要解决这个<span
class="math inline">\(l_1\)</span>约束问题最直接的方法就是加一个<span
class="math inline">\(l_1\)</span>正则化项，但是这样做会使生成的扰动收敛于0，生成稠密扰动，如果直接在这个稠密扰动上面使用二值化（即选某些点保留扰动，其余不扰动），则会丢失信息而导致样本不再有攻击性。本文使用将扰动分解为幅度和位置两个变量的哈达玛乘积来解决这个问题，即<span
class="math inline">\(\delta =r \odot m\)</span>， 其中<span
class="math inline">\(r\in R^N\)</span>，是扰动大小，<span
class="math inline">\(m\in
\{0,1\}^N\)</span>，是表示此位置是否施加扰动。同时优化这两个向量，并且只给向量
<span class="math inline">\(m\)</span> 添加 <span
class="math inline">\(l_1\)</span> 正则，即可实现稀疏的目标。</p>
<h4 id="framework">Framework</h4>
<figure>
<img src="https://s2.loli.net/2022/07/16/YuWkryZzCdJ3UsA.png"
alt="Figure 1: Our framework for generating transferable sparse adversarial examples." />
<figcaption aria-hidden="true">Figure 1: Our framework for generating
transferable sparse adversarial examples.</figcaption>
</figure>
<p>如上图，实现了两个分支分别生成 <span class="math inline">\(r\)</span>
和 <span class="math inline">\(m\)</span>。</p>
<p>记编码器为<span class="math inline">\(E\)</span>，
则编码器生成的latent code <span class="math inline">\(z =
E(x)\)</span>，之后 $z $ 将被送入<span
class="math inline">\(D_1,D_2\)</span>两个解码器。</p>
<p><span class="math inline">\(D_1\)</span> 生成对抗扰动的大小，结果
<span class="math inline">\(r\)</span> 将<span
class="math inline">\(D_1(z)\)</span> 缩放到<span
class="math inline">\([-255, 255]\)</span> 之间。</p>
<p><span class="math inline">\(D_2\)</span> 生成向量<span
class="math inline">\(Q\in [0,1]^N\)</span>，为得到离散的向量 <span
class="math inline">\(m\)</span>，使用一个二值化算子 <span
class="math inline">\(q\)</span></p>
<p><img src="https://s2.loli.net/2022/07/16/sw3Kqa2IdBvmi7y.png" /></p>
<p>但显然这个函数的梯度都是0，会导致<span
class="math inline">\(D_2\)</span>的参数无法更新，于是本文设计了一个随机算子，随机变量<span
class="math inline">\(X\in \{0, 1\}\)</span>，如果<span
class="math inline">\(X=1\)</span>，则<span
class="math inline">\(Q_{i,j}\)</span>被量化为0,1，否则<span
class="math inline">\(q_{i,j}=Q_{i,j}\)</span>。其中<span
class="math inline">\(X\)</span>服从参数为p的伯努利分布，p为<span
class="math inline">\(X=1\)</span>的概率。</p>
<p>其实就是，如果<span class="math inline">\(X=1\)</span>，则<span
class="math inline">\(Q\)</span>被量化，阻断反向传播；如果<span
class="math inline">\(X=0\)</span>，则<span
class="math inline">\(Q\)</span>保持原状，允许梯度传递，从而可以更改<span
class="math inline">\(D_2\)</span>的参数。</p>
<p>在推理过程中， p设置为1。</p>
<h4 id="loss-functions">Loss functions</h4>
<h5 id="adversial-loss">Adversial loss</h5>
<p>这里使用C&amp;W的loss</p>
<p><img src="https://s2.loli.net/2022/07/16/OqhxTN7yS2Ufk4H.png" /></p>
<p>如果是有目标攻击的话，使用</p>
<p><img src="https://s2.loli.net/2022/07/17/ZHVzntyFrb1vPIf.png" /></p>
<p>代替第一项。</p>
<h5 id="sparse-loss">Sparse loss</h5>
<p><img src="https://s2.loli.net/2022/07/17/cInl2au5YNAbTeG.png" /></p>
<p>本方法的稀疏度主要是由 <span class="math inline">\(m\)</span>
决定的，由于<span
class="math inline">\(L_0\)</span>很难优化求解，于是使用<span
class="math inline">\(L_1\)</span>代替（L1范数是L0范数的最优凸近似，且L1范数容易优化求解），相应的，在下面的loss中，我们要让<span
class="math inline">\(m\)</span>中的值尽量趋近于0或者1。</p>
<h5 id="quantization-loss">Quantization loss</h5>
<p>为减小训练和测试之间的gap，在损失函数中增加一项，使得Qij的值趋近于0或1</p>
<p><img src="https://s2.loli.net/2022/07/17/3eSnOVKMZ6AUtTY.png" /></p>
<p>总体loss为</p>
<p><img src="https://s2.loli.net/2022/07/17/WPTr6gS25Fopn38.png" /></p>
<h3 id="实验">实验</h3>
<p>大致进行了四个实验。</p>
<ol type="1">
<li>在类似的稀疏约束条件下，在不同的<span
class="math inline">\(l_\infty\)</span>条件下，测试与另外三个稀疏对抗攻击算法的Non-target的性能。</li>
<li>在类似的稀疏约束条件下，测试与另外两个稀疏对抗攻击算法在Target设定下的性能。但目标类别只有两个，“秃鹫”和“泡泡”。</li>
<li>与GAP和Cross-domain
perturbations在Non-target设定下进行相似评估。</li>
<li>消融实验：（1）不解耦为幅度和位置分量的性能；（2）训练时使p=0时（即不进行量化）的性能，q=STE的性能；（3）不使用稀疏性约束loss（即不要L0约束）的性能；（4）不使用量化损失的性能；（5）对于每张图片训练自己的生成器的性能。</li>
</ol>
<p>实验结果描述为：</p>
<ol type="1">
<li><p>相比于其他三个类似的方法，这个方法在Non-target下的迁移性大大提升，（白盒下效果反而不好，这是由于使用训练好的生成器做的原因，不过不重要）</p>
<figure>
<img src="https://s2.loli.net/2022/07/17/qUTpRi6z9xoZV1P.png"
alt="Table 1: `∞ = 255 constrained non-targeted attack transferability comparison on ImageNet dataset. The best speed and transfer rate are shown in bold. ‘*’ means white-box setting." />
<figcaption aria-hidden="true">Table 1: `∞ = 255 constrained
non-targeted attack transferability comparison on ImageNet dataset. The
best speed and transfer rate are shown in bold. ‘*’ means white-box
setting.</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/07/17/KJtF6GQMDCnwN3g.png"
alt="Table 2: `∞ = 10 constrained non-targeted attack transferability comparison on ImageNet dataset. The best speed and transfer rate are shown in bold. ‘*’ means white-box setting." />
<figcaption aria-hidden="true">Table 2: `∞ = 10 constrained non-targeted
attack transferability comparison on ImageNet dataset. The best speed
and transfer rate are shown in bold. ‘*’ means white-box
setting.</figcaption>
</figure></li>
<li><p>相比于其他两个类似的方法，这个方法在Target设定下也有一定的迁移效果，其他两种方法迁移性很差。随有提升，但貌似也不高。在实验中只进行了两个target
class的实验，迁移性差别明显，可能是未来研究的一个方向。</p>
<figure>
<img src="https://s2.loli.net/2022/07/17/zKREC3Ng4hPJes8.png"
alt="Table 3: Targeted attack transferability comparison. The source model is IncV3 and attacks are performed on ImageNet dataset, with `∞ = 255 constraint. The best speed and transfer rate are shown in bold. ‘*’ means white-box setting." />
<figcaption aria-hidden="true">Table 3: Targeted attack transferability
comparison. The source model is IncV3 and attacks are performed on
ImageNet dataset, with `∞ = 255 constraint. The best speed and transfer
rate are shown in bold. ‘*’ means white-box setting.</figcaption>
</figure></li>
<li><p>相比于其他的基于生成的方法，发现在进行更少的扰动的情况下，也能达到甚至超过稠密扰动的生成式方法，这表明有很多扰动是无用的，甚至有负优化。</p>
<figure>
<img src="https://s2.loli.net/2022/07/17/FNbl83EtUmn2RhQ.png"
alt="Table 4: Comparison with generator-based dense attacks. Results are sparsity(%) and fooling rate(%) on different models. ‘*’ means white-box setting." />
<figcaption aria-hidden="true">Table 4: Comparison with generator-based
dense attacks. Results are sparsity(%) and fooling rate(%) on different
models. ‘*’ means white-box setting.</figcaption>
</figure></li>
<li><p>（1）去掉解耦，发现不能真正的实现稀疏。</p>
<p>（2）去掉量化，即使训练中的p=0，发现仍能实现稀疏，但是生成的对抗样本迁移性下降。并且与STE方法比较，发现结果比STE方法好。</p>
<p>（3）去掉sparse loss，生成的对抗样本变为100%的dense attack。</p>
<p>（4）去掉quantization
loss，稀疏程度提高了（更改像素变多），并且迁移性降低了，验证了量化操作带来的信息损失会影响测试时的性能。</p>
<p>（5）使用每张图片生成自己的生成器的方法，发现白盒攻击效果提高了，但是黑盒攻击迁移性降低了，证明使用大量数据进行训练可以减小过拟合并提高迁移性的假设是正确的。</p>
<figure>
<img src="https://s2.loli.net/2022/07/17/npc5NCajtmWSHPF.png"
alt="Table 5: Ablation study of the proposed framework. Results are sparsity(%) and fooling rate(%) on different models (fooling rate is not studied if sparsity is not satisfactory). ‘*’ means white-box setting." />
<figcaption aria-hidden="true">Table 5: Ablation study of the proposed
framework. Results are sparsity(%) and fooling rate(%) on different
models (fooling rate is not studied if sparsity is not satisfactory).
‘*’ means white-box setting.</figcaption>
</figure></li>
</ol>
<h3 id="结论">结论</h3>
<p>本文提出了一种基于生成器的稀疏对抗攻击框架。在相同的稀疏性条件下，该方法比现有的现有方法具有更强的可迁移性，推理速度更快。根据经验，我们观察到，当对大规模ImageNet攻击时，我们的方法产生最先进的结果。我们的工作阐明了可转移的基于<span
class="math inline">\(l_0\)</span>的稀疏对抗样本的存在，并说明了最先进的白盒稀疏攻击方法倾向于找到修改像素数量最少但不具有迁移性的对抗样本。这两种类型的稀疏对抗攻击对于分析dnn的漏洞和评估安全风险(如在物理世界中创建可转移的对抗补丁来欺骗自动驾驶汽车)同样重要。</p>
<h3 id="思考">思考</h3>
<p>方法的局限或问题：</p>
<ol type="1">
<li>用的损失函数是C&amp;W的loss，与人脸识别中通常使用的特征图的余弦值或L2dis不同。</li>
<li>直觉上觉得，这个方法只适用于黑盒模型训练数据已知的情况。①如果黑盒模型训练数据未知（这里想强调的是类别不知道），则无法使用C&amp;W
loss，无法使用logits。②如果训练数据未知，那么学出的样本到对抗样本之间的映射，是不是有domain
shift。</li>
</ol>
<p>几个想法：</p>
<ol type="1">
<li>在训练数据未知的情况下。如果使用大量数据进行预训练，并且在单张图片上进行fine
tune的效果如何？</li>
<li>如何将这个方法迁移到人脸识别系统的攻击上。这个方法是否与对抗补丁有联系。</li>
<li>提出的随机化量化方法很有趣，模型性能与p的关系是什么呢。当Q被量化为0,1时，阻断反向传播，这时Dec2参数不更新，并按照测试条件更新Dec1参数；当Q不被量化时，允许梯度的传递，这时Dec2参数进行更新（既有让结果趋近0或1，也有生成效果更好的对抗样本），同时Dec1也在更新参数，只不过设定是训练条件下。</li>
</ol>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>[论文阅读] Towards Face Encryption by Generating Adversarial Identity Masks</title>
    <url>/2022/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Towards-Face-Encryption-by-Generating-Adversarial-Identity-Masks/</url>
    <content><![CDATA[<center>
ICCV2021 通过生成对抗性身份掩码来进行人脸加密
</center>
<span id="more"></span>
<p>题目：Towards Face Encryption by Generating Adversarial Identity
Masks</p>
<p>作者：Xiao Yang, Yinpeng Dong, Tianyu Pang, Hang Su, Jun Zhu, Yuefeng
Chen, Hui Xue</p>
<p>链接：<a
href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yang_Towards_Face_Encryption_by_Generating_Adversarial_Identity_Masks_ICCV_2021_paper.pdf">文章链接</a></p>
<p>代码链接：<a
href="https://github.com/ShawnXYang/TIP-IM">代码链接</a></p>
<hr />
<h2 id="摘要翻译">1 摘要翻译</h2>
<p>随着数以亿计的个人数据通过社交媒体和网络共享，数据的隐私和安全问题越来越受到关注。为了减少面部照片泄露身份信息的情况，已作出了一些尝试，例如利用图像模糊处理技术。然而，目前的大多数结果不是<strong>对可感知性不满意</strong>，就是对人脸识别系统<strong>攻击低效</strong>。我们在本文中的目标是开发一种技术，可以加密个人照片，这样它们可以保护用户不受未经授权的人脸识别系统的影响，但在视觉上仍然与人类的原始版本相同。为此，我们提出了一种有针对性的身份保护迭代方法<strong>target
identity-protection iterative
method(TIP-IM)</strong>来生成对抗性的身份面具，该面具可以叠加在人脸图像上，这样就可以在<strong>不牺牲视觉质量</strong>的情况下隐藏身份。大量实验表明，在实际测试场景下，TIP-IM对各种最先进的人脸识别模型提供了95%以上的保护成功率。此外，我们还展示了我们的方法在一个商业API服务上的实际和有效的适用性。</p>
<h3 id="基本问题">基本问题</h3>
<ul>
<li>论文解决的问题：为人脸图像生成不可感知的、有效的隐私保护掩码。</li>
</ul>
<h2 id="introduction">2 Introduction</h2>
<figure>
<img src="https://s2.loli.net/2022/08/10/BcuE7rg8sJtYlid.png"
alt="Figure 1. An illustrative example of targeted identity protection. When users share a photo xr on social media (e.g., Twitter, Facebook, etc.), unauthorized applications could scrabble this identity y0 based on face recognition systems, resulting in the privacy leakage of personal information. Thus we provide an effective identity mask tool to generate a protected image xp, which can conceal the corresponding identity by misleading the malicious systems to predict it as a wrong target identity yt in an authorized or virtual target set, which can be provided by the service providers." />
<figcaption aria-hidden="true">Figure 1. An illustrative example of
targeted identity protection. When users share a photo xr on social
media (e.g., Twitter, Facebook, etc.), unauthorized applications could
scrabble this identity y0 based on face recognition systems, resulting
in the privacy leakage of personal information. Thus we provide an
effective identity mask tool to generate a protected image xp, which can
conceal the corresponding identity by misleading the malicious systems
to predict it as a wrong target identity yt in an authorized or virtual
target set, which can be provided by the service providers.</figcaption>
</figure>
<p>社交媒体和网络的蓬勃发展带来了大量的个人数据(如照片)被公开分享。随着深度神经网络的日益普及，这些技术极大地提高了人脸识别系统处理个人数据的能力，但作为副产品，也增加了个人信息隐私泄露的潜在风险。例如，未经授权的第三方可能会在未经许可的情况下抓取和识别社交媒体(如Twitter,
Facebook,
LinkedIn等)上共享的照片。因此，在不影响用户体验的前提下，为用户提供一种有效的方式来保护其隐私信息不被未经授权的系统识别和泄露是必要的。<strong>（提出人脸隐私保护的必要性）</strong></p>
<p>过去的几年见证了人脸加密在安全和计算机视觉领域的进步。在现有的技术中，<strong>基于模糊的方法</strong>得到了广泛的研究。传统的模糊处理技术，如模糊化、像素化、暗化和遮挡，可能在可感知性上令人满意或能有效地对抗识别系统。<strong>生成对抗网络(GANs)</strong>的最新进展为生成更真实的图像进行模糊处理提供了一种很有吸引力的方法。但由于对某些有判别力的特征进行了夸张和抑制，得到的模糊图像在视觉外观上与原始图像有显著差异，偶尔会产生带有伪影的不自然的输出图像。<strong>（用模糊方法进行人脸加密）</strong></p>
<p>最近的研究发现，<strong>对抗样本</strong>通过在原始图像上叠加对抗性扰动，可以逃避FR系统的识别。它成为了一种很有吸引力的方式来应用对抗扰动来隐藏一个人的身份，即使是在更严格的限制下<strong>模仿</strong>一些被授权的或生成的人脸图像(例如，由社交媒体服务提供)。它提供了一种可能的解决方案来指定输出，这可能会<strong>避免侵犯他人的隐私</strong>（图像被识别为任意身份）。尽管如此，应该注意到，尽管现有方法(如PGD和MIM)产生的对抗扰动的强度变化很小(如[0,255]中每个像素的强度变化为12或16)，但由于Fig.2所示的伪影，它们仍然可能<strong>牺牲视觉质量</strong>，并且有研究指出，ℓp-范数限制的对抗扰动不能很好地适应人类感知。此外，目前的对抗攻击主要依赖于目标系统的<strong>白盒模型</strong>或大量的<strong>模型查询</strong>，这在现实场景中(如社交媒体上的未经授权的人脸识别系统)难以实现身份保护。<strong>（用对抗样本进行人脸加密及不足）</strong></p>
<p>在本文中，我们从普通用户的角度考虑了一些有价值的问题，并提出了缓解真实社交媒体中个人照片身份泄露的建议。我们特别关注<strong>face
identification</strong>，这是人脸识别中一个典型的子任务，其目标是在一个未知的gallery
identity
set中识别真实的人脸图像，我们的目标是<strong>将真实的人脸图像识别为一个unknown
gallery identity
set</strong>，因为它可以被未经授权的应用程序用于识别用户的身份信息。如Fig.1所示，人脸加密是为了阻止恶意应用程序的自动推理能力，使其预测服务提供商错误的被授权的授权或虚拟目标。一般来说，人们对人脸识别系统不可知，不可能直接访问查询。因此，我们需要针对代理模型生成对抗掩码，以欺骗<strong>黑盒</strong>人脸识别系统。此外，当用户在社交媒体上分享受保护的照片时，我们尽量<strong>不影响用户体验</strong>，同时对未经授权的识别系统<strong>隐藏其身份</strong>。因此，受保护的图像在视觉上也应该像相应的原始图像一样然，否则可能会引入不希望看到的伪影。<strong>（本文提出的方法的一些考虑，target
set，黑盒，自然）</strong></p>
<p>为了解决上述挑战，我们提出了<strong>targeted identity-protection
iterative
method(TIP-IM)</strong>来对黑盒人脸识别系统进行人脸加密。提出的方法生成<strong>可迁移的且不可察觉的</strong>对抗身份掩码。好的可迁移性意味着一个模型可以有效地欺骗其他黑盒人脸识别系统，同时不可感知性意味着一张由对抗身份掩码处理的照片在视觉上对人类来说是自然的。具体来说，<strong>为了确保生成的图像不会被任意误分类为其他身份，我们从互联网上收集的数据集中随机选择一组人脸图像作为我们实验中指定的目标</strong>。该方法通过一种新颖的迭代优化算法，在<strong>多目标识别</strong>的白盒和黑盒人脸系统中获得了较好的性能。<strong>（本文提出方法的具体内容，可迁移，不可感知，多目标）</strong></p>
<p>在实际和具有挑战性的open-set测试场景下进行的大量实验表明，我们的算法对白盒人脸系统提供了95%以上的保护成功率，并且即使与各种最先进的算法相比，也比以前的方法有一定的优势。此外，我们还通过考虑一个商业API服务，在一个真实世界的实验中证明了它的有效性。我们的主要贡献总结如下:</p>
<ul>
<li>从用户的角度出发，我们涉及到一些有价值的考虑，以保护隐私免受未经授权的身份识别系统的侵害，包括<strong>target
protection、natural output、black-box system和unknown gallery
set</strong>。</li>
<li>我们提出了targeted identity-protection iterative
method(TIP-IM)来生成对抗身份掩码，该方法考虑了<strong>多目标集</strong>，并引入了一种<strong>新的优化机制</strong>来保证在不同场景下的有效性。</li>
</ul>
<p><img src="https://s2.loli.net/2022/08/10/QdI3BFlnt9bfcaU.png" alt="Figure 2. Illustration of different perturbations under the l∞ norm. More examples are presented in Appendix D." style="zoom:67%;" /></p>
<h2 id="adversarial-identity-mask">3 Adversarial Identity Mask</h2>
<p>用<span class="math inline">\(f(\mathbf{x} ):\chi \to
\mathcal{R}^d\)</span> 表示一个人脸识别系统，对一个人脸图像<span
class="math inline">\(\mathbf{x}\in \mathcal{X}\subset
\mathcal{R}^n\)</span>提取在<span
class="math inline">\(\mathcal{R}^d\)</span>内固定长度的特征表示。给定度量<span
class="math inline">\(\mathcal{D}_f(\mathbf{x}_1,
\mathbf{x}_2)=||f(\mathbf{x}_1)-f(\mathbf{x}_2)||_2^2\)</span>来描述两张人脸图像的特征距离。人脸识别是识别一个probe图像和一个人脸图像集合<span
class="math inline">\(\mathcal{G}=\{\mathbf{x}_1^g,
\dots,\mathbf{x}_m^g\}\)</span>，并返回其中与probe图像特征距离最近的图像的身份。</p>
<p>在本文中，我们从用户的角度考虑了一些有价值的因素，以保护用户的照片不受非法人脸识别系统的影响。具体来说，为了隐藏用户图像<span
class="math inline">\(\mathbf{x}^r\)</span>的真实身份<span
class="math inline">\(y\)</span>，我们通过在<span
class="math inline">\(\mathbf{x}^r\)</span>上添加一个对抗性身份掩码<span
class="math inline">\(\mathbf{m}^a\)</span>来生成一个被保护的图像<span
class="math inline">\(\mathbf{x}^p\)</span>，可以表示为<span
class="math inline">\(\mathbf{x}^p=\mathbf{x}^r+\mathbf{m}^a\)</span>，来使人脸识别系统将<span
class="math inline">\(\mathbf{x}^p\)</span>识别为不同的被授权的身份或者生成图像对应的虚拟的身份。与指定一个目标身份来生成保护图像不同，我们选择一个身份集合<span
class="math inline">\(\mathcal{T}=\{y_1, \dots,
y_k\}\)</span>，我们使人人脸识别系统将被保护图像识别为<span
class="math inline">\(\mathcal{T}\)</span>中的任意一个目标身份，这样可以使身份保护更容易实现。</p>
<p>正式的说，使<span class="math inline">\(\mathcal{G}_y=\{x|x\in
\mathcal{G}, \mathcal{O}(\mathbf{x})=y\}\)</span>表示包含<span
class="math inline">\(\mathcal{G}\)</span>中所有属于<span
class="math inline">\(\mathbf{x}^r\)</span>的真实身份<span
class="math inline">\(y\)</span>的所有人脸图像的集合，其中<span
class="math inline">\(\mathcal{O}\)</span>的作用是给出图像的ground-truth，并且<span
class="math inline">\(\mathcal{G}_\mathcal{T}=\cup _{q\le i \le k}
\mathcal{G}_{y_i}\)</span>表示gallery set <span
class="math inline">\(\mathcal{G}\)</span>中包含的所有属于<span
class="math inline">\(\mathcal{T}\)</span>的目标身份的图像的集合。为了隐藏<span
class="math inline">\(\mathbf{x}^r\)</span>的身份，生成的保护图像<span
class="math inline">\(\mathbf{x}^p\)</span>要满足约束 <span
class="math display">\[
\exists \mathbf{x}^t\in \mathcal{G}_\mathcal{T}, \forall \mathbf{x}\in
\mathcal{G}_y:\mathcal{D}_f(\mathbf{x}^p,
\mathbf{x})&gt;\mathcal{D}_f(\mathbf{x}^p,
\mathbf{x}^t)     \,\,\,\,\,\,(1)
\]</span>
与之前研究的设定相比，我们从一般用户的角度考虑了更多的实际问题，主要体现在以下三个方面：</p>
<ul>
<li><p><strong>Naturalness</strong></p>
<p>为了使被保护图像与原始图像难以区分，通常的做法是限制保护图像与原始图像之间的ℓp
(p =
2，∞等)范数。然而，ℓp范数下的扰动不能自然地很好地拟合人类的感知。因此，我们要求受保护图像除了ℓp范数界的约束外，还要看起来自然，使其<strong>约束于真实图像的数据流形</strong>，从而达到人眼无法察觉的效果。我们使用一个<strong>目标函数</strong>来提高被保护图像的自然度。</p></li>
<li><p><strong>Unawareness of gallery set</strong></p>
<p>对于一个真实的人脸识别系统，我们不知道它的gallery set <span
class="math inline">\(\mathcal{G}\)</span>，这也表明不可能直接求解上式(1)，而以前的工作假设gallery
set可以访问或者是closed-set设定。为了解决这个问题，我们使用<strong>替代人脸图像</strong>进行优化。具体的，我们收集图像集<strong><span
class="math inline">\(\tilde{\mathcal{G}_\mathcal{T}}\)</span></strong>，包含目标身份<span
class="math inline">\(\mathcal{T}\)</span>的人脸图像作为 <span
class="math inline">\(\mathcal{G}_\mathcal{T}\)</span>的替代，并且使用<span
class="math inline">\(\{\mathbf{x}^r\}\)</span>而不是<span
class="math inline">\(\mathcal{G}_y\)</span>。使用替代图像的合理性在于，一个身份的人脸表征是相似的，因此优化后的与替代图像相似的受保护图像的表征也可以接近gallery
set中属于相同目标身份的图像。</p></li>
<li><p><strong>Unknown face system</strong></p>
<p>在实践中，我们也不知道人脸识别模型，包括它的架构、参数和梯度。以前的方法依赖于对目标模型的白盒访问，这在真实的身份保护场景中是不切实际的。因此，我们采用<strong>代理白盒模型</strong>来生成受保护的图像，以提高对抗式掩码对未知人脸系统的<strong>可迁移性</strong>。</p></li>
</ul>
<h2 id="methodology">4 Methodology</h2>
<h3 id="problem-formulation">4.1 Problem Formulation</h3>
<p>将目标隐私保护函数定义为：</p>
<p><img src="https://s2.loli.net/2022/08/10/SPwBcjQpzCO76x9.png" style="zoom:67%;" /></p>
<p>其中，<span class="math inline">\(\mathbf{x}^t\in
\tilde{\mathcal{G}_\mathcal{T}}\)</span>，并且<span
class="math inline">\(\mathcal{L}_{iden}\)</span>
是一个相对的识别损失，是生成的<span
class="math inline">\(\mathbf{x}^p\)</span>在特征空间上增加与<span
class="math inline">\(\mathbf{x}^r\)</span>的距离，缩小与<span
class="math inline">\(\mathbf{x}^t\)</span>的距离。$_{nat}$ 是使<span
class="math inline">\(\mathbf{x}^p\)</span>看起来自然的限制条件。同时也限制了<span
class="math inline">\(l_p\,\,norm\)</span>。</p>
<p>本文中使用<strong>maximum mean discrepancy(MMD)</strong> 作为<span
class="math inline">\(\mathcal{L}_{nat}\)</span>，因为它是一种有效的非参数和可微的度量，能够比较两个数据分布和评估生成的图像的不可感知性。即给定两个数据集合<span
class="math inline">\(\mathbf{X}^p=\{\mathbf{x}_1^p, \dots,
\mathbf{x}_2^p\}\)</span> 和 <span
class="math inline">\(\mathbf{X}^r=\{\mathbf{x}_1^r, \dots,
\mathbf{x}_2^r\}\)</span>，由N个生成的图像和N个真实的图像组成，MMD通过下式算两个分布的差异：</p>
<p><img src="https://s2.loli.net/2022/08/10/qnULCo71T6NBJQe.png" /></p>
<p>其中<span
class="math inline">\(\phi(·)\)</span>将数据映射到再生核希尔伯特空间中(RKHS)。</p>
<p>通过最小化生成分布的样本<span
class="math inline">\(\mathbf{X}^p\)</span>和真实数据分布的样本<span
class="math inline">\(\mathbf{X}^r\)</span>之间的MMD，我们可以将<span
class="math inline">\(\mathbf{X}^p\)</span>约束在真实数据分布的流形上，这意味着<span
class="math inline">\(\mathbf{X}^p\)</span>中被保护的图像将像真实的图像一样自然。</p>
<p>由于MMD是一种可微的度量，并且定义在batch上，因此我们将MMD集成到Eq.(2)中，并用batch-based的公式重写目标为：</p>
<p><img src="https://s2.loli.net/2022/08/10/1XoWjtNMTlAhe5E.png" style="zoom:67%;" /></p>
<p>其中，<span class="math inline">\(\mathbf{x}_i^t\in
\tilde{\mathcal{G}_\mathcal{T}}\)</span>，是<span
class="math inline">\(\mathbf{x}_i^t\)</span>对应的那个目标图像，
并且<span
class="math inline">\(\gamma\)</span>是平衡两个loss的超参数。</p>
<h3 id="target-identity-protection-iterative-method">4.2 Target
Identity-Protection Iterative Method</h3>
<p>上一节给定了<span
class="math inline">\(\mathcal{L}(\mathbf{X}^p)\)</span>的表达式，所以通过最小化<span
class="math inline">\(\mathcal{L}(\mathbf{X}^p)\)</span>即可生成一个batch被保护图像<span
class="math inline">\(\mathbf{X}^p\)</span>。并且通过fast
gradient方法做多次迭代，最小化<span
class="math inline">\(\mathcal{L}(\mathbf{X}^p)\)</span>。即通过下式生成：</p>
<p><img src="https://s2.loli.net/2022/08/10/AhuXM7jQiG2clIZ.png" style="zoom:67%;" /></p>
<p>其中<span
class="math inline">\(\mathbf{X}^p_t\)</span>是迭代了t次的被保护图像，<span
class="math inline">\(\Pi\)</span>是投影函数，将图像投影到<span
class="math inline">\(l_p\)</span>范数边界，
Normalize是用来归一化梯度的（如在无穷范数中的符号函数，在l2范数中的l2归一化）。共进行<span
class="math inline">\(T\)</span>次迭代。</p>
<p>为了防止受保护图像陷入局部极小值，并提高其对其他黑箱人脸识别模型的可迁移性，我们将动量技术引入迭代过程。</p>
<h3 id="search-optimal-xt-via-greedy-insertion">4.3 Search Optimal <span
class="math inline">\(x^t\)</span> via Greedy Insertion</h3>
<p>下面的问题就是，如果<span
class="math inline">\(\tilde{\mathcal{G}_\mathcal{T}}\)</span>中不只有一张目标图片，那么就为获得更好的性能提供了更多潜在的优化方向。因此，本文开发了一种优化算法，在生成受保护图像的同时搜索最优目标。具体来说，对于式(5)中<span
class="math inline">\(T\)</span>次迭代的迭代过程，我们在<span
class="math inline">\(\tilde{\mathcal{G}_\mathcal{T}}\)</span>中为每一个受保护图像每次迭代选择一个代表目标进行更新，这属于子集选择问题。</p>
<blockquote>
<p><strong>定义.</strong> <span
class="math inline">\(S_t\)</span>表示每次迭代在<span
class="math inline">\(\tilde{\mathcal{G}_\mathcal{T}}\)</span>中选择的目标的集合直到第<span
class="math inline">\(t\)</span>次迭代。令<span
class="math inline">\(F\)</span>表示一个映射函数，从集合到一个实数增益值（越大越好）。对于<span
class="math inline">\(\mathbf{x}^t\in
\tilde{\mathcal{G}_\mathcal{T}}\)</span>，我们定义<span
class="math inline">\(\Delta(\mathbf{x}^t|S_t)=F(S_t\cup
\{\mathbf{x^t}\})-F(S_t)\)</span>为<span
class="math inline">\(F\)</span>在<span
class="math inline">\(S_t\)</span>时给定<span
class="math inline">\(\mathbf{x}^t\)</span>的边际效益。</p>
</blockquote>
<p>形式上，随着迭代循环中迭代次数的增加，如果边际增益单调减少，那么f将属于<strong>子模函数族</strong>。对于子模函数问题，用贪心算法可以求得近似解。但本问题不是严格的子模函数，不过之前的研究表明问题不大。于是本问题也使用了贪心插入的策略。</p>
<p>我们采用贪婪插入算法进行近似子模优化，该算法计算每个对象在每次迭代时从目标集中获得的收益，并根据定义将收益最大的对象集成到当前子集<span
class="math inline">\(S_t\)</span>中：</p>
<p><img src="https://s2.loli.net/2022/08/10/JdpEbksvx4NIuzD.png" style="zoom:67%;" /></p>
<p>下面定义映射函数<span
class="math inline">\(F\)</span>。具体的，映射F定义为，先在之前用了<span
class="math inline">\(S_t\)</span>内的targets做了t次迭代的结果上进行一步迭代，得到被保护的图像<span
class="math inline">\(\mathbf{x}^p\)</span>，再用<span
class="math inline">\(G\)</span>函数计算增益值。</p>
<p>合适的增益函数G应当选择最小化<span
class="math inline">\(\mathcal{L}_{iden}(\mathbf{x}^t,
\mathbf{x}^p)\)</span>最有效的图像。要注意的是<span
class="math inline">\(G\)</span>必须是正值（为什么），并且越大代表效果越好。于是定义了一个基于特征相似度的增益函数：</p>
<p><img src="https://s2.loli.net/2022/08/10/raghNGbADY6CRK9.png" style="zoom:67%;" /></p>
<p>每次迭代时，算法倾向于选择一个在特征子空间里更接近真实图像的目标。</p>
<p>贪心插入算法流程如下：</p>
<p><img src="https://s2.loli.net/2022/08/10/aLrfnheZ1dpA2Pl.png" /></p>
<p>中间迭代的时候只用<span
class="math inline">\(\mathcal{L}_{iden}(\mathbf{x}^t,
\mathbf{x}^p)\)</span>做损失函数是因为，之前定义的损失需要一个batch进行计算，但是贪心插入的时候是针对一个图像的，没有batch。</p>
<h2 id="experiments">5 Experiments</h2>
<h3 id="experiments-settings">5.1 Experiments Settings</h3>
<h4 id="datasets">Datasets</h4>
<p>在LFW和MegFace数据集上进行实验。为了接近真实的测试场景，我们涉及到一些额外的考虑因素。</p>
<ol type="1">
<li><strong>practical gallery set</strong>:
首先选择500个不同的身份做被保护的身份。同时随机对每个身份选择1张做probe
image，并将同身份的其他图像在加入gallery set。</li>
<li><strong>target identities</strong>:
随机在MS-Celeb-!M数据集中选择10个身份作为<span
class="math inline">\(\mathcal{T}\)</span>，每个身份选择一张图片形成<span
class="math inline">\(\tilde{\mathcal{G}_\mathcal{T}}\)</span>，剩下的图像加入gallery
set中，保证训练是的图像在gallery set中不可知。</li>
<li><strong>additional identities</strong>: 像gallery
set中添加额外的500个身份，模拟真实的测试场景。</li>
</ol>
<h4 id="target-models">Target models</h4>
<p>选择不同backbones和不同loss的模型。MTCNN用来检测人脸，并对齐为112x112的图像。只有一个模型被用于训练，剩下的作为黑盒模型。所用的模型如下表：</p>
<figure>
<img src="https://s2.loli.net/2022/08/10/JXEQBy2O9GDasLH.png"
alt="Table 2. Chosen target models that lie in various settings, including different architectures and training objectives." />
<figcaption aria-hidden="true">Table 2. Chosen target models that lie in
various settings, including different architectures and training
objectives.</figcaption>
</figure>
<h4 id="compared-methods">Compared Methods</h4>
<p>许多之前的人脸加密动作都是single-target的。<strong>MIM</strong>将动量引入迭代过程，<strong>DIM</strong>和TIM通过输入多样化来增加迁移性。但注意TIM只专注于规避防御模型，并且在实验上也比MIM和DIM取得更差的性能。</p>
<p>由于原始DIM在迭代优化中只支持单目标攻击，因此我们在内部最小化中通过对同一目标集的动态赋值实现了DIM的多目标版本，命名为<strong>MT-DIM</strong>。</p>
<p>此外，我们还研究了其他多目标优化方法的影响。如将式子(7)改写为<span
class="math inline">\(G_1(\mathbf{x})=log(1+\sum_{\mathbf{x}^t\in\tilde{\mathcal{G}_\mathcal{T}}}exp(\mathcal{D}_f(\mathbf{x},
\mathbf{x}^r)-\mathcal{D}_f(\mathbf{x},
\mathbf{x}^t)))\)</span>，这个方法命名为 <strong>Center-Opt</strong>.
这个方法使被保护图像向目标身份特征空间的中心更新。</p>
<p>MT-TIM, Center-Opt和本文的方法都是multi-target optimization
methods，single-target methods之用一张图片做更新。</p>
<p>设置迭代次数为50， 学习率为1.5， 扰动大小最大为12在无穷范数下。</p>
<h4 id="evaluation-metrics">Evaluation Metrics</h4>
<p>为了综合评估<strong>保护成功率</strong>，我们汇报Rank-N target
identity success rate（<strong>Rank-N-T</strong>）和untarget identity
success rate（<strong>Rank-N-UT</strong>）。</p>
<p>Rank-N-T表示在gallery set中与<span
class="math inline">\(\mathbf{x}\)</span>前N相似的，至少有1张属于target
identity， Rank-N-UT表示前N相似的没有与<span
class="math inline">\(\mathbf{x}\)</span>相同身份的。</p>
<p>为了检验所生成的受保护图像的<strong>不可感知性</strong>，我们采用标准的量化指标<strong>峰值信噪比(PSNR
)</strong>和<strong>结构相似度(SSIM)</strong>，以及<strong>人脸区域的MMD</strong>。对于SSIM和PSNR，值越大表示图像质量越好，而MMD值越小表示性能越好。</p>
<h3 id="effectiveness-of-black-box-face-encryption">5.2 Effectiveness of
Black-box Face Encryption</h3>
<figure>
<img src="https://s2.loli.net/2022/08/10/w94Bl3jXrYDW7u5.png"
alt="Table 3. Rank-1-T and Rank-5-T (%) of black-box identity protection against different models on LFW. ∗ indicates white-box results." />
<figcaption aria-hidden="true">Table 3. Rank-1-T and Rank-5-T (%) of
black-box identity protection against different models on LFW. ∗
indicates white-box results.</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/08/10/lqAyG4D5mgU1cap.png"
alt="Table 4. Rank-1-UT and Rank-5-UT (%) of black-box identity protection against different models on LFW. ∗ indicates white-box attacks." />
<figcaption aria-hidden="true">Table 4. Rank-1-UT and Rank-5-UT (%) of
black-box identity protection against different models on LFW. ∗
indicates white-box attacks.</figcaption>
</figure>
<p><img src="https://s2.loli.net/2022/08/10/OB7uYsRGUxILmnP.png" alt="Figure 3. Comparison of SSIM for different methods." style="zoom: 80%;" /></p>
<p>Tab.3
显示，在各种方法SSIM值很相近的情况下(Fig.3.)，本文的方法在R-N-T的表现上比其他方法好很多。与singel-target方法DIM相比，MT-DIM获得了更好的性能，表明多目标设置可获得更好的黑箱迁移性。并且不同的multi-target方法表现也有差异，如本文提出的TIP-IM好于Center-Opt。</p>
<p>Tab.4 显示，本文的方法也能保证最佳的效果。</p>
<p>并且实验发现，10张target图片已经足够了，目标数量的小幅增加可以获得更好的性能，尽管需要略微的时间成本。</p>
<p>我们从StyleGAN中指定一些生成的图像作为目标图像。结果表明，该算法仍然具有良好的身份保护黑箱性能。在实际应用中，我们可以任意指定可用和授权的目标身份集或生成的人脸图像，我们的算法适用于任何目标集。</p>
<h3 id="naturalness">5.3 Naturalness</h3>
<p>为验证本文方法能否控制自然度，对不同的系数<span
class="math inline">\(\gamma\)</span>进行枚举。Tab.5显示了不同的人脸识别模型(包括ArcFace、MobileFace和ResNet50)在PSNR、SSIM和MMD三个不同指标下的评价结果。随着γ的增加，生成的图像的视觉质量越来越好，这也与Fig4中的示例一致。因此，根据<span
class="math inline">\(\gamma\)</span>系数的不同，我们可以控制生成保护图像的自然程度。当<span
class="math inline">\(\gamma\)</span>增加时，图像看起来更自然，而在一定程度上，身份保护往往会失败。</p>
<figure>
<img src="https://s2.loli.net/2022/08/10/hwkUrXtg5Qd9eEB.png"
alt="Table 5. The average PSNR (db), SSIM, and MMD of the protected images generated by TIP-IM with different γ." />
<figcaption aria-hidden="true">Table 5. The average PSNR (db), SSIM, and
MMD of the protected images generated by TIP-IM with different
γ.</figcaption>
</figure>
<figure>
<img src="https://s2.loli.net/2022/08/10/9Z6mcAjf2JSBMWV.png"
alt="Figure 4. Experiments on how different γ affects the performance. Green hook refers to successful targeted identity protection while red hook refers to failure, which also implies a trade-off on effectiveness and naturalness. Best view when zoom in." />
<figcaption aria-hidden="true">Figure 4. Experiments on how different γ
affects the performance. Green hook refers to successful targeted
identity protection while red hook refers to failure, which also implies
a trade-off on effectiveness and naturalness. Best view when zoom
in.</figcaption>
</figure>
<p>Fig.5
显示了不同的人脸识别模型(包括ArcFace、MobileFace和ResNet50)在PSNR、SSIM和MMD三个不同指标下的评价结果。随着<span
class="math inline">\(\gamma\)</span>的增加，SSIM值也在增加，Rank-1-T精度呈现下降趋势，这意味着适当的<span
class="math inline">\(\gamma\)</span>对可转移性和自然性至关重要。</p>
<figure>
<img src="https://s2.loli.net/2022/08/10/m7Z8sdeGl1Tha93.png"
alt="Figure 5. Rank-1-T score and SSIM of protected images generated by TIP-IM with different γ against different models." />
<figcaption aria-hidden="true">Figure 5. Rank-1-T score and SSIM of
protected images generated by TIP-IM with different γ against different
models.</figcaption>
</figure>
<h3 id="effectiveness-on-a-real-world-application">5.4 Effectiveness on
a Real-World Application</h3>
<p>将提出的TIP-IM应用于腾讯AI开放平台提供的商业人脸搜索API上，测试身份保护性能。为了模拟隐私数据场景，我们使用上面描述的同一个图库集。在该平台中，我们从上述probe
set中选择20个probe faces，基于相似度排序进行人脸搜索。所有20个probe
faces都可以在Rank1被识别。然后从probe
faces生成相应的受保护图像，进行人脸搜索。对于返回排名，有6个目标身份在排名1和16个目标身份在排名5。注意，具有相同身份的人脸相似度也呈现不同程度的下降，这也说明了黑箱人脸系统的有效性，如图6所示为两个示例。</p>
<figure>
<img src="https://s2.loli.net/2022/08/10/OvrLQ5qYIHcUaJ2.png"
alt="Figure 6. Examples of face encryption on the real-world face recognition API. We separately use real and protected faces by TIP-IM as probes to do face search and show top three results by similarity. Blue boxes represent the faces with same identities as probe faces and green boxes imply the faces belonging to targeted identities. Similarity scores with probe face are marked in yellow." />
<figcaption aria-hidden="true">Figure 6. Examples of face encryption on
the real-world face recognition API. We separately use real and
protected faces by TIP-IM as probes to do face search and show top three
results by similarity. Blue boxes represent the faces with same
identities as probe faces and green boxes imply the faces belonging to
targeted identities. Similarity scores with probe face are marked in
yellow.</figcaption>
</figure>
<h2 id="conclusion">6 Conclusion</h2>
<p>在本文中，我们通过在社交媒体中模拟真实的身份识别系统来研究身份保护问题。大量实验表明，所提出的TIP-IM方法在不影响社交媒体用户体验的同时，能够保护用户的私人信息不被未经授权的身份识别系统暴露。</p>
<hr />
<h2 id="总结和思考">总结和思考</h2>
<ol type="1">
<li>文章提出的multi-target方法，多一些target选择，可以显著增加迁移性和成功率，这对于人脸隐私保护来说，是很有用的。人脸隐私保护，只要认不出来就行了，可以使用de-identification，也可以使用target，而使用target方法，可以避免一些无辜的人身份被窃取。</li>
<li>文章提出的控制自然度，是用MMD放在损失函数中来实现的，用MMD来逼迫生成图像和原始图像分布相同。在读GAP文章的时候就在想有没有其他方法将生成图像控制在真实数据分布的流形上，GAP是用训练好的StyleGAN来隐式实现的，本文是用目标函数中加入正则化项来显式实现的。用MMD，但没有使用人脸的特殊性，如特殊特征什么的。</li>
<li>为什么Tab.4没有Center-Opt算法的数据了？</li>
<li>次模函数那块。前面的定义与submodular高度相似，submodular问题是NP-hard问题，但是可以用文中类似的贪心方法求近似解。（我觉得把本文中的F定义为次模函数有点牵强，毕竟每次更新所用的图像不一定是不同的。用其他近似方法求解可能会得到更好的效果）。用其他的方法，贪心的，亦或是其他启发式的算法，是不是可以提升性能呢。（而且计算增益的时候，是不考虑自然度的）</li>
<li>是否可以类似于OPOM，提供多张输入图片，来提升性能。</li>
<li>是否可以不人工指定target图像，而是根据什么准则、在什么条件下生成target？</li>
</ol>
<hr />
<h2 id="其他参考资料">其他参考资料</h2>
<ol type="1">
<li>MMD：https://zhuanlan.zhihu.com/p/163839117</li>
<li>定量评价图像生成质量：http://www.360doc.com/content/20/1127/03/72629698_948146939.shtml</li>
<li>SSIM：https://blog.csdn.net/qq_42951560/article/details/115463083</li>
<li>PSNR：https://blog.csdn.net/weixin_29732003/article/details/122569893</li>
</ol>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>[论文阅读] LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition</title>
    <url>/2022/08/11/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-LowKey-Leveraging-Adversarial-Attacks-to-Protect-Social-Media-Users-from-Facial-Recognition/</url>
    <content><![CDATA[<center>
ICLR2021 LowKey: 利用对抗攻击保护社交媒体用户免于人脸识别
</center>
<span id="more"></span>
<p>题目：LowKey: Leveraging Adversarial Attacks to Protect Social Media
Users from Facial Recognition</p>
<p>作者：Valeriia Cherepanova, Micah Goldblum, Harrison Foley, Shiyuan
Duan, John P. Dickerson, Gavin Taylor, Tom Goldstein</p>
<p>链接：<a href="https://arxiv.org/pdf/2101.07922.pdf">文章链接</a></p>
<hr />
<h2 id="摘要翻译">1 摘要翻译</h2>
<p>人脸识别系统越来越多地被私营企业、政府机构以及消费者服务和大规模监控项目的承包商使用。这些系统通常是通过抓取社交媒体资料来获取用户图片。对抗扰动已经被提出用来绕过面部识别系统。然而，现有的方法在大规模系统和商业api上失败了。我们开发了我们自己的对抗性滤波器，它占了整个图像处理流程，并且对包括人脸检测和大规模数据库在内的工业级流程非常有效。此外，我们发布了一个易于使用的网络工具，显著降低了Amazon
Rekognition和Microsoft
Azure人脸识别API的准确性，将它们的准确性降低到1%以下。</p>
<h3 id="基本问题">基本问题</h3>
<ul>
<li>解决问题：首个提出利用对抗样本思路保护人脸隐私</li>
<li><strong>贡献</strong>：
<ol type="1">
<li>我们设计了一种针对人脸识别模型的<strong>黑盒对抗攻击</strong>。我们的算法移动gallery
faces的特征空间表示，使它们不匹配相应的probe图像，同时<strong>保持图像质量</strong>。</li>
<li>我们<strong>在商业黑盒api(包括Amazon Rekognition和Microsoft Azure
Face)上测试方法的性能</strong>，这些api的内部工作原理尚未公开。我们与现有的数据投毒替代方案Fawkes进行了全面的比较，我们发现，Fawkes在每个实验中都是无效的，但我们的方法始终阻止了面部识别。</li>
<li>我们发布了一个<strong>简单易用的网络工具LowKey</strong>。</li>
</ol></li>
<li>相似方案， Fawkes的问题
<ul>
<li>Fawkes假设人脸识别从业者根据每个人的数据训练他们的模型。</li>
<li>作者主要使用图像分类器。相比之下，商业系统使用FR特定的head和loss进行训练，而不是分类器使用的标准交叉熵损失</li>
<li>作者在非常小的数据集上进行评估，且该系统只使用top-1精确度进行评估。</li>
<li>虽然原论文描述了人眼无法察觉Fawkes的扰动，但实验表明，情况恰恰相反</li>
<li>Fawkes还没有发布应用程序或网络工具</li>
</ul></li>
</ul>
<h2 id="method">2 Method</h2>
<p>为了提高黑盒迁移性，使用集成模型攻击。对于每个集成的模型，目标函数都考虑与原图的特征空间的差距，包括使用和不使用高斯模糊。同时使用LPIPS来作为感知相似度损失。</p>
<p><img src="https://s2.loli.net/2022/08/11/bSFRfpcLXZm7MJ1.png" /></p>
<p>其中<span class="math inline">\(x\)</span>是原图像，<span
class="math inline">\(x&#39;\)</span>是扰动图像，<span
class="math inline">\(f_i\)</span>表示第i个模型，<span
class="math inline">\(G\)</span>是高斯平滑函数，<span
class="math inline">\(A\)</span>表示人脸检测和人脸对齐为112x112图像。</p>
<p>使用迭代符号梯度上升方法求解。</p>
<p>集成模型是IR-152和ResNet-152，用ArcFace和CosFace做损失训练的4个模型。</p>
<p><strong>注意，LowKey是通过更改gallery
set中的图像来实现上传真实图像的人脸隐私保护的。</strong></p>
<h2 id="experiments">3 Experiments</h2>
<h3 id="experiments-setting">3.1 Experiments Setting</h3>
<p>文中的实验是使用FaceScrub数据集，去除接近重复的图像，选择每个身份的1/10的图像作为probe
images，剩下的图像插入gallery
set中。随机选择100个身份使用LowKey保护，模拟大规模用户中少量使用LowKey做隐私保护的用户。</p>
<h3 id="在商业api上实验">3.2 在商业API上实验</h3>
<p>略过，效果比Fawkes好很多</p>
<h3 id="补充实验">3.3 补充实验</h3>
<h4 id="ensemble-and-transferability">Ensemble and Transferability</h4>
<p>使用不同模型做白盒和黑盒进行实验，发现集成模型具有更好的黑盒迁移性。</p>
<h4 id="gaussian-smoothing">Gaussian Smoothing</h4>
<p>我们在我们的目标函数中加入高斯平滑作为预处理步骤，以使我们的扰动更平滑和更稳健。直觉上，这提高了被攻击图像的有效性，即使应用了去噪滤波器。加入模糊，可以迫使对抗扰动是基于低频的图像修改，而不是“噪声”。</p>
<p>生成的图像也表明，扰动变得平滑，且没有尖锐线条和高频的振荡。</p>
<p>并且实验表明，加入了高斯平滑后，在Rank-50精度上与不加高斯平滑一样好，但是却更有鲁棒性。</p>
<h4 id="run-time">Run-time</h4>
<p>生成一张用2080TI要32s，略过。</p>
<h4 id="robustness-to-image-compression">Robustness to Image
Compression</h4>
<p>如jpg格式保存图像会有压缩损失。实验表明会略微降低性能，但是攻击仍然十分有效。</p>
<h4 id="scalability-to-all-image-sizes">Scalability to All Image
Sizes</h4>
<p>对不同大小图像的保护能力也很重要，因为在生成对抗扰动的时候，将人脸缩放到了112x112大小，恢复的时候，若原始人脸过大或过小，都会导致攻击能力大幅下降。</p>
<p>实验也验证了这个结果。</p>
<h2 id="discussion">Discussion</h2>
<p>在这项工作中，我们开发了一个工具，以保护用户免受未经授权的面部识别。我们的工具在用户图片上传到社交媒体之前对其进行预处理。这些预处理后的图像对于第三方机构收集来进行面部识别是无用的。虽然我们已经证明了<strong>LowKey对于商业黑箱api是非常有效的</strong>，但它不能100%地保护用户，可能会被专门设计的健壮系统所绕过。因此，我们希望用户在公开个人信息时仍保持谨慎。<strong>一个有趣的未来方向是生产更具美感的对抗性过滤器，以促进该工具的更广泛使用。</strong>然而，可能没有免费的午餐，如果没有可见的干扰，人们无法欺骗最先进的面部识别系统。最后，我们注意到，我们推广这一工具的目标之一是提高人们对面部识别及其引发的道德问题的更广泛认识。可以在lowkey.umiacs.umd.edu网址找到LowKey工具。</p>
<h2 id="总结与思考">总结与思考</h2>
<ol type="1">
<li>本方法生成的图像质量还是太差，使用LPIPS作为可感知性损失，有没有其他更好的方法代替。</li>
<li>如何解决大图像攻击效果不佳的问题？</li>
</ol>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>[论文阅读] Adversarial Privacy-preserving Filter</title>
    <url>/2022/08/20/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Adversarial-Privacy-preserving-Filter/</url>
    <content><![CDATA[<p>ACM MM2020 对抗性隐私保护滤波器</p>
<span id="more"></span>
<p>题目：Adversarial Privacy-preserving Filter</p>
<p>作者：<a
href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+J">Jiaming
Zhang</a>, <a
href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sang%2C+J">Jitao
Sang</a>, <a
href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhao%2C+X">Xian
Zhao</a>, <a
href="https://arxiv.org/search/cs?searchtype=author&amp;query=Huang%2C+X">Xiaowen
Huang</a>, <a
href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+Y">Yanfeng
Sun</a>, <a
href="https://arxiv.org/search/cs?searchtype=author&amp;query=Hu%2C+Y">Yongli
Hu</a></p>
<p>链接：<a href="https://arxiv.org/pdf/2007.12861.pdf">论文链接</a>，
<a
href="https://github.com/adversarial-for-goodness/APF">代码链接</a></p>
<hr />
<h1 id="摘要翻译">1 摘要翻译</h1>
<p>人脸识别在实际应用中得到了广泛的应用，在恶意使用人脸图像和潜在的隐私问题方面受到了广泛的讨论，例如欺骗支付系统和造成个人破坏。在线照片共享服务在无意中成为了恶意爬虫和人脸识别应用程序的主要存储库。这项工作旨在开发一种隐私保护解决方案，称为对抗性隐私保护滤波器(APF)，以保护在线共享的人脸图像不被恶意使用。我们提出了一种<strong>端云协同</strong>对抗攻击解决方案，以满足<strong>隐私、实用和不可访问</strong>的要求。具体而言，该解决方案包括三个模块:(1)<strong>image-specific
gradient
generation</strong>，通过压缩探针模型提取用户端的image-specific梯度;
(2)<strong>adversarial gradient
transfer</strong>，对服务器云中的image-specific gradient进行微调;
(3)<strong>universal adversarial perturbation
enhancement</strong>，附加与图像无关的扰动来得到最终的对抗噪声。在三个数据集上的大量实验验证了该方法的有效性和高效性。还发布了一个原型应用程序，以供进一步评估。我们希望该端云协同攻击框架能够从用户端解决在线多媒体共享的隐私保护问题。</p>
<h3 id="基本问题">基本问题</h3>
<ul>
<li>解决的问题：生成保护隐私、实用、不可访问的人脸隐私保护掩码</li>
</ul>
<h2 id="introduction">2 Introduction</h2>
<p>本文旨在在不影响用户分享照片体验的前提下，保护用户的肖像隐私。生成保护人脸隐私掩码需要考虑的要求：</p>
<ol type="1">
<li><strong>privacy</strong>.
用户的身份信息无法从向社交媒体共享的人脸图像中识别出来。</li>
<li><strong>utility</strong>. 面部图像的质量不能被破坏</li>
</ol>
<p>​
对抗攻击能满足以上两点要求。虽然对抗样本可以保证照片在共享服务上的隐私保护，但在生成对抗样本时仍然存在隐私泄露的风险。由于大多数对抗攻击解决方案都涉及复杂的模型和大量的计算操作，通常都是将原始人脸图像上传到服务器进行处理。这不可避免地将原始人脸图像暴露给第三方应用程序，使它们在传输过程和云计算中都容易受到攻击。因此有第3个要求</p>
<ol start="3" type="1">
<li><strong>non-accessibility</strong>.
原始的人脸图像只能在用户端访问。</li>
</ol>
<p>为解决以上3个要求，文章提出了一个端云协作的对抗攻击方法，其中原始人脸图像只用于提取image-specific
gradient，接着在云服务端进行微调生成最终的对抗扰动。端云协同解决方案成功地解决了<strong>终端计算量不足与云中的隐私泄露风险之间的矛盾</strong>。此外，为了提高云中生成的对抗扰动的攻击性能，我们进一步引入与image-independent的<strong>通用对抗扰动进行增强</strong>，结果表明，该增强方法在加速训练收敛和增强攻击能力方面都是有效的。</p>
<p>文章贡献如下：</p>
<ul>
<li>我们<strong>设计了一个对抗性隐私保护过滤器</strong>，在不影响用户的照片共享体验的情况下，保护用户的肖像隐私，免受恶意人脸识别破解者的攻击。对抗性攻击自然满足了隐私性和实用性两个基本要求。</li>
<li>我们提出了一个<strong>端云协作对抗攻击框架</strong>，该框架解决了额外的不可访问性要求，以保证原始图像只能被用户自己的设备端访问。这种两阶段攻击与传统的一阶段攻击的<strong>兼容性能</strong>也为理解对抗性攻击问题提供了一个新的视角。</li>
<li>我们<strong>将通用对抗扰动与image-dependent扰动相结合</strong>，以提高隐私保护能力。这提出了利用对抗样本的另一种方法。</li>
<li>我们进行了<strong>大量的实验</strong>，以验证所提出的解决方案框架的有效性和效率。进一步开发了一种对抗性隐私保护过滤器的原型，并发布进行评估。</li>
</ul>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202208202257138.png?token=ATUOZVNFKXOBFSRQNOOCEB3DAD3IS"
alt="Figure 1: Schematic illustration of the proposed adversarial privacy-preserving filter. Given a face image, the synthetic adversarial image is expected to fool the malicious face recognition algorithm." />
<figcaption aria-hidden="true">Figure 1: Schematic illustration of the
proposed adversarial privacy-preserving filter. Given a face image, the
synthetic adversarial image is expected to fool the malicious face
recognition algorithm.</figcaption>
</figure>
<h2 id="methodology">3 Methodology</h2>
<h3 id="问题定义">3.1 问题定义</h3>
<p>给定原始图像<span
class="math inline">\(x\)</span>，假设人脸识别模型是<span
class="math inline">\(f_\theta\)</span>，生成<span
class="math inline">\(l\)</span>维的特征向量<span
class="math inline">\(f_\theta(x)\)</span>。且<span
class="math inline">\(x_e\)</span>表示对应的“注册图像”，当距离<span
class="math inline">\(d(f_\theta(x),
f_\theta(x_e))\)</span>小于某个阈值时，就表明是相同身份，否则是不同身份。</p>
<p>本文的主要目的是生成不可见的对抗噪声<span
class="math inline">\(s\)</span>，使对抗样本<span
class="math inline">\(x+s\)</span>与<span
class="math inline">\(x\)</span>在人类的视角下很像，但在人脸识别模型<span
class="math inline">\(f_\theta\)</span>下不是同一个身份。</p>
<h3 id="总体框架">3.2 总体框架</h3>
<p><img
src="D:\zzhbrrBlog\source_posts\论文阅读-Adversarial-Privacy-preserving-Filter.assets\image-20220820230709251.png" /></p>
<p>隐私保护过滤器的工作流程如Fig.2所示，包括用户端、隐私保护服务器云和照片共享服务三个部分。给定一幅肖像图像，首先在用户端提取其<strong>特定于图像的梯度</strong>，然后将其发布到隐私保护服务器云进行<strong>增强</strong>，得到对抗噪声。经过增强的对抗噪声的干扰后，得到的对抗肖像图像有望欺骗照片共享服务上潜在的人脸识别系统。整个过程中，原图仅供用户端访问，防止在服务器上泄露隐私。</p>
<p>核心解决方案是一个端云协同对抗攻击框架，由三个算法模块组成，分别部署在用户端和服务器云中:(1)Image-specific
gradient
generation，是通过可以在终端运行的压缩过的probe模型来获得图像梯度。(2)Adversarial
gradient
transfer，是将probe模型和服务器模型在云中的图像梯度进行<strong>对齐</strong>，以恢复对抗信息。(3)Universal
adversarial
perturbation,是附加与图像无关的通用扰动来进一步增强导出的对抗噪声。</p>
<h3 id="image-specific-gradient-generation">3.3 Image-specific gradient
generation</h3>
<p>在用户端使用一个压缩模型，从原始图像中提取初步信息，然后在云中增强信息。在这个过程中可以使用多种对抗攻击方法，在这里我们只以FGSM为例。原始图像<span
class="math inline">\(x\)</span>的image-specific gradient <span
class="math inline">\(g\)</span>可以用以下公式提取：</p>
<p><img
src="D:\zzhbrrBlog\source_posts\论文阅读-Adversarial-Privacy-preserving-Filter.assets\image-20220820231547389.png" /></p>
<p>其中，<span
class="math inline">\(L(·)\)</span>是衡量原始图像和注册图像特征距离的损失函数：</p>
<p><img
src="D:\zzhbrrBlog\source_posts\论文阅读-Adversarial-Privacy-preserving-Filter.assets\image-20220820231714410.png" /></p>
<p>其中，<span class="math inline">\(d(·)\)</span>是用欧几里得距离。</p>
<h3 id="adversarial-gradient-transfer">3.4 Adversarial gradient
transfer</h3>
<p>小的probe模型在用户端提取图像梯度来生成对抗样本。但是由于终端的probe模型和云服务器模型的结构和参数不同，不能直接使用梯度。为了对probe模型和服务器模型之间的图像梯度进行对齐，我们提出梯度迁移模块<span
class="math inline">\(T\)</span>，其定义为:</p>
<p><img
src="D:\zzhbrrBlog\source_posts\论文阅读-Adversarial-Privacy-preserving-Filter.assets\image-20220820231916978.png" /></p>
<p>我们认为梯度迁移模块是一个图像到图像的网络，我们使用U-Net架构将梯度从probe模型迁移到服务器模型。具体的，我们用以下优化问题来训练梯度迁移模型：</p>
<p><img
src="D:\zzhbrrBlog\source_posts\论文阅读-Adversarial-Privacy-preserving-Filter.assets\image-20220820232109558.png" /></p>
<p>其中，<span
class="math inline">\(\tilde{g}\)</span>是用公式(1)在服务器模型上计算出来的梯度，<span
class="math inline">\(\theta_T\)</span>是网络<span
class="math inline">\(T\)</span>的参数。该目标函数使网络<span
class="math inline">\(T\)</span>学习probe模型和服务器模型之间的关系。</p>
<p>我们还设计了服务器为集成模型，将公式(4)中的<span
class="math inline">\(\tilde{g}\)</span>改为以下的<span
class="math inline">\(\tilde{g}_{ensemble}\)</span>即可：</p>
<p><img
src="D:\zzhbrrBlog\source_posts\论文阅读-Adversarial-Privacy-preserving-Filter.assets\image-20220820232433430-16610090756481.png" /></p>
<p>其中<span class="math inline">\(\sum_{k=1}^{K}a_k=1\)</span>。</p>
<h3 id="universal-adversarial-perturbation">3.5 Universal adversarial
perturbation</h3>
<p>通用对抗扰动包含了误导许多图像的分类的与image-independent的信息。这启发我们整合图像特定信息和图像无关信息来增强对抗扰动的性能</p>
<p>。</p>
]]></content>
      <categories>
        <category>论文阅读</category>
        <category>对抗攻击</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title>CMU10714 dlsys lec14 卷积的实现</title>
    <url>/2022/12/30/CMU10714-dlsys-lec14-%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<center>
本节介绍了卷积的不同实现方法。
</center>
<span id="more"></span>
<h3 id="存储结构">存储结构</h3>
<p>首先需要明确tensor在内存中是如何存储的。我们假设被卷积的图像高度为<span
class="math inline">\(H\)</span>，宽度为<span
class="math inline">\(W\)</span>，通道数为<span
class="math inline">\(C_{in}\)</span>，卷积核的大小为<span
class="math inline">\(K\times K\)</span>，卷积的输出通道数为<span
class="math inline">\(C_{out}\)</span>。同时还有批量维度，<span
class="math inline">\(N\)</span>。</p>
<p>图像的表示方法为<code>float Z[N][H][W][C_in]</code>，这种表示方法称为NHWC格式，pytorch中的存储格式是NCHW，只考虑每张图片计算速度，我们的这种表示更好，但对大批量卷积pytorch的格式友好。</p>
<p>卷积核的表示方法为<code>float W[K][K][C_in][C_out]</code>。可以将卷积核视为<span
class="math inline">\(K\times K\)</span> 个 <span
class="math inline">\(C_{in}\times
C_{out}\)</span>矩阵的矩阵（其实本来就是这样）。注意pytorch其实使用了<code>[C_out][C_in][K][K]</code>的格式。</p>
<h3 id="baseline">Baseline</h3>
<p>首先写一个参考答案，直接使用Pytorch实现，目的是检查我们代码的正确性，以及比较时间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_reference</span>(<span class="params">Z, weight</span>):</span></span><br><span class="line">    <span class="comment"># NHWC -&gt; NCHW</span></span><br><span class="line">    z_torch = torch.tensor(Z).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># KKIO -&gt; OIKK</span></span><br><span class="line">    W_torch = torch.tensor(weight).permute(<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    out = nn.functional.conv2d(z_torch, W_torch)</span><br><span class="line">    <span class="keyword">return</span> out.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous().numpy()</span><br><span class="line"></span><br><span class="line">Z = np.random.randn(<span class="number">10</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">W = np.random.randn(<span class="number">3</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">16</span>)</span><br></pre></td></tr></table></figure>
<h3 id="暴力循环">暴力循环</h3>
<p>最简单的实现卷积的方法就是直接嵌套for循环了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_naive</span>(<span class="params">Z, weight</span>):</span></span><br><span class="line">    N, H, W, C_in = Z.shape</span><br><span class="line">    K, _, _, C_out = weight.shape</span><br><span class="line"></span><br><span class="line">    out = np.zeros((N, H-K+<span class="number">1</span>, W-K+<span class="number">1</span>, C_out))</span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        <span class="keyword">for</span> c_in <span class="keyword">in</span> <span class="built_in">range</span>(C_in):</span><br><span class="line">            <span class="keyword">for</span> c_out <span class="keyword">in</span> <span class="built_in">range</span>(C_out):</span><br><span class="line">                <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(H-K+<span class="number">1</span>):</span><br><span class="line">                    <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(W-K+<span class="number">1</span>):</span><br><span class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">                            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">                                out[n, y, x, c_out] += Z[n, y+i, x+j, c_in] * weight[i, j, c_in, c_out]</span><br><span class="line">    <span class="keyword">return</span> out</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>但对于Z为(10, 32, 32, 8)，W为(3, 3, 8, 16)。</p>
<p>暴力循环的时间：</p>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202212310940265.png"
alt="image-20221231002544422" />
<figcaption aria-hidden="true">image-20221231002544422</figcaption>
</figure>
<p>Pytorch的时间：</p>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202212310940487.png"
alt="image-20221230222117748" />
<figcaption aria-hidden="true">image-20221230222117748</figcaption>
</figure>
<p>。。。</p>
<h3 id="使用矩阵乘法">使用矩阵乘法</h3>
<p>首先设想卷积核大小为<span class="math inline">\(1\times
1\)</span>的时候，卷积操作就是矩阵乘法：将图片每个位置的长为<span
class="math inline">\(C_{in}\)</span>的向量，乘以大小为<span
class="math inline">\(C_{in}\times C_{out}\)</span>的矩阵。</p>
<p>如</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Z = np.random.randn(<span class="number">10</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">8</span>)</span><br><span class="line">W1 = np.random.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">8</span>, <span class="number">16</span>)</span><br><span class="line">out2 = Z @ W1</span><br><span class="line"><span class="built_in">print</span>(np.linalg.norm(out-out2))</span><br><span class="line">---</span><br><span class="line"><span class="number">1.0738548044478649e-14</span></span><br></pre></td></tr></table></figure>
<p>于是推广到<span class="math inline">\(K\times
K\)</span>的卷积核，实际上是卷积核“中”每个“矩阵”与原始图像对应位置的那些向量做矩阵乘法，然后将得到的向量相加。</p>
<p>于是可以这么实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_matrix_mul</span>(<span class="params">Z, weight</span>):</span></span><br><span class="line">    N, H, W, C_in = Z.shape</span><br><span class="line">    K, _, _, C_out = weight.shape</span><br><span class="line"></span><br><span class="line">    out = np.zeros((N, H-K+<span class="number">1</span>, W-K+<span class="number">1</span>, C_out))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(K): <span class="comment"># 迭代卷积核的每个位置</span></span><br><span class="line">            out += Z[:, i:i+H-K+<span class="number">1</span>, j:j+W-K+<span class="number">1</span>, :] @ weight[i, j] <span class="comment"># 将图像上的向量与卷积核的特定矩阵做乘法的结果加到对应的位置上</span></span><br><span class="line">    <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>这个实现方法用时为：</p>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202212310940924.png"
alt="image-20221231002632685" />
<figcaption aria-hidden="true">image-20221231002632685</figcaption>
</figure>
<p>还是比Pytorch要慢</p>
<h3 id="使用im2col实现卷积">使用im2col实现卷积</h3>
<h4 id="另一种矩阵乘法的视角">另一种矩阵乘法的视角</h4>
<p>回顾上一节课，考虑简单的1D卷积，输入维度为5，padding为1，卷积核大小为3时，有
<span class="math display">\[
\begin{bmatrix} 0&amp;  x_1&amp; x_2 &amp; x_3 &amp; x_4 &amp; x_5
&amp;0\end{bmatrix} * \begin{bmatrix} w_1&amp; w_2&amp;
w_3\end{bmatrix}=\begin{bmatrix} z_1&amp; z_2 &amp; z_3 &amp; z_4 &amp;
z_5\end{bmatrix}
\]</span> 可以写成两个矩阵相乘的形式： <span class="math display">\[
\begin{bmatrix}z_1 \\z_2 \\z_3 \\z_4 \\z_5\end{bmatrix}=\begin{bmatrix}
0 &amp; x_1 &amp; x_2\\
x_1 &amp; x_2 &amp;x_3 \\
x_2 &amp; x_3 &amp; x_4\\
x_3 &amp; x_4 &amp; x_5\\
x_4 &amp; x_5 &amp; 0
\end{bmatrix} \times \begin{bmatrix}w_1 \\w_2 \\ w_3\end{bmatrix}
\]</span> 虽然这样做看起来很浪费空间，但现实中大家都是这么实现的（。</p>
<p>而且这么表示卷积，可以方便地进行求导，解释一下，不想看的可以直接看下一节：</p>
<p>令<span class="math inline">\(z=conv(x,
W)\)</span>，我们要计算partial adjoints: <span
class="math inline">\(\bar{v}\frac{\partial z}{\partial
W}\)</span>和<span class="math inline">\(\bar{v}\frac{\partial
z}{\partial x}\)</span>，因为<span
class="math inline">\(\bar{v}\)</span>已经在反向过程中已知了，所以就是要求<span
class="math inline">\(\frac{\partial z}{\partial W}\)</span>和<span
class="math inline">\(\frac{\partial z}{\partial x}\)</span>。</p>
<p>首先有一个简单的问题，对于<span class="math inline">\(x\in \R^n, W\in
\R^{m\times n},z=Wx\)</span> ，则<span
class="math inline">\(\frac{\partial z}{\partial
x}=W\)</span>，则x的partial adjoint为<span
class="math inline">\(W^T\bar{v}\)</span>，即反向时候只需要计算W的转置即可。</p>
<p>我们发现卷积可以写成上面的矩阵与向量相乘的形式，于是我们可以知道
<span class="math display">\[
\frac{\partial z}{\partial w} =\begin{bmatrix}
0 &amp; x_1 &amp; x_2\\
x_1 &amp; x_2 &amp;x_3 \\
x_2 &amp; x_3 &amp; x_4\\
x_3 &amp; x_4 &amp; x_5\\
x_4 &amp; x_5 &amp; 0
\end{bmatrix}^T
\]</span> on the other hand，卷积也可以写成 <span
class="math display">\[
\begin{bmatrix}z_1 \\z_2 \\z_3 \\z_4 \\z_5\end{bmatrix}=\begin{bmatrix}
w_2 &amp; w_3 &amp; 0&amp;0&amp;0\\
w_1 &amp; w_2 &amp; w_3&amp;0&amp;0 \\
0&amp;w_1 &amp; w_2 &amp; w_3&amp;0\\
0&amp;0&amp;w_1 &amp; w_2 &amp; w_3\\
0&amp;0&amp;0&amp;w_1 &amp; w_2
\end{bmatrix} \times \begin{bmatrix}x_1 \\x_2 \\ x_3 \\
x_4\\x_5\end{bmatrix}
\]</span> 于是 <span class="math display">\[
\frac{\partial z}{\partial x} =\begin{bmatrix}
w_2 &amp; w_3 &amp; 0&amp;0&amp;0\\
w_1 &amp; w_2 &amp; w_3&amp;0&amp;0 \\
0&amp;w_1 &amp; w_2 &amp; w_3&amp;0\\
0&amp;0&amp;w_1 &amp; w_2 &amp; w_3\\
0&amp;0&amp;0&amp;w_1 &amp; w_2
\end{bmatrix}^T = \begin{bmatrix}
w_2 &amp; w_1 &amp; 0&amp;0&amp;0\\
w_3 &amp; w_2 &amp; w_1&amp;0&amp;0 \\
0&amp;w_3 &amp; w_2 &amp; w_1&amp;0\\
0&amp;0&amp;w_3 &amp; w_2 &amp; w_1\\
0&amp;0&amp;0&amp;w_3 &amp; w_2
\end{bmatrix}
\]</span> 而<span class="math inline">\(\bar{v}\frac{\partial
z}{\partial x}\)</span> 其实就是对<span
class="math inline">\(\bar{v}\)</span>用转置卷积核<span
class="math inline">\(w^T\)</span>卷积！</p>
<h4 id="神奇函数as_strided">神奇函数：as_strided</h4>
<p>通常情况下，一个<span class="math inline">\(M\times
N\)</span>的矩阵在底层是以row
major方法以一维的形式存储的，即一行一行存储，扩展到多维的数组<span
class="math inline">\(A\times B\times
C\)</span>，则是按照由后向前的order存储。通过strides的方法来获取多维的元素。如在<code>float A[M][N]</code>中，它的stride为<span
class="math inline">\((N, 1)\)</span>，如果我们想获取<span
class="math inline">\(A[3][2]\)</span>，则是获取一维数组的第<span
class="math inline">\(3 \times N + 2\)</span>个元素。</p>
<p>进一步的，我们想更好利用CPU的缓存机制，方便向量化的操作，我们要把矩阵分为<code>TILE x TILE</code>的小块（如TILE=4）</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">float</span> A[M/TILE][n/TILE][TILE][TILE]</span><br></pre></td></tr></table></figure>
<p>我们就可以在小块上进行高效操作，因为A的<code>TILE x TILE</code>的块在内存中是连续排布的。</p>
<p>如将一个<code>6 x 6</code>的矩阵</p>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202212310940327.png"
alt="image-20221231002645467" />
<figcaption aria-hidden="true">image-20221231002645467</figcaption>
</figure>
<p>划分为TILE=2的小块，结果应该是这样：</p>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202212310940357.png"
alt="image-20221231002652207" />
<figcaption aria-hidden="true">image-20221231002652207</figcaption>
</figure>
<p>我们需要使用numpy中一个非常神奇的函数：<code>np.lib.stride_tricks.as_strided()</code>来实现。</p>
<p>这个函数可以让我们指定数组的shape和strides，但不修改底层数据，最终我们只需要用<code>np.ascontiguousarray()</code>来使内存连续排布即可。</p>
<p>首先看一下我们目的的矩阵大小是什么，我们选取了TILE=2，所以最终的shape应该是<span
class="math inline">\(3\times 3\times 2 \times 2\)</span>。</p>
<p>接下来我们看一下strides是多少，strides需要与shape相同，对于第一维，我们每次增加都想下降两行，如现在我们指在1，那么第一维加1后，我们应该指在13，所以第一维的stride为12；而第二维，每次增加1都想向左移两位，所以第二维的stride为2；第三维每次增加1都想下降一行，所以第三维stride为6；对于最后一位，每增加1只向右移动1个即可，所以stride=1，</p>
<p>于是我们可以构造矩阵B</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy.lib.stride_tricks <span class="keyword">import</span> as_strided</span><br><span class="line">B = as_strided(A, shape=(<span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">2</span>), strides=np.array((<span class="number">12</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">1</span>))*<span class="number">4</span>) <span class="comment"># *4是因为strides的单位是Byte</span></span><br></pre></td></tr></table></figure>
<p>然后将B重新排列</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">C = np.ascontiguousarray(B)</span><br></pre></td></tr></table></figure>
<p>就得到了内存紧凑 我们想要的数组。</p>
<h4 id="使用im2col实现卷积-1">使用im2col实现卷积</h4>
<p>首先看输出通道为1的二维卷积核在通道数为1的二维图片上做卷积的操作，</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">A = np.arange(<span class="number">36</span>, dtype=np.float32).reshape(<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">W = np.arange(<span class="number">9</span>, dtype=np.float32).reshape(<span class="number">3</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>我们按照上面的做法，将原始形状为<span
class="math inline">\([6][6]\)</span>的A变化成为<span
class="math inline">\([2][2][3][3]\)</span>的矩阵：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">B = np.lib.stride_trices.as_strided(A, shape=(<span class="number">4</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">4</span> * (np.array((<span class="number">6</span>, <span class="number">1</span>, <span class="number">6</span>, <span class="number">1</span>))))</span><br></pre></td></tr></table></figure>
<p>然后把B拍平，与同样拍平的W做乘法，再reshape到正常大小：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">(B.reshape(<span class="number">16</span>, <span class="number">9</span>) @ W.reshape(<span class="number">9</span>)).reshape(<span class="number">4</span>, <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>这样就可以实现卷积了！</p>
<p>但注意reshape的操作隐式的调用了<code>ascontinugousarray</code>，也就意味着我们并不能节省内存的开销，该开的还是得开。</p>
<p>按照以上思想，可以实现卷积如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv_im2col</span>(<span class="params">Z, weight</span>):</span></span><br><span class="line">    N, H, W, C_in = Z.shape</span><br><span class="line">    K, _, _, C_out = weight.shape</span><br><span class="line">    Ns, Hs, Ws, Cs = Z.strides</span><br><span class="line">    </span><br><span class="line">    inner_dim = K * K * C_in</span><br><span class="line">    A = as_strided(Z, shape=(N, H-K+<span class="number">1</span>, W-K+<span class="number">1</span>, K, K, C_in),</span><br><span class="line">                   strides=(Ns, Hs, Ws, Hs, Ws, Cs)).reshape(-<span class="number">1</span>, inner_dim)</span><br><span class="line">    out = A @ weight.reshape(-<span class="number">1</span>, C_out)</span><br><span class="line">    <span class="keyword">return</span> out.reshape(N, H-K+<span class="number">1</span>, W-K+<span class="number">1</span>, C_out)</span><br></pre></td></tr></table></figure>
<p>这样用时为</p>
<figure>
<img
src="https://raw.githubusercontent.com/zzhbrr/Images/main/202212310940743.png"
alt="image-20221231002615014" />
<figcaption aria-hidden="true">image-20221231002615014</figcaption>
</figure>
]]></content>
      <categories>
        <category>CMU10714</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
      </tags>
  </entry>
</search>
